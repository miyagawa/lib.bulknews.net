<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2//EN">
<html>
  <head>
   <title>mod_perl guide: Performance Tuning </title>
   <meta name="Author" content="Stas Bekman">
   <meta name="Description" content="All Apache/Perl related information: Hints, Guidelines, Scenarios and Troubleshottings">
   <meta name="keywords" content="mod_perl modperl perl cgi apache webserver speed fast guide mod_perl apache guide help info faq mod_perl installation cgi troubleshooting help no sex speedup free open source OSS mod_perl apache guide">
   <meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
   <meta name="Classification" content="information">
   <link href="./style.css" rel=stylesheet type="text/css" title="refstyle">
  </head>
  <body>

    <h1 align=center>
      <a href="http://perl.apache.org"><img src="images/mod_perl.gif" alt="Mod Perl Icon" border=0 height=30 width=90 align=left></a>
      <a href="http://perl.apache.org"><img src="images/mod_perl.gif" alt="Mod Perl Icon" border=0 height=30 width=90 align=right></a>
      Performance Tuning 
    </h1>
    <hr>
    <p>
    <div class="navbar">
      <a href="./porting.html">Prev</a>                                 |
      <a href="./index.html"         >Contents</a> |
      <a href="./index.html#search"  >Search</a>   |
      <a href="./index.html#download">Download</a> |
      <a href="./frequent.html">Next</a>
    </div>
    <p>

    <div class="toc">
      
<A NAME="toc"></A>
<P><B>Table of Contents:</B></P>

<UL>

	<LI><A HREF="#The_Big_Picture">The Big Picture</A>
	<LI><A HREF="#System_Analysis">System Analysis</A>
	<UL>

		<LI><A HREF="#Software_Requirements">Software Requirements</A>
		<LI><A HREF="#Hardware_Requirements">Hardware Requirements</A>
	</UL>

	<LI><A HREF="#Essential_Tools">Essential Tools</A>
	<UL>

		<LI><A HREF="#Benchmarking_Applications">Benchmarking Applications</A>
		<UL>

			<LI><A HREF="#Benchmarking_Perl_Code">Benchmarking Perl Code</A>
			<LI><A HREF="#Benchmarking_a_Graphic_Hits_Coun">Benchmarking a Graphic Hits Counter with Persistent DB Connections</A>
			<LI><A HREF="#Benchmarking_Response_Times">Benchmarking Response Times</A>
			<UL>

				<LI><A HREF="#ApacheBench">ApacheBench</A>
				<LI><A HREF="#httperf">httperf</A>
				<LI><A HREF="#http_load">http_load</A>
				<LI><A HREF="#the_crashme_Script">the crashme Script</A>
			</UL>

			<LI><A HREF="#Benchmarking_PerlHandlers">Benchmarking PerlHandlers</A>
		</UL>

		<LI><A HREF="#Code_Profiling_Techniques">Code Profiling Techniques</A>
		<LI><A HREF="#Measuring_the_Memory_of_the_Proc">Measuring the Memory of the Process</A>
		<LI><A HREF="#Measuring_the_Memory_Usage_of_Su">Measuring the Memory Usage of Subroutines </A>
	</UL>

	<LI><A HREF="#Know_Your_Operating_System">Know Your Operating System</A>
	<UL>

		<LI><A HREF="#Sharing_Memory">Sharing Memory</A>
		<UL>

			<LI><A HREF="#How_Shared_Is_My_Memory_">How Shared Is My Memory?</A>
			<LI><A HREF="#Calculating_Real_Memory_Usage">Calculating Real Memory Usage</A>
			<LI><A HREF="#Are_My_Variables_Shared_">Are My Variables Shared?</A>
			<LI><A HREF="#Preloading_Perl_Modules_at_Serve">Preloading Perl Modules at Server Startup</A>
			<LI><A HREF="#Preloading_Registry_Scripts_at_S">Preloading Registry Scripts at Server Startup</A>
			<LI><A HREF="#Modules_Initializing_at_Server_S">Modules Initializing at Server Startup</A>
			<UL>

				<LI><A HREF="#Initializing_DBI_pm">Initializing DBI.pm</A>
				<LI><A HREF="#Initializing_CGI_pm">Initializing CGI.pm</A>
			</UL>

		</UL>

		<LI><A HREF="#Increasing_Shared_Memory_With_me">Increasing Shared Memory With mergemem</A>
		<LI><A HREF="#Forking_and_Executing_Subprocess">Forking and Executing Subprocesses from mod_perl</A>
		<UL>

			<LI><A HREF="#Forking_a_New_Process">Forking a New Process</A>
			<LI><A HREF="#Freeing_the_Parent_Process">Freeing the Parent Process</A>
			<LI><A HREF="#Detaching_the_Forked_Process">Detaching the Forked Process</A>
			<LI><A HREF="#Avoiding_Zombie_Processes">Avoiding Zombie Processes</A>
			<LI><A HREF="#A_Complete_Fork_Example">A Complete Fork Example</A>
			<LI><A HREF="#Starting_a_Long_Running_External">Starting a Long Running External Program</A>
			<LI><A HREF="#Starting_a_Short_Running_Externa">Starting a Short Running External Program</A>
			<LI><A HREF="#Executing_system_or_exec_in_">Executing system() or exec() in the Right Way</A>
		</UL>

		<LI><A HREF="#OS_Specific_Parameters_for_Proxy">OS Specific Parameters for Proxying</A>
	</UL>

	<LI><A HREF="#Performance_Tuning_by_Tweaking_A">Performance Tuning by Tweaking Apache Configuration</A>
	<UL>

		<LI><A HREF="#Configuration_Tuning_with_Apache">Configuration Tuning with ApacheBench</A>
		<LI><A HREF="#Choosing_MaxClients">Choosing MaxClients</A>
		<LI><A HREF="#Choosing_MaxRequestsPerChild">Choosing MaxRequestsPerChild</A>
		<LI><A HREF="#Choosing_MinSpareServers_MaxSpa">Choosing MinSpareServers, MaxSpareServers and StartServers</A>
		<LI><A HREF="#Summary_of_Benchmarking_to_tune_">Summary of Benchmarking to tune all 5 parameters</A>
		<LI><A HREF="#KeepAlive">KeepAlive</A>
		<LI><A HREF="#PerlSetupEnv_Off">PerlSetupEnv Off</A>
		<LI><A HREF="#Reducing_the_Number_of_stat_Ca">Reducing the Number of stat() Calls Made by Apache</A>
	</UL>

	<LI><A HREF="#TMTOWTDI_Convenience_and_Habit_">TMTOWTDI: Convenience and Habit vs. Performance</A>
	<UL>

		<LI><A HREF="#Apache_Registry_PerlHandler_vs_">Apache::Registry PerlHandler vs. Custom PerlHandler</A>
		<LI><A HREF="#_Bloatware_modules">&quot;Bloatware&quot; modules</A>
		<LI><A HREF="#Apache_args_vs_Apache_Request">Apache::args vs. Apache::Request::param vs. CGI::param</A>
		<LI><A HREF="#Using_1_Under_mod_perl_and_Be">Using $|=1 Under mod_perl and Better print() Techniques.</A>
		<LI><A HREF="#Global_vs_Fully_Qualified_Varia">Global vs. Fully Qualified Variables</A>
		<LI><A HREF="#Object_Methods_Calls_vs_Functio">Object Methods Calls vs. Function Calls</A>
		<UL>

			<LI><A HREF="#The_Overhead_with_Light_Subrouti">The Overhead with Light Subroutines</A>
			<LI><A HREF="#The_Overhead_with_Heavy_Subrouti">The Overhead with Heavy Subroutines</A>
			<LI><A HREF="#Are_All_Methods_Slower_than_Func">Are All Methods Slower than Functions?</A>
		</UL>

		<LI><A HREF="#Imported_Symbols_and_Memory_Usag">Imported Symbols and Memory Usage</A>
		<LI><A HREF="#Interpolation_Concatenation_or_">Interpolation, Concatenation or List</A>
		<LI><A HREF="#Using_Perl_stat_Call_s_Cached_">Using Perl stat() Call's Cached Results</A>
	</UL>

	<LI><A HREF="#Apache_Registry_and_Derivatives">Apache::Registry and Derivatives Specific Notes</A>
	<UL>

		<LI><A HREF="#Be_Careful_with_Symbolic_Links">Be Careful with Symbolic Links</A>
	</UL>

	<LI><A HREF="#Improving_Performance_by_Prevent">Improving Performance by Prevention</A>
	<UL>

		<LI><A HREF="#Memory_leakage">Memory leakage</A>
		<UL>

			<LI><A HREF="#Reading_In_A_Whole_File">Reading In A Whole File</A>
			<LI><A HREF="#Copying_Variables_Between_Functi">Copying Variables Between Functions</A>
			<LI><A HREF="#Work_With_Databases">Work With Databases</A>
		</UL>

		<LI><A HREF="#Keeping_the_Shared_Memory_Limit">Keeping the Shared Memory Limit</A>
		<LI><A HREF="#Limiting_the_Size_of_the_Process">Limiting the Size of the Processes</A>
		<LI><A HREF="#Limiting_Other_Resources_Used_by">Limiting Other Resources Used by Apache Child Processes</A>
		<UL>

			<LI><A HREF="#OS_Specific_notes">OS Specific notes</A>
		</UL>

		<LI><A HREF="#Limiting_the_Number_of_Processes">Limiting the Number of Processes Serving the Same Resource</A>
		<LI><A HREF="#Limiting_the_Request_Rate_Speed_">Limiting the Request Rate Speed (Robot Blocking)</A>
	</UL>

	<LI><A HREF="#Perl_Modules_for_Performance_Imp">Perl Modules for Performance Improvement</A>
	<UL>

		<LI><A HREF="#Sending_Plain_HTML_as_Compressed">Sending Plain HTML as Compressed Output</A>
		<LI><A HREF="#Caching_Components_with_HTML_Ma">Caching Components with HTML::Mason</A>
	</UL>

	<LI><A HREF="#Efficient_Work_with_Databases_un">Efficient Work with Databases under mod_perl</A>
	<UL>

		<LI><A HREF="#Persistent_DB_Connections">Persistent DB Connections</A>
		<UL>

			<LI><A HREF="#Preopening_Connections_at_the_Ch">Preopening Connections at the Child Process' Fork Time</A>
			<LI><A HREF="#Caching_prepare_Statements">Caching prepare() Statements</A>
		</UL>

		<LI><A HREF="#mod_perl_Database_Performance_Im">mod_perl Database Performance Improving</A>
		<UL>

			<LI><A HREF="#Analysis_of_the_Problem">Analysis of the Problem</A>
			<LI><A HREF="#Optimizing_Database_Connections">Optimizing Database Connections</A>
			<LI><A HREF="#Utilizing_the_Database_Server_s_">Utilizing the Database Server's Cache</A>
			<LI><A HREF="#Eliminating_SQL_Statement_Parsin">Eliminating SQL Statement Parsing</A>
			<LI><A HREF="#Conclusion">Conclusion</A>
		</UL>

	</UL>

	<LI><A HREF="#Using_3rd_Party_Applications">Using 3rd Party Applications</A>
	<UL>

		<LI><A HREF="#Proxying_the_mod_perl_Server">Proxying the mod_perl Server</A>
	</UL>

	<LI><A HREF="#Upload_and_Download_of_Big_Files">Upload and Download of Big Files</A>
	<LI><A HREF="#Apache_mod_perl_Build_Options">Apache/mod_perl Build Options</A>
	<UL>

		<LI><A HREF="#mod_perl_Process_Size_as_a_Funct">mod_perl Process Size as a Function of Compiled in C Modules and mod_perl Features</A>
	</UL>

	<LI><A HREF="#Perl_Build_Options">Perl Build Options</A>
	<UL>

		<LI><A HREF="#_DTWO_POT_OPTIMIZE_and_DPACK_MA">-DTWO_POT_OPTIMIZE and -DPACK_MALLOC Perl Build Options</A>
		<LI><A HREF="#_Dusemymalloc_Perl_Build_Option">-Dusemymalloc Perl Build Option</A>
	</UL>

	<LI><A HREF="#Architecture_Specific_Compile_Op">Architecture Specific Compile Options</A>
</UL>

    </div>

    [ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
    <table width="60%" align="center">

      <tr>
	<td>
	  <div class="ad">
	    The <a href="http://www.modperl.com/">
	      <B>Writing Apache Modules with Perl and C</B></a>
	    book can be purchased online from <a
	      href="http://www.ora.com/catalog/wrapmod/">O'Reilly </a>
	    and <a
	    href="http://www.amazon.com/exec/obidos/ASIN/156592567X/writinapachemodu">
	      Amazon.com</a>.
	  </div>
	</td>
      </tr>

      <tr>
	<td>
	  <div class="notice">
	  <B>Your corrections of the technical and grammatical
	     errors are very welcome. You are encouraged to help me
	     improve this guide.  If you have something to contribute
	     please <A HREF="help.html#Contacting_me"> send it
	     directly to me</A>.</B>
	  </div>
	</td>
      </tr>

</table>

    

	    [ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>

<P>
<CENTER><H1><A NAME="The_Big_Picture">The Big Picture</A></H1></CENTER>
<P>
To make the user's Web browsing experience as painless as possible, every
effort must be made to wring the last drop of performance from the server.
There are many factors which affect Web site usability, but speed is one of
the most important. This applies to any webserver, not just Apache, so it
is very important that you understand it.

<P>
How do we measure the speed of a server? Since the user (and not the
computer) is the one that interacts with the Web site, one good speed
measurement is the time elapsed between the moment when she clicks on a
link or presses a <EM>Submit</EM> button to the moment when the resulting page is fully rendered.

<P>
The requests and replies are broken into packets. A request may be made up
of several packets, a reply may be many thousands. Each packet has to make
its own way from one machine to another, perhaps passing through many
interconnection nodes. We must measure the time starting from when the
first packet of the request leaves our user's machine to when the last
packet of the reply arrives back there.

<P>
A webserver is only one of the entities the packets see along their way. If
we follow them from browser to server and back again, they may travel by
different routes through many different entities. Before they are processed
by your server the packets might have to go through proxy (accelerator)
servers and if the request contains more than one packet, packets might
arrive to the server by different routes with different arrival times,
therefore it's possible that some packets that arrive earlier will have to
wait for other packets before they could be reassembled into a chunk of the
request message that will be then read by the server. Then the whole
process is repeated in reverse.

<P>
You could work hard to fine tune your webserver's performance, but a slow
Network Interface Card (NIC) or a slow network connection from your server
might defeat it all. That's why it's important to think about the Big
Picture and to be aware of possible bottlenecks between the server and the
Web.

<P>
Of course there is little that you can do if the user has a slow
connection. You might tune your scripts and webserver to process incoming
requests ultra quickly, so you will need only a small number of working
servers, but you might find that the server processes are all busy waiting
for slow clients to accept their responses.

<P>
But there are techniques to cope with this. For example you can deliver the
respond after it was compressed. If you are delivering a pure text
respond--gzip compression will sometimes reduce the size of the respond by
10 times.

<P>
You should analyze all the involved components when you try to create the
best service for your users, and not the web server or the code that the
web server executes. A Web service is like a car, if one of the parts or
mechanisms is broken the car may not go smoothly and it can even stop dead
if pushed too far without first fixing it.

<P>
And let me stress it again--if you want to have a success in the web
service business you should start worrying about the client's browsing
experience and <STRONG>not only</STRONG> how good your code benchmarks are.

<P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H1><A NAME="System_Analysis">System Analysis</A></H1></CENTER>
<P>
Before we try to solve a problem we need to indentify it. In our case we
want to get the best performance we can with as little monetary and time
investment as possible.

<P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H2><A NAME="Software_Requirements">Software Requirements</A></H2></CENTER>
<P>
Covered in the section ``<A HREF="././hardware.html#Choosing_an_Operating_System">Choosing an Operating System</A>''.

<P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H2><A NAME="Hardware_Requirements">Hardware Requirements</A></H2></CENTER>
<P>
(META: Only partial analysis. Please submit more points. Many points are
scattered around the document and should be gathered here, to represent the
whole picture. It also should be merged with the above item!)

<P>
You need to analyze all of the problem's dimensions. There are several
things that need to be considered:

<UL>
<P><LI>
<P>
How long does it take to process each request?

<P><LI>
<P>
How many requests can you process simultaneously?

<P><LI>
<P>
How many simultaneous requests are you planning to get?

<P><LI>
<P>
At what rate are you expecting to receive requests?

</UL>
<P>
The first one is probably the easiest to optimize. Following the
performance optimization tips in this and other documents allows a perl
(mod_perl) programmer to exercise their code and improve it.

<P>
The second one is a function of RAM. How much RAM is in each box, how many
boxes do you have, and how much RAM does each mod_perl process use?
Multiply the first two and divide by the third. Ask yourself whether it is
better to switch to another, possibly just as inefficient language or
whether that will actually cost more than throwing another powerful machine
into the rack.

<P>
Also ask yourself whether switching to another language will even help. In
some applications, for example to link Oracle runtime libraries, a huge
chunk of memory is needed so you would save nothing even if you switched
from Perl to C.

<P>
The last two are important. You need a realistic estimate. Are you really
expecting 8 million hits per day? What is the expected peak load, and what
kind of response time do you need to guarantee? Remember that these numbers
might change drastically when you apply code changes and your site becomes
popular. Remember that when you get a very high hit rate, the resource
requirements don't grow linearly but exponentially!

<P>
More coverage is provided in the section ``<A HREF="././hardware.html#Choosing_Hardware">Choosing Hardware</A>''.

<P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H1><A NAME="Essential_Tools">Essential Tools</A></H1></CENTER>
<P>
In order to improve performance we need measurement tools. The main tool
categories are benchmarking and code profiling.

<P>
It's important to understand that in a major number of the benchmarking
tests that we will execute we will not look at the absolute result numbers
but the relation between the two and more result sets, since in most cases
we would try to show which coding approach is preferable and the you
shouldn't try to compare the absolute results collected while running the
same benchmarks on your machine, since you won't have the exact hardware
and software setup anyway. So this kind of comparisment would be
misleading. Compare the relative results from the tests running on your
machine, don't compare your absolute results with those in this Guide.

<P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H2><A NAME="Benchmarking_Applications">Benchmarking Applications</A></H2></CENTER>
<P>
How much faster is mod_perl than mod_cgi (aka plain perl/CGI)? There are
many ways to benchmark the two. I'll present a few examples and numbers
below. Check out the <CODE>benchmark</CODE> directory of the mod_perl distribution for more examples.

<P>
If you are going to write your own benchmarking utility, use the
<CODE>Benchmark</CODE> module for heavy scripts and the <CODE>Time::HiRes</CODE> module for very fast scripts (faster than 1 sec) where you will need better
time precision.

<P>
There is no need to write a special benchmark though. If you want to
impress your boss or colleagues, just take some heavy CGI script you have
(e.g. a script that crunches some data and prints the results to STDOUT),
open 2 xterms and call the same script in mod_perl mode in one xterm and in
mod_cgi mode in the other. You can use <CODE>lwp-get</CODE>
from the <CODE>LWP</CODE> package to emulate the browser. The <CODE>benchmark</CODE>
directory of the mod_perl distribution includes such an example.

<P>
See also two tools for benchmarking:
<A HREF="././performance.html#Configuration_Tuning_with_Apache">ApacheBench</A> and
<A HREF="././performance.html#the_crashme_Script">crashme test</A>



<P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H3><A NAME="Benchmarking_Perl_Code">Benchmarking Perl Code</A></H3></CENTER>
<P>
If you are going to write your own benchmarking utility, use the
<CODE>Benchmark</CODE> module and the <CODE>Time::HiRes</CODE> module where you need better time precision (&lt;10msec).

<P>
An example of the <CODE>Benchmark.pm</CODE> module usage:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  benchmark.pl
  ------------
  use Benchmark;
  
  timethis (1_000,
   sub {
    my $x = 100;
    my $y = log ($x ** 100)  for (0..10000);
  });</pre>
        </td>
	    
      </tr>
    </table>
    <P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  % perl benchmark.pl
  timethis 1000: 25 wallclock secs (24.93 usr +  0.00 sys = 24.93 CPU)</pre>
        </td>
	    
      </tr>
    </table>
    <P>
If you want to get the benchmark results in micro-seconds you will have to
use the <CODE>Time::HiRes</CODE> module, its usage is similar to
<CODE>Benchmark</CODE>'s.

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  use Time::HiRes qw(gettimeofday tv_interval);
  my $start_time = [ gettimeofday ];
  sub_that_takes_a_teeny_bit_of_time();
  my $end_time = [ gettimeofday ];
  my $elapsed = tv_interval($start_time,$end_time);
  print &quot;The sub took $elapsed seconds.&quot;</pre>
        </td>
	    
      </tr>
    </table>
    <P>
See also the <A HREF="././performance.html#the_crashme_Script">crashme test</A>.

<P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H3><A NAME="Benchmarking_a_Graphic_Hits_Coun">Benchmarking a Graphic Hits Counter with Persistent DB Connections</A></H3></CENTER>
<P>
Here are the numbers from Michael Parker's mod_perl presentation at the
Perl Conference (Aug, 98). (Sorry, there used to be links here to the
source, but they went dead one day, so I removed them). The script is a
standard hits counter, but it logs the counts into a mysql relational
DataBase:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>    Benchmark: timing 100 iterations of cgi, perl...  [rate 1:28]
    
    cgi: 56 secs ( 0.33 usr 0.28 sys = 0.61 cpu) 
    perl: 2 secs ( 0.31 usr 0.27 sys = 0.58 cpu) 
    
    Benchmark: timing 1000 iterations of cgi,perl...  [rate 1:21]
     
    cgi: 567 secs ( 3.27 usr 2.83 sys = 6.10 cpu) 
    perl: 26 secs ( 3.11 usr 2.53 sys = 5.64 cpu)      
    
    Benchmark: timing 10000 iterations of cgi, perl   [rate 1:21]
     
    cgi: 6494 secs (34.87 usr 26.68 sys = 61.55 cpu) 
    perl: 299 secs (32.51 usr 23.98 sys = 56.49 cpu) </pre>
        </td>
	    
      </tr>
    </table>
    <P>
We don't know what server configurations were used for these tests, but I
guess the numbers speak for themselves.

<P>
The source code of the script was available at <A
HREF="http://www.realtime.net/~parkerm/perl/conf98/sld006.htm.">http://www.realtime.net/~parkerm/perl/conf98/sld006.htm.</A>
It's now a dead link. If you know its new location, please let me know.

<P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H3><A NAME="Benchmarking_Response_Times">Benchmarking Response Times</A></H3></CENTER>
<P>
In the next sections we will talk about tools that allow us to benchmark
response times.

<P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H4><A NAME="ApacheBench">ApacheBench</A></H4></CENTER>
<P>
ApacheBench (<STRONG>ab</STRONG>) is a tool for benchmarking your Apache HTTP server. It is designed to
give you an idea of the performance that your current Apache installation
can give. In particular, it shows you how many requests per second your
Apache server is capable of serving. The <STRONG>ab</STRONG> tool comes bundled with the Apache source distribution.

<P>
Let's try it. We will simulate 10 users concurrently requesting a very
light script at <CODE>www.example.com/perl/test.pl</CODE>. Each simulated user makes 10 requests.

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  % ./ab -n 100 -c 10 www.example.com/perl/test.pl</pre>
        </td>
	    
      </tr>
    </table>
    <P>
The results are:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  Document Path:          /perl/test.pl
  Document Length:        319 bytes
  
  Concurrency Level:      10
  Time taken for tests:   0.715 seconds
  Complete requests:      100
  Failed requests:        0
  Total transferred:      60700 bytes
  HTML transferred:       31900 bytes
  Requests per second:    139.86
  Transfer rate:          84.90 kb/s received
  
  Connection Times (ms)
                min   avg   max
  Connect:        0     0     3
  Processing:    13    67    71
  Total:         13    67    74</pre>
        </td>
	    
      </tr>
    </table>
    <P>
We can see that under load of ten concurrent users our server is capable of
processing 140 requests per second. Of course this benchmark is correct
only when the script under test is used. We can also learn about the
average processing time, which in this case was 67 milli-seconds. Other
numbers reported by c&lt;ab&gt; may or may not be of interest to you.

<P>
For example if we believe that the script <EM>perl/test.pl</EM> is not efficient we will try to improve it and run the benchmark again, to
see whether we have any improve in performance.

<P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H4><A NAME="httperf">httperf</A></H4></CENTER>
<P>
httperf is a utility written by David Mosberger. Just like ApacheBench, it
measures the performance of the webserver.

<P>
A sample command line is shown below:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  httperf --server hostname --port 80 --uri /test.html \
   --rate 150 --num-conn 27000 --num-call 1 --timeout 5</pre>
        </td>
	    
      </tr>
    </table>
    <P>
This command causes httperf to use the web server on the host with IP name
hostname, running at port 80. The web page being retrieved is
<EM>/test.html</EM> and, in this simple test, the same page is retrieved repeatedly. The rate
at which requests are issued is 150 per second. The test involves
initiating a total of 27,000 TCP connections and on each connection one
HTTP call is performed. A call consists of sending a request and receiving
a reply.

<P>
The timeout option defines the number of seconds that the client is willing
to wait to hear back from the server. If this timeout expires, the tool
considers the corresponding call to have failed. Note that with a total of
27,000 connections and a rate of 150 per second, the total test duration
will be approximately 180 seconds (27,000/150), independently of what load
the server can actually sustain. Here is a result that one might get:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>     Total: connections 27000 requests 26701 replies 26701 test-duration 179.996 s
    
     Connection rate: 150.0 conn/s (6.7 ms/conn, &lt;=47 concurrent connections)
     Connection time [ms]: min 1.1 avg 5.0 max 315.0 median 2.5 stddev 13.0
     Connection time [ms]: connect 0.3
     
     Request rate: 148.3 req/s (6.7 ms/req)
     Request size [B]: 72.0
     
     Reply rate [replies/s]: min 139.8 avg 148.3 max 150.3 stddev 2.7 (36 samples)
     Reply time [ms]: response 4.6 transfer 0.0
     Reply size [B]: header 222.0 content 1024.0 footer 0.0 (total 1246.0)
     Reply status: 1xx=0 2xx=26701 3xx=0 4xx=0 5xx=0
     
     CPU time [s]: user 55.31 system 124.41 (user 30.7% system 69.1% total 99.8%)
     Net I/O: 190.9 KB/s (1.6*10^6 bps)
     
     Errors: total 299 client-timo 299 socket-timo 0 connrefused 0 connreset 0
     Errors: fd-unavail 0 addrunavail 0 ftab-full 0 other 0</pre>
        </td>
	    
      </tr>
    </table>
    <P>
<A HREF="././download.html#httperf_webserver_Benchmarkin">httperf download</A>



<P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H4><A NAME="http_load">http_load</A></H4></CENTER>
<P>
<CODE>http_load</CODE> is yet another utility that does webserver load testing. It can simulate
33.6kbps modem connection (<EM>-throttle</EM>) and allows you to provide a file with a list of URLs, which we be fetched
randomly. You can specify how many parallel connections to run using the <EM>-parallel N</EM> option, or you can specify the number of requests to generate per second
with <EM>-rate N</EM> option. Finally you can tell the utility when to stop by specifying either
the test time length (<EM>-seconds N</EM>) or the total number of fetches (<EM>-fetches N</EM>).

<P>
A sample run with the file <EM>urls</EM> including:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  <A HREF="http://www.example.com/foo/">http://www.example.com/foo/</A>
  <A HREF="http://www.example.com/bar/">http://www.example.com/bar/</A></pre>
        </td>
	    
      </tr>
    </table>
    <P>
We ask to generate three requests per second and run for only two seconds.
Here is the generated output:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  % ./http_load -rate 3 -seconds 2 urls
  <A HREF="http://www.example.com/foo/">http://www.example.com/foo/</A>: check-connect SUCCEEDED, ignoring
  <A HREF="http://www.example.com/bar/">http://www.example.com/bar/</A>: check-connect SUCCEEDED, ignoring
  <A HREF="http://www.example.com/bar/">http://www.example.com/bar/</A>: check-connect SUCCEEDED, ignoring
  <A HREF="http://www.example.com/bar/">http://www.example.com/bar/</A>: check-connect SUCCEEDED, ignoring
  <A HREF="http://www.example.com/foo/">http://www.example.com/foo/</A>: check-connect SUCCEEDED, ignoring
  5 fetches, 3 max parallel, 96870 bytes, in 2.00258 seconds
  19374 mean bytes/connection
  2.49678 fetches/sec, 48372.7 bytes/sec
  msecs/connect: 1.805 mean, 5.24 max, 0.79 min
  msecs/first-response: 291.289 mean, 560.338 max, 34.349 min</pre>
        </td>
	    
      </tr>
    </table>
    <P>
So you can see that it has reported 2.5 requests per second. Of course for
the real test you will want to load the server heavily and run the test for
a longer time to get more reliable results.

<P>
Note that when you provide a file with a list of URLs make sure that you
don't have empty lines in it. If you do -- the utility won't work
complaining:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  ./http_load: unknown protocol - </pre>
        </td>
	    
      </tr>
    </table>
    <P>
<A HREF="././download.html#http_load_another_webserver_B">http_load download</A>



<P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H4><A NAME="the_crashme_Script">the crashme Script</A></H4></CENTER>
<P>
This is another crashme suite originally written by Michael Schilli (and
was located at <A
HREF="http://www.linux-magazin.de">http://www.linux-magazin.de</A> site,
but now the link has gone). I made a few modifications, mostly adding
<CODE>my()</CODE> operators. I also allowed it to accept more than one url
to test, since sometimes you want to test more than one script.

<P>
The tool provides the same results as <STRONG>ab</STRONG> above but it also allows you to set the timeout value, so requests will
fail if not served within the time out period. You also get values for <STRONG>Latency</STRONG>
(seconds per request) and <STRONG>Throughput</STRONG> (requests per second). It can do a complete simulation of your favorite
Netscape browser :) and give you a better picture.

<P>
I have noticed while running these two benchmarking suites, that <STRONG>ab</STRONG>
gave me results from two and a half to three times better. Both suites were
run on the same machine, with the same load and the same parameters, but
the implementations were different.

<P>
Sample output:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  URL(s):          <A HREF="http://www.example.com/perl/access/access.cgi">http://www.example.com/perl/access/access.cgi</A>
  Total Requests:  100
  Parallel Agents: 10
  Succeeded:       100 (100.00%)
  Errors:          NONE
  Total Time:      9.39 secs
  Throughput:      10.65 Requests/sec
  Latency:         0.85 secs/Request</pre>
        </td>
	    
      </tr>
    </table>
    <P>
And the code:


	       <p><a href="code/lwp-bench.pl"><code>lwp-bench.pl</code></a> -- The LWP::Parallel::UserAgent benchmark

</p>
	      <P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H3><A NAME="Benchmarking_PerlHandlers">Benchmarking PerlHandlers</A></H3></CENTER>
<P>
The <CODE>Apache::Timeit</CODE> module does <CODE>PerlHandler</CODE> Benchmarking. With the help of this module you can log the time taken to
process the request, just like you'd use the <CODE>Benchmark</CODE> module to benchmark a regular Perl script. Of course you can extend this
module to perform more advanced processing like putting the results into a
database for a later processing. But all it takes is adding this
configuration directive inside <EM>httpd.conf</EM>:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  PerlFixupHandler Apache::Timeit</pre>
        </td>
	    
      </tr>
    </table>
    <P>
Since scripts running under <CODE>Apache::Registry</CODE> are running inside the PerlHandler these are benchmarked as well.

<P>
An example of the lines which show up in the <EM>error_log</EM> file:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  timing request for /perl/setupenvoff.pl:
    0 wallclock secs ( 0.04 usr +  0.01 sys =  0.05 CPU)
  timing request for /perl/setupenvoff.pl:
    0 wallclock secs ( 0.03 usr +  0.00 sys =  0.03 CPU)</pre>
        </td>
	    
      </tr>
    </table>
    <P>
The <CODE>Apache::Timeit</CODE> package is a part of the <EM>Apache-Perl-contrib</EM>
files collection available from CPAN.

<P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H2><A NAME="Code_Profiling_Techniques">Code Profiling Techniques</A></H2></CENTER>
<P>
The profiling process helps you to determine which subroutines or just
snippets of code take the longest time to execute and which subroutines are
called most often. Probably you will want to optimize those.

<P>
When do you need to profile your code? You do that when you suspect that
some part of your code is called very often and may be there is a need to
optimize it to significantly improve the overall performance.

<P>
For example if you have ever used the <CODE>diagnostics</CODE> pragma, which extends the terse diagnostics normally emitted by both the
Perl compiler and the Perl interpreter, augmenting them with the more
verbose and endearing descriptions found in the <CODE>perldiag</CODE> manpage. You know that it might tremendously slow you code down, so let's
first prove that it is correct.

<P>
We will run a benchmark, once with diagnostics enabled and once disabled,
on a subroutine called <EM>test_code</EM>.

<P>
The code inside the subroutine does an arithmetic and a numeric comparison
of two strings. It assigns one string to another if the condition tests
true but the condition always tests false. To demonstrate the <CODE>diagnostics</CODE> overhead the comparison operator is intentionally <EM>wrong</EM>. It should be a string comparison, not a numeric one.

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  use Benchmark;
  use diagnostics;
  use strict;
  
  my $count = 50000;
  
  disable diagnostics;
  my $t1 = timeit($count,\&amp;test_code);
  
  enable  diagnostics;
  my $t2 = timeit($count,\&amp;test_code);
  
  print &quot;Off: &quot;,timestr($t1),&quot;\n&quot;;
  print &quot;On : &quot;,timestr($t2),&quot;\n&quot;;
  
  sub test_code{
    my ($a,$b) = qw(foo bar);
    my $c;
    if ($a == $b) {
      $c = $a;
    }
  }</pre>
        </td>
	    
      </tr>
    </table>
    <P>
For only a few lines of code we get:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  Off:  1 wallclock secs ( 0.81 usr +  0.00 sys =  0.81 CPU)
  On : 13 wallclock secs (12.54 usr +  0.01 sys = 12.55 CPU)</pre>
        </td>
	    
      </tr>
    </table>
    <P>
With <CODE>diagnostics</CODE> enabled, the subroutine <CODE>test_code()</CODE> is 16 times slower, than
with <CODE>diagnostics</CODE> disabled!

<P>
Now let's fix the comparison the way it should be, by replacing <CODE>==</CODE>
with <CODE>eq</CODE>, so we get:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>    my ($a,$b) = qw(foo bar);
    my $c;
    if ($a eq $b) {
      $c = $a;
    }</pre>
        </td>
	    
      </tr>
    </table>
    <P>
and run the same benchmark again:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  Off:  1 wallclock secs ( 0.57 usr +  0.00 sys =  0.57 CPU)
  On :  1 wallclock secs ( 0.56 usr +  0.00 sys =  0.56 CPU)</pre>
        </td>
	    
      </tr>
    </table>
    <P>
Now there is no overhead at all. The <CODE>diagnostics</CODE> pragma slows things down only when warnings are generated.

<P>
After we have verified that using the <CODE>diagnostics</CODE> pragma might adds a big overhead to execution runtime, let's use the code
profiling to understand why this happens. We are going to use <CODE>Devel::DProf</CODE> to profile the code. Let's use this code:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  diagnostics.pl
  --------------
  use diagnostics;
  print &quot;Content-type:text/html\n\n&quot;;
  test_code();
  sub test_code{
    my ($a,$b) = qw(foo bar);
    my $c;
    if ($a == $b) {
      $c = $a;
    }
  }</pre>
        </td>
	    
      </tr>
    </table>
    <P>
Run it with the profiler enabled, and then create the profiling stastics
with the help of dprofpp:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  % perl -d:DProf diagnostics.pl
  % dprofpp
  
  Total Elapsed Time = 0.342236 Seconds
    User+System Time = 0.335420 Seconds
  Exclusive Times
  %Time ExclSec CumulS #Calls sec/call Csec/c  Name
   92.1   0.309  0.358      1   0.3089 0.3578  main::BEGIN
   14.9   0.050  0.039   3161   0.0000 0.0000  diagnostics::unescape
   2.98   0.010  0.010      2   0.0050 0.0050  diagnostics::BEGIN
   0.00   0.000 -0.000      2   0.0000      -  Exporter::import
   0.00   0.000 -0.000      2   0.0000      -  Exporter::export
   0.00   0.000 -0.000      1   0.0000      -  Config::BEGIN
   0.00   0.000 -0.000      1   0.0000      -  Config::TIEHASH
   0.00   0.000 -0.000      2   0.0000      -  Config::FETCH
   0.00   0.000 -0.000      1   0.0000      -  diagnostics::import
   0.00   0.000 -0.000      1   0.0000      -  main::test_code
   0.00   0.000 -0.000      2   0.0000      -  diagnostics::warn_trap
   0.00   0.000 -0.000      2   0.0000      -  diagnostics::splainthis
   0.00   0.000 -0.000      2   0.0000      -  diagnostics::transmo
   0.00   0.000 -0.000      2   0.0000      -  diagnostics::shorten
   0.00   0.000 -0.000      2   0.0000      -  diagnostics::autodescribe</pre>
        </td>
	    
      </tr>
    </table>
    <P>
It's not easy to see what is responsible for this enormous overhead, even
if <CODE>main::BEGIN</CODE> seems to be running most of the time. To get the full picture we must see
the OPs tree, which shows us who calls whom, so we run:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  % dprofpp -T</pre>
        </td>
	    
      </tr>
    </table>
    <P>
and the output is:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre> main::BEGIN
   diagnostics::BEGIN
      Exporter::import
         Exporter::export
   diagnostics::BEGIN
      Config::BEGIN
      Config::TIEHASH
      Exporter::import
         Exporter::export
   Config::FETCH
   Config::FETCH
   diagnostics::unescape
   .....................
   3159 times [diagnostics::unescape] snipped
   .....................
   diagnostics::unescape
   diagnostics::import
 diagnostics::warn_trap
   diagnostics::splainthis
      diagnostics::transmo
      diagnostics::shorten
      diagnostics::autodescribe
 main::test_code
   diagnostics::warn_trap
      diagnostics::splainthis
         diagnostics::transmo
         diagnostics::shorten
         diagnostics::autodescribe
   diagnostics::warn_trap
      diagnostics::splainthis
         diagnostics::transmo
         diagnostics::shorten
        diagnostics::autodescribe</pre>
        </td>
	    
      </tr>
    </table>
    <P>
So we see that two executions of <CODE>diagnostics::BEGIN</CODE> and 3161 of
<CODE>diagnostics::unescape</CODE> are responsible for most of the running overhead.

<P>
If we comment out the <CODE>diagnostics</CODE> module, we get:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  Total Elapsed Time = 0.079974 Seconds
    User+System Time = 0.059974 Seconds
  Exclusive Times
  %Time ExclSec CumulS #Calls sec/call Csec/c  Name
   0.00   0.000 -0.000      1   0.0000      -  main::test_code</pre>
        </td>
	    
      </tr>
    </table>
    <P>
It is possible to profile code running under mod_perl with the
<CODE>Devel::DProf</CODE> module, available on CPAN. However, you must have apache version 1.3b3 or
higher and the <CODE>PerlChildExitHandler</CODE> enabled during the httpd build process. When the server is started,
<CODE>Devel::DProf</CODE> installs an <CODE>END</CODE> block to write the <EM>tmon.out</EM>
file. This block will be called at server shutdown. Here is how to start
and stop a server with the profiler enabled:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  % setenv PERL5OPT -d:DProf
  % httpd -X -d `pwd` &amp;
  ... make some requests to the server here ...
  % kill `cat logs/httpd.pid`
  % unsetenv PERL5OPT
  % dprofpp</pre>
        </td>
	    
      </tr>
    </table>
    <P>
The <CODE>Devel::DProf</CODE> package is a Perl code profiler. It will collect information on the
execution time of a Perl script and of the subs in that script (remember
that <CODE>print()</CODE> and <CODE>map()</CODE> are just like any other subroutines you write, but they come bundled with
Perl!)

<P>
Another approach is to use <CODE>Apache::DProf</CODE>, which hooks
<CODE>Devel::DProf</CODE> into mod_perl. The <CODE>Apache::DProf</CODE> module will run a
<CODE>Devel::DProf</CODE> profiler inside each child server and write the
<EM>tmon.out</EM> file in the directory <CODE>$ServerRoot/logs/dprof/$$</CODE> when the child is shutdown (where <CODE>$$</CODE> is the number of the child process). All it takes is to add to <EM>httpd.conf</EM>:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  PerlModule Apache::DProf</pre>
        </td>
	    
      </tr>
    </table>
    <P>
Remember that any PerlHandler that was pulled in before
<CODE>Apache::DProf</CODE> in the <EM>httpd.conf</EM> or <EM>startup.pl</EM>, will not have its code debugging information inserted. To run <CODE>dprofpp</CODE>, chdir to
<CODE>$ServerRoot/logs/dprof/$$</CODE> and run:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  % dprofpp</pre>
        </td>
	    
      </tr>
    </table>
    <P>
(Lookup the <CODE>ServerRoot</CODE> directive's value in <EM>httpd.conf</EM> to figure out what's your <CODE>$ServerRoot</CODE>.)

<P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H2><A NAME="Measuring_the_Memory_of_the_Proc">Measuring the Memory of the Process</A></H2></CENTER>
<P>
Very important aspect of performance tuning is to make sure that your
applications don't use much memory, since if they do you cannot run many
servers and therefore in most cases under a heavy load the overall
performance degrades. 

<P>
In addition the code may not be clean and leak memory, which is even worse,
since if the same process serves many requests and after each request more
memory is used, after awhile all RAM will be used and machine will start
swapping (use the swap partition) which is a very undesirable event, since
it may lead to a machine crash.

<P>
The simplest way to figure out how big the processes are and see whether
they grow is to watch the output of <CODE>top(1)</CODE> or
<CODE>ps(1)</CODE> utilities.

<P>
For example the output of <CODE>top(1):</CODE>

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>    8:51am  up 66 days,  1:44,  1 user,  load average: 1.09, 2.27, 2.61
  95 processes: 92 sleeping, 3 running, 0 zombie, 0 stopped
  CPU states: 54.0% user,  9.4% system,  1.7% nice, 34.7% idle
  Mem:  387664K av, 309692K used,  77972K free, 111092K shrd,  70944K buff
  Swap: 128484K av,  11176K used, 117308K free                170824K cached</pre>
        </td>
	    
      </tr>
    </table>
    <P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>     PID USER PRI NI SIZE  RSS SHARE STAT LIB %CPU %MEM   TIME COMMAND
  29225 nobody 0  0  9760 9760  7132 S      0 12.5  2.5   0:00 httpd_perl
  29220 nobody 0  0  9540 9540  7136 S      0  9.0  2.4   0:00 httpd_perl
  29215 nobody 1  0  9672 9672  6884 S      0  4.6  2.4   0:01 httpd_perl
  29255 root   7  0  1036 1036   824 R      0  3.2  0.2   0:01 top
    376 squid  0  0 15920  14M   556 S      0  1.1  3.8 209:12 squid
  29227 mysql  5  5  1892 1892   956 S N    0  1.1  0.4   0:00 mysqld
  29223 mysql  5  5  1892 1892   956 S N    0  0.9  0.4   0:00 mysqld
  29234 mysql  5  5  1892 1892   956 S N    0  0.9  0.4   0:00 mysqld</pre>
        </td>
	    
      </tr>
    </table>
    <P>
Which starts with overall information of the system and then displays the
most active processes at the given moment. So for example if we look at the <CODE>httpd_perl</CODE> processes we can see the size of the resident (<CODE>RSS</CODE>) and shared (<CODE>SHARE</CODE>) memory segments. This sample was taken on the production server running
linux.

<P>
But of course we want to see all the apache/mod_perl processes, and that's
where <CODE>ps(1)</CODE> comes to help. The options of this utility vary
from one Unix flavor to another, and some flavors provide their own tools.
Let's check the information about mod_perl processes:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  % ps -o pid,user,rss,vsize,%cpu,%mem,ucomm -C httpd_perl
    PID USER      RSS   VSZ %CPU %MEM COMMAND
  29213 root     8584 10264  0.0  2.2 httpd_perl
  29215 nobody   9740 11316  1.0  2.5 httpd_perl
  29216 nobody   9668 11252  0.7  2.4 httpd_perl
  29217 nobody   9824 11408  0.6  2.5 httpd_perl
  29218 nobody   9712 11292  0.6  2.5 httpd_perl
  29219 nobody   8860 10528  0.0  2.2 httpd_perl
  29220 nobody   9616 11200  0.5  2.4 httpd_perl
  29221 nobody   8860 10528  0.0  2.2 httpd_perl
  29222 nobody   8860 10528  0.0  2.2 httpd_perl
  29224 nobody   8860 10528  0.0  2.2 httpd_perl
  29225 nobody   9760 11340  0.7  2.5 httpd_perl
  29235 nobody   9524 11104  0.4  2.4 httpd_perl</pre>
        </td>
	    
      </tr>
    </table>
    <P>
Now you can see the resident (<CODE>RSS</CODE>) and virtual (<CODE>VSZ</CODE>) memory segments (and shared memory segment if you ask for it) of all
mod_perl processes. Please refer to the <CODE>top(1)</CODE> and
<CODE>ps(1)</CODE> man pages for more information.

<P>
You probably agree that using <CODE>top(1)</CODE> and <CODE>ps(1)</CODE> is
cumbersome if we want to use memory size sampling during the benchmark
test. We want to have a way to print memory sizes during the program
execution at desired places. If you have <CODE>GTop</CODE> modules installed, which is a perl glue to the <CODE>libgtop</CODE> library, it's exactly what we need.

<P>
Note: <CODE>GTop</CODE> requires the <CODE>libgtop</CODE> library but is not available for all platforms. Visit <A
HREF="http://www.home-of-linux.org/gnome/libgtop/">http://www.home-of-linux.org/gnome/libgtop/</A>
to check whether your platform/flavor is supported.

<P>
<CODE>GTop</CODE> provides an API for retrieval of information about processes and the whole
system. We are interested only in memory sampling API methods. To print all
the process related memory information we can execute the following code:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  use GTop;
  my $gtop = GTop-&gt;new;
  my $proc_mem = $gtop-&gt;proc_mem($$);
  for (qw(size vsize share rss)) {
      printf &quot;   %s =&gt; %d\n&quot;, $_, $proc_mem-&gt;$_();
  }</pre>
        </td>
	    
      </tr>
    </table>
    <P>
When executed we see the following output (in bytes):

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>      size =&gt; 1900544
     vsize =&gt; 3108864
     share =&gt; 1392640
       rss =&gt; 1900544</pre>
        </td>
	    
      </tr>
    </table>
    <P>
So if we are interested in to print the process resident memory segment
before and after some event we just do it: For example if we want to see
how much extra memory was allocated after a variable creation we can write
the following code:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  use GTop;
  my $gtop = GTop-&gt;new;
  my $before = $gtop-&gt;proc_mem($$)-&gt;rss;
  my $x = 'a' x 10000;
  my $after  = $gtop-&gt;proc_mem($$)-&gt;rss;
  print &quot;diff: &quot;,$after-$before, &quot; bytes\n&quot;;</pre>
        </td>
	    
      </tr>
    </table>
    <P>
and the output

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  diff: 20480 bytes</pre>
        </td>
	    
      </tr>
    </table>
    <P>
So we can see that Perl has allocated extra 20480 bytes to create
<CODE>$x</CODE> (of course the creation of <CODE>after</CODE> needed a few bytes as well, but it's insignificant compared to a size of <CODE>$x</CODE>)

<P>
The <CODE>Apache::VMonitor</CODE> module with help of the <CODE>GTop</CODE> module allows you to watch all your system information using your favorite
browser from anywhere in the world without a need to telnet to your
machine. If you are looking at what information you can retrieve with <CODE>GTop</CODE>, you should look at <CODE>Apache::VMonitor</CODE> as it deployes a big part of the API <CODE>GTop</CODE> provides.

<P>
If you are running a true BSD system, you may use
<CODE>BSD::Resource::getrusage</CODE> instead of <CODE>GTop</CODE>. For example:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  print &quot;used memory = &quot;.(BSD::Resource::getrusage)[2].&quot;\n&quot;</pre>
        </td>
	    
      </tr>
    </table>
    <P>
For more information refer to the <CODE>BSD::Resource</CODE> manpage.

<P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H2><A NAME="Measuring_the_Memory_Usage_of_Su">Measuring the Memory Usage of Subroutines</A></H2></CENTER>
<P>
With help of <CODE>Apache::Status</CODE> you can find out the size of each and every subroutine.

<OL>
<P><LI>
<P>
Build and install mod_perl as you always do, make sure it's version 1.22 or
higher.

<P><LI>
<P>
Configure /perl-status if you haven't already:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  &lt;Location /perl-status&gt;
    SetHandler perl-script
    PerlHandler Apache::Status
    order deny,allow
    #deny from all
    #allow from ...
  &lt;/Location&gt;</pre>
        </td>
	    
      </tr>
    </table>
    <P><LI>
<P>
Add to httpd.conf

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  PerlSetVar StatusOptionsAll On
  PerlSetVar StatusTerse On
  PerlSetVar StatusTerseSize On
  PerlSetVar StatusTerseSizeMainSummary On</pre>
        </td>
	    
      </tr>
    </table>
    <P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  PerlModule B::TerseSize</pre>
        </td>
	    
      </tr>
    </table>
    <P><LI>
<P>
Start the server (best in httpd -X mode)

<P><LI>
<P>
From your favorite browser fetch <A
HREF="http://localhost/perl-status">http://localhost/perl-status</A>

<P><LI>
<P>
Click on 'Loaded Modules' or 'Compiled Registry Scripts'

<P><LI>
<P>
Click on the module or script of your choice (you might need to run some
script/handler before you will see it here unless it was preloaded)

<P><LI>
<P>
Click on 'Memory Usage' at the bottom

<P><LI>
<P>
You should see all the subroutines and their respective sizes.

</OL>
<P>
Now you can start to optimize your code. Or test which of the several
implementations is of the least size.

<P>
For example let's compare <CODE>CGI.pm</CODE>'s OO vs. procedural interfaces:

<P>
As you will see below the first OO script uses about 2k bytes while the
second script (procedural interface) uses about 5k.

<P>
Here are the code examples and the numbers:

<OL>
<P><LI>
<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  cgi_oo.pl
  ---------
  use CGI ();
  my $q = CGI-&gt;new;
  print $q-&gt;header;
  print $q-&gt;b(&quot;Hello&quot;);</pre>
        </td>
	    
      </tr>
    </table>
    <P><LI>
<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  cgi_mtd.pl
  ---------
  use CGI qw(header b);
  print header();
  print b(&quot;Hello&quot;);</pre>
        </td>
	    
      </tr>
    </table>
    </OL>
<P>
After executing each script in single server mode (-X) the results are:

<OL>
<P><LI>
<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  Totals: 1966 bytes | 27 OPs</pre>
        </td>
	    
      </tr>
    </table>
    <P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  handler 1514 bytes | 27 OPs
  exit     116 bytes |  0 OPs</pre>
        </td>
	    
      </tr>
    </table>
    <P><LI>
<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  Totals: 4710 bytes | 19 OPs
  
  handler  1117 bytes | 19 OPs
  basefont  120 bytes |  0 OPs
  frameset  120 bytes |  0 OPs
  caption   119 bytes |  0 OPs
  applet    118 bytes |  0 OPs
  script    118 bytes |  0 OPs
  ilayer    118 bytes |  0 OPs
  header    118 bytes |  0 OPs
  strike    118 bytes |  0 OPs
  layer     117 bytes |  0 OPs
  table     117 bytes |  0 OPs
  frame     117 bytes |  0 OPs
  style     117 bytes |  0 OPs
  Param     117 bytes |  0 OPs
  small     117 bytes |  0 OPs
  embed     117 bytes |  0 OPs
  font      116 bytes |  0 OPs
  span      116 bytes |  0 OPs
  exit      116 bytes |  0 OPs
  big       115 bytes |  0 OPs
  div       115 bytes |  0 OPs
  sup       115 bytes |  0 OPs
  Sub       115 bytes |  0 OPs
  TR        114 bytes |  0 OPs
  td        114 bytes |  0 OPs
  Tr        114 bytes |  0 OPs
  th        114 bytes |  0 OPs
  b         113 bytes |  0 OPs</pre>
        </td>
	    
      </tr>
    </table>
    </OL>
<P>
Note, that the above is correct if you didn't precompile all
<CODE>CGI.pm</CODE>'s methods at server startup. Since if you did, the procedural interface in
the second test will take up to 18k and not 5k as we saw. That's because
the whole of <CODE>CGI.pm</CODE>'s namespace is inherited and it already has all its methods compiled, so
it doesn't really matter whether you attempt to import only the symbols
that you need. So if you have:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  use CGI  qw(-compile :all);</pre>
        </td>
	    
      </tr>
    </table>
    <P>
in the server startup script. Having:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  use CGI qw(header);</pre>
        </td>
	    
      </tr>
    </table>
    <P>
or

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  use CGI qw(:all);</pre>
        </td>
	    
      </tr>
    </table>
    <P>
is essentially the same. You will have all the symbols precompiled at
startup imported even if you ask for only one symbol. It seems to me like a
bug, but probably that's how <CODE>CGI.pm</CODE> works.

<P>
BTW, you can check the number of opcodes in the code by a simple command
line run. For example comparing 'my&nbsp;%hash' vs. 'my&nbsp;%hash&nbsp;=
()'.

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  % perl -MO=Terse -e 'my %hash' | wc -l
  -e syntax OK
      4</pre>
        </td>
	    
      </tr>
    </table>
    <P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  % perl -MO=Terse -e 'my %hash = ()' | wc -l
  -e syntax OK
     10</pre>
        </td>
	    
      </tr>
    </table>
    <P>
The first one has less opcodes.

<P>
Note that you shouldn't use <CODE>Apache::Status</CODE> module on production server as it adds quite a bit of overhead for each
request.

<P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H1><A NAME="Know_Your_Operating_System">Know Your Operating System</A></H1></CENTER>
<P>
In order to get the best performance it helps to get intimately familiar
with the Operating System (OS) the web server is running on. There are many
OS specific things that you may be able to optimise which will improve your
web server's speed, reliability and security.

<P>
The following sections will unveal some of the most important details you
should know about your OS.

<P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H2><A NAME="Sharing_Memory">Sharing Memory</A></H2></CENTER>
<P>
The sharing of memory is one very important factor. If your OS supports it
(and most sane systems do), you might save memory by sharing it between
child processes. This is only possible when you preload code at server
startup. However, during a child process' life its memory pages tend to
become unshared.

<P>
There is no way we can make Perl allocate memory so that (dynamic)
variables land on different memory pages from constants, so the
<STRONG>copy-on-write</STRONG> effect (we will explain this in a moment) will hit you almost at random.

<P>
If you are pre-loading many modules you might be able to trade off the
memory that stays shared against the time for an occasional fork by tuning <CODE>MaxRequestsPerChild</CODE>. Each time a child reaches this upper limit and dies it should release its
unshared pages. The new child which replaces it will share its fresh pages
until it scribbles on them.

<P>
The ideal is a point where your processes usually restart before too much
memory becomes unshared. You should take some measurements to see if it
makes a real difference, and to find the range of reasonable values. If you
have success with this tuning the value of
<CODE>MaxRequestsPerChild</CODE> will probably be peculiar to your situation and may change with changing
circumstances.

<P>
It is very important to understand that your goal is not to have
<CODE>MaxRequestsPerChild</CODE> to be 10000. Having a child serving 300 requests on precompiled code is
already a huge overall speedup, so if it is 100 or 10000 it probably does
not really matter if you can save RAM by using a lower value.

<P>
Do not forget that if you preload most of your code at server startup, the
newly forked child gets ready very very fast, because it inherits most of
the preloaded code and the perl interpreter from the parent process.

<P>
During the life of the child its memory pages (which aren't really its own
to start with, it uses the parent's pages) gradually get `dirty' -
variables which were originally inherited and shared are updated or
modified -- and the <EM>copy-on-write</EM> happens. This reduces the number of shared memory pages, thus increasing
the memory requirement. Killing the child and spawning a new one allows the
new child to get back to the pristine shared memory of the parent process.

<P>
The recommendation is that <CODE>MaxRequestsPerChild</CODE> should not be too large, otherwise you lose some of the benefit of sharing
memory.

<P>
See <A HREF="././performance.html#Choosing_MaxRequestsPerChild">Choosing MaxRequestsPerChild</A> for more about tuning the <CODE>MaxRequestsPerChild</CODE> parameter.

<P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H3><A NAME="How_Shared_Is_My_Memory_">How Shared Is My Memory?</A></H3></CENTER>
<P>
You've probably noticed that the word shared is repeated many times in
relation to mod_perl. Indeed, shared memory might save you a lot of money,
since with sharing in place you can run many more servers than without it.
See <A HREF="././performance.html#Choosing_MaxClients">the Formula and the numbers</A>.

<P>
How much shared memory do you have? You can see it by either using the
memory utility that comes with your system or you can deploy the
<CODE>GTop</CODE> module:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  use GTop ();
  print &quot;Shared memory of the current process: &quot;,
    GTop-&gt;new-&gt;proc_mem($$)-&gt;share,&quot;\n&quot;;
  
  print &quot;Total shared memory: &quot;,
    GTop-&gt;new-&gt;mem-&gt;share,&quot;\n&quot;;</pre>
        </td>
	    
      </tr>
    </table>
    <P>
When you watch the output of the <CODE>top</CODE> utility, don't confuse the
<CODE>RES</CODE> (or <CODE>RSS</CODE>) columns with the <CODE>SHARE</CODE> column.  <CODE>RES</CODE> is RESident memory, which is the size of pages currently swapped in.

<P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H3><A NAME="Calculating_Real_Memory_Usage">Calculating Real Memory Usage</A></H3></CENTER>
<P>
I have shown how to measure the size of the process' shared memory, but we
still want to know what the real memory usage is. Obviously this cannot be
calculated simply by adding up the memory size of each process because that
wouldn't account for the shared memory.

<P>
On the other hand we cannot just subtract the shared memory size from the
total size to get the real memory usage numbers, because in reality each
process has a different history of processed requests, therefore the shared
memory is not the same for all processes.

<P>
So how do we measure the real memory size used by the server we run? It's
probably too difficult to give the exact number, but I've found a way to
get a fair approximation which was verified in the following way. I have
calculated the real memory used, by the technique you will see in the
moment, and then have stopped the Apache server and saw that the memory
usage report indicated that the total used memory went down by almost the
same number I've calculated. Note that some OSs do smart memory pages
caching so you may not see the memory usage decrease as soon as it actually
happens when you quit the application.

<P>
This is a technique I've used:

<OL>
<P><LI>
<P>
For each process sum up the difference between shared and system memory. To
calculate a difference for a single process use:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  use GTop;
  my $proc_mem = GTop-&gt;new-&gt;proc_mem($$);
  my $diff     = $proc_mem-&gt;size - $proc_mem-&gt;share;
  print &quot;Difference is $diff bytes\n&quot;;</pre>
        </td>
	    
      </tr>
    </table>
    <P><LI>
<P>
Now if we add the shared memory size of the process with maximum shared
memory, we will get all the memory that actually is being used by all httpd
processes, except for the parent process.

<P><LI>
<P>
Finally, add the size of the parent process.

</OL>
<P>
Please note that this might be incorrect for your system, so you use this
number on your own risk.

<P>
I've used this technique to display real memory usage in the module
<A HREF="././debug.html#Apache_VMonitor_Visual_Syste">Apache::VMonitor</A>, so instead of trying to manually calculate this number you can use this
module to do it automatically. In fact in the calculations used in this
module there is no separation between the parent and child processes, they
are all counted indifferently using the following code:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  use GTop ();
  my $gtop = GTop-&gt;new;
  my $total_real = 0;
  my $max_shared = 0;
  # @mod_perl_pids is initialized by Apache::Scoreboard, irrelevant here
  my @mod_perl_pids = some_code();
  for my $pid (@mod_perl_pids)
    my $proc_mem = $gtop-&gt;proc_mem($pid);
    my $size     = $proc_mem-&gt;size($pid);
    my $share    = $proc_mem-&gt;share($pid);
    $total_real += $size - $share;
    $max_shared  = $share if $max_shared &lt; $share;
  }
  my $total_real += $max_shared;</pre>
        </td>
	    
      </tr>
    </table>
    <P>
So as you see we that we accumulate the difference between the shared and
reported memory:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>    $total_real  += $size-$share;</pre>
        </td>
	    
      </tr>
    </table>
    <P>
and at the end add the biggest shared process size:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  my $total_real += $max_shared;</pre>
        </td>
	    
      </tr>
    </table>
    <P>
So now <CODE>$total_real</CODE> contains approximately the really used memory.

<P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H3><A NAME="Are_My_Variables_Shared_">Are My Variables Shared?</A></H3></CENTER>
<P>
How do you find out if the code you write is shared between the processes
or not? The code should be shared, except where it is on a memory page with
variables that change. Some variables are read-only in usage and never
change. For example, if you have some variables that use a lot of memory
and you want them to be read-only. As you know the variable becomes
unshared when the process modifies its value.

<P>
So imagine that you have this 10Mb in-memory database that resides in a
single variable, you perform various operations on it and want to make sure
that the variable is still shared. For example if you do some matching
regular expression (regex) processing on this variable and want to use the
<CODE>pos()</CODE> function, will it make the variable unshared or not?

<P>
The <CODE>Apache::Peek</CODE> module comes to rescue. Let's write a module called <EM>MyShared.pm</EM> which we preload at server startup, so all the variables of this module are
initially shared by all children.

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  MyShared.pm
  ---------
  package MyShared;
  use Apache::Peek;
  
  my $readonly = &quot;Chris&quot;;
  
  sub match    { $readonly =~ /\w/g;               }
  sub print_pos{ print &quot;pos: &quot;,pos($readonly),&quot;\n&quot;;}
  sub dump     { Dump($readonly);                  }
  1;</pre>
        </td>
	    
      </tr>
    </table>
    <P>
This module declares the package <CODE>MyShared</CODE>, loads the
<CODE>Apache::Peek</CODE> module and defines the lexically scoped <CODE>$readonly</CODE>
variable which is supposed to be a variable of large size (think about a
huge hash data structure), but we will use a small one to simplify this
example.

<P>
The module also defines three subroutines: <CODE>match()</CODE> that does a
simple character matching, <CODE>print_pos()</CODE> that prints the current
position of the matching engine inside the string that was last matched and
finally the <CODE>dump()</CODE> subroutine that calls the <CODE>Apache::Peek</CODE> module's <CODE>Dump()</CODE> function to dump a raw Perl data-type of the <CODE>$readonly</CODE>
variable.

<P>
Now we write the script that prints the process ID (PID) and calls all
three functions. The goal is to check whether <CODE>pos()</CODE> makes the
variable <EM>dirty</EM> and therefore unshared.

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  share_test.pl
  -------------
  use MyShared;
  print &quot;Content-type: text/plain\r\n\r\n&quot;;
  print &quot;PID: $$\n&quot;;
  MyShared::match();
  MyShared::print_pos();
  MyShared::dump();</pre>
        </td>
	    
      </tr>
    </table>
    <P>
Before you restart the server, in <EM>httpd.conf</EM> set:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  MaxClients 2</pre>
        </td>
	    
      </tr>
    </table>
    <P>
for easier tracking. You need at least two servers to compare the print
outs of the test program. Having more than two can make the comparison
process harder.

<P>
Now open two browser windows and issue the request for this script several
times in both windows, so you get different processes PIDs reported in the
two windows and each process has processed a different number of requests
to the <EM>share_test.pl</EM> script.

<P>
In the first window you will see something like that:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  PID: 27040
  pos: 1
  SV = PVMG(0x853db20) at 0x8250e8c
    REFCNT = 3
    FLAGS = (PADBUSY,PADMY,SMG,POK,pPOK)
    IV = 0
    NV = 0
    PV = 0x8271af0 &quot;Chris&quot;\0
    CUR = 5
    LEN = 6
    MAGIC = 0x853dd80
      MG_VIRTUAL = &amp;vtbl_mglob
      MG_TYPE = 'g'
      MG_LEN = 1</pre>
        </td>
	    
      </tr>
    </table>
    <P>
And in the second window:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  PID: 27041
  pos: 2
  SV = PVMG(0x853db20) at 0x8250e8c
    REFCNT = 3
    FLAGS = (PADBUSY,PADMY,SMG,POK,pPOK)
    IV = 0
    NV = 0
    PV = 0x8271af0 &quot;Chris&quot;\0
    CUR = 5
    LEN = 6
    MAGIC = 0x853dd80
      MG_VIRTUAL = &amp;vtbl_mglob
      MG_TYPE = 'g'
      MG_LEN = 2</pre>
        </td>
	    
      </tr>
    </table>
    <P>
We see that all the addresses of the supposedly big structure are the same
(<CODE>0x8250e8c</CODE> and <CODE>0x8271af0</CODE>), therefore the variable data structure is almost completely shared. The
only difference is in
<CODE>SV.MAGIC.MG_LEN</CODE> record, which is not shared.

<P>
So given that the <CODE>$readonly</CODE> variable is a big one, its value is still shared between the processes,
while part of the variable data structure is non-shared. But it's almost
insignificant because it takes a very little memory space.

<P>
Now if you need to compare more than variable, doing it by hand can be
quite time consuming and error prune. Therefore it's better to correct the
testing script to dump the Perl data-types into files (e.g
<EM>/tmp/dump.$$</EM>, where <CODE>$$</CODE> is the PID of the process) and then using <CODE>diff(1)</CODE> utility to
see whether there is some difference.

<P>
So correcting the <CODE>dump()</CODE> function to write the info to the
file will do the job. Notice that we use <CODE>Devel::Peek</CODE> and not
<CODE>Apache::Peek</CODE>. The both are almost the same, but <CODE>Apache::Peek</CODE>
prints it output directly to the opened socket so we cannot intercept and
redirect the result to the file. Since <CODE>Devel::Peek</CODE> dumps results to the STDERR stream we can use the old trick of saving away
the default STDERR handler, and open a new filehandler using the STDERR. In
our example when <CODE>Devel::Peek</CODE> now prints to STDERR it actually prints to our file. When we are done, we
make sure to restore the original STDERR filehandler. 

<P>
So this is the resulting code:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  MyShared2.pm
  ---------
  package MyShared2;
  use Devel::Peek;
  
  my $readonly = &quot;Chris&quot;;
  
  sub match    { $readonly =~ /\w/g;               }
  sub print_pos{ print &quot;pos: &quot;,pos($readonly),&quot;\n&quot;;}
  sub dump{
    my $dump_file = &quot;/tmp/dump.$$&quot;;
    print &quot;Dumping the data into $dump_file\n&quot;;
    open OLDERR, &quot;&gt;&amp;STDERR&quot;;
    open STDERR, &quot;&gt;&quot;.$dump_file or die &quot;Can't open $dump_file: $!&quot;;
    Dump($readonly);
    close STDERR ;
    open STDERR, &quot;&gt;&amp;OLDERR&quot;;
  }
  1;</pre>
        </td>
	    
      </tr>
    </table>
    <P>
When if we modify the code to use the modified module:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  share_test2.pl
  -------------
  use MyShared2;
  print &quot;Content-type: text/plain\r\n\r\n&quot;;
  print &quot;PID: $$\n&quot;;
  MyShared2::match();
  MyShared2::print_pos();
  MyShared2::dump();</pre>
        </td>
	    
      </tr>
    </table>
    <P>
And run it as before (with MaxClients&nbsp;2), two dump files will be created in the directory <EM>/tmp</EM>. In our test these were created as
<EM>/tmp/dump.1224</EM> and <EM>/tmp/dump.1225</EM>. When we run <CODE>diff(1):</CODE>

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  % diff /tmp/dump.1224 /tmp/dump.1225
  12c12
  &lt;       MG_LEN = 1
  ---
  &gt;       MG_LEN = 2</pre>
        </td>
	    
      </tr>
    </table>
    <P>
We see that the two padlists (of the variable <CODE>readonly</CODE>) are different, as we have observed before when we did a manual
comparison.

<P>
In fact we if we think about these results again, we get to a conclusion
that there is no need for two processes to find out whether the variable
gets modified (and therefore unshared). It's enough to check the
datastructure before the script was executed and after that. You can modify
the <CODE>MyShared2</CODE> module to dump the padlists into a different file after each invocation and
than to run the <CODE>diff(1)</CODE> on the two files.

<P>
If you want to watch whether some lexically scoped (with <CODE>my())</CODE>
variables in your <CODE>Apache::Registry</CODE> script inside the same process get changed between invocations you can use
the
<CODE>Apache::RegistryLexInfo</CODE> module instead. Since it does exactly this: it makes a snapshot of the
padlist before and after the code execution and shows the difference
between the two. This specific module was written to work with <CODE>Apache::Registry</CODE> scripts so it won't work for loaded modules. Use the technique we have
described above for any type of variables in modules and scripts.

<P>
Surely another way of ensuring that a scalar is readonly and therefore
sharable is to either use the <CODE>constant</CODE> pragma or <CODE>readonly</CODE>
pragma. But then you won't be able to make calls that alter the variable
even a little, like in the example that we just showed, because it will be
a true constant variable and you will get compile time error if you try
this:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  MyConstant.pm
  -------------
  package MyConstant;
  use constant readonly =&gt; &quot;Chris&quot;;
  
  sub match    { readonly =~ /\w/g;               }
  sub print_pos{ print &quot;pos: &quot;,pos(readonly),&quot;\n&quot;;}
  1;</pre>
        </td>
	    
      </tr>
    </table>
    <P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  % perl -c MyConstant.pm</pre>
        </td>
	    
      </tr>
    </table>
    <P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  Can't modify constant item in match position at MyConstant.pm line
  5, near &quot;readonly)&quot;
  MyConstant.pm had compilation errors.</pre>
        </td>
	    
      </tr>
    </table>
    <P>
However this code is just right:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  MyConstant1.pm
  -------------
  package MyConstant1;
  use constant readonly =&gt; &quot;Chris&quot;;
  
  sub match { readonly =~ /\w/g; }
  1;</pre>
        </td>
	    
      </tr>
    </table>
    <P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H3><A NAME="Preloading_Perl_Modules_at_Serve">Preloading Perl Modules at Server Startup</A></H3></CENTER>
<P>
You can use the <CODE>PerlRequire</CODE> and <CODE>PerlModule</CODE> directives to load commonly used modules such as <CODE>CGI.pm</CODE>, <CODE>DBI</CODE> and etc., when the server is started. On most systems, server children will
be able to share the code space used by these modules. Just add the
following directives into <EM>httpd.conf</EM>:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  PerlModule CGI
  PerlModule DBI</pre>
        </td>
	    
      </tr>
    </table>
    <P>
But an even better approach is to create a separate startup file (where you
code in plain perl) and put there things like:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  use DBI ();
  use Carp ();</pre>
        </td>
	    
      </tr>
    </table>
    <P>
Don't forget to prevent importing of the symbols exported by default by the
module you are going to preload, by placing empty parentheses
<CODE>()</CODE> after a module's name. Unless you need some of these in the startup file,
which is unlikely. This will save you a few more memory bits.

<P>
Then you <CODE>require()</CODE> this startup file in <EM>httpd.conf</EM> with the
<CODE>PerlRequire</CODE> directive, placing it before the rest of the mod_perl configuration
directives:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  PerlRequire /path/to/start-up.pl</pre>
        </td>
	    
      </tr>
    </table>
    <P>
<CODE>CGI.pm</CODE> is a special case. Ordinarily <CODE>CGI.pm</CODE> autoloads most of its functions on an as-needed basis. This speeds up the
loading time by deferring the compilation phase. When you use mod_perl,
FastCGI or another system that uses a persistent Perl interpreter, you will
want to precompile the functions at initialization time. To accomplish
this, call the package function <CODE>compile()</CODE> like this:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  use CGI ();
  CGI-&gt;compile(':all');</pre>
        </td>
	    
      </tr>
    </table>
    <P>
The arguments to <CODE>compile()</CODE> are a list of method names or sets, and are identical to those accepted by
the <CODE>use()</CODE> and <CODE>import()</CODE>
operators. Note that in most cases you will want to replace <CODE>':all'</CODE>
with the tag names that you actually use in your code, since generally you
only use a subset of them.

<P>
Let's conduct a memory usage test to prove that preloading, reduces memory
requirements.

<P>
In order to have an easy measurement we will use only one child process,
therefore we will use this setting:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  MinSpareServers 1
  MaxSpareServers 1
  StartServers 1
  MaxClients 1
  MaxRequestsPerChild 100</pre>
        </td>
	    
      </tr>
    </table>
    <P>
We are going to use the <CODE>Apache::Registry</CODE> script <EM>memuse.pl</EM> which consists of two parts: the first one preloads a bunch of modules
(that most of them aren't going to be used), the second part reports the
memory size and the shared memory size used by the single child process
that we start. and of course it prints the difference between the two
sizes.

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  memuse.pl
  ---------
  use strict;
  use CGI ();
  use DB_File ();
  use LWP::UserAgent ();
  use Storable ();
  use DBI ();
  use GTop ();</pre>
        </td>
	    
      </tr>
    </table>
    <P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  my $r = shift;
  $r-&gt;send_http_header('text/plain');
  my $proc_mem = GTop-&gt;new-&gt;proc_mem($$);
  my $size  = $proc_mem-&gt;size;
  my $share = $proc_mem-&gt;share;
  my $diff  = $size - $share;
  printf &quot;%10s %10s %10s\n&quot;, qw(Size Shared Difference);
  printf &quot;%10d %10d %10d (bytes)\n&quot;,$size,$share,$diff;</pre>
        </td>
	    
      </tr>
    </table>
    <P>
First we restart the server and execute this CGI script when none of the
above modules preloaded. Here is the result:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>     Size   Shared     Diff
  4706304  2134016  2572288 (bytes)</pre>
        </td>
	    
      </tr>
    </table>
    <P>
Now we take all the modules:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  use strict;
  use CGI ();
  use DB_File ();
  use LWP::UserAgent ();
  use Storable ();
  use DBI ();
  use GTop ();</pre>
        </td>
	    
      </tr>
    </table>
    <P>
and copy them into the startup script, so they will get preloaded. The
script remains unchanged. We restart the server and execute it again. We
get the following.

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>     Size   Shared    Diff
  4710400  3997696  712704 (bytes)</pre>
        </td>
	    
      </tr>
    </table>
    <P>
Let's put the two results into one table:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  Preloading    Size   Shared     Diff
     Yes     4710400  3997696   712704 (bytes)
      No     4706304  2134016  2572288 (bytes)
  --------------------------------------------
  Difference    4096  1863680 -1859584</pre>
        </td>
	    
      </tr>
    </table>
    <P>
You can clearly see that when the modules weren't preloaded the shared
memory pages size, were about 1864Kb smaller relative to the case where the
modules were preloaded.

<P>
Assuming that you have had 256M dedicated to the web server, if you didn't
preload the modules, you could have:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  268435456 = X * 2572288 + 2134016</pre>
        </td>
	    
      </tr>
    </table>
    <P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  X = (268435456 - 2134016) / 2572288 = 103 </pre>
        </td>
	    
      </tr>
    </table>
    <P>
103 servers.

<P>
Now let's calculate the same thing with modules preloaded:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  268435456 = X * 712704 + 3997696</pre>
        </td>
	    
      </tr>
    </table>
    <P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  X = (268435456 - 3997696) / 712704 = 371</pre>
        </td>
	    
      </tr>
    </table>
    <P>
You can have almost 4 times more servers!!!

<P>
Remember that we have mentioned before that memory pages gets dirty and the
size of the shared memory gets smaller with time? So we have presented the
ideal case where the shared memory stays intact. Therefore the real numbers
will be a little bit different, but not far from the numbers in our
example.

<P>
Also it's obvious that in your case it's possible that the process size
will be bigger and the shared memory will be smaller, since you will use
different modules and a different code, so you won't get this fantastic
ratio, but this example is certainly helps to feel the difference.

<P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H3><A NAME="Preloading_Registry_Scripts_at_S">Preloading Registry Scripts at Server Startup</A></H3></CENTER>
<P>
What happens if you find yourself stuck with Perl CGI scripts and you
cannot or don't want to move most of the stuff into modules to benefit from
modules preloading, so the code will be shared by the children. Luckily you
can preload scripts as well. This time the
<CODE>Apache::RegistryLoader</CODE> modules comes to aid.
<CODE>Apache::RegistryLoader</CODE> compiles <CODE>Apache::Registry</CODE> scripts at server startup.

<P>
For example to preload the script <EM>/perl/test.pl</EM> which is in fact the file <EM>/home/httpd/perl/test.pl</EM> you would do the following:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  use Apache::RegistryLoader ();
  Apache::RegistryLoader-&gt;new-&gt;handler(&quot;/perl/test.pl&quot;,
                            &quot;/home/httpd/perl/test.pl&quot;);</pre>
        </td>
	    
      </tr>
    </table>
    <P>
You should put this code either into <CODE>&lt;Perl&gt;</CODE> sections or into a startup script.

<P>
But what if you have a bunch of scripts located under the same directory
and you don't want to list them one by one. Take the benefit of Perl
modules and put them to a good use. The <CODE>File::Find</CODE>
module will do most of the work for you.

<P>
The following code walks the directory tree under which all
<CODE>Apache::Registry</CODE> scripts are located. For each encountered file with extension <EM>.pl</EM>, it calls the
<CODE>Apache::RegistryLoader::handler()</CODE> method to preload the script in the parent server, before pre-forking the
child processes:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  use File::Find qw(finddepth);
  use Apache::RegistryLoader ();
  {
    my $scripts_root_dir = &quot;/home/httpd/perl/&quot;;
    my $rl = Apache::RegistryLoader-&gt;new;
    finddepth
      (
       sub {
         return unless /\.pl$/;
         my $url = &quot;$File::Find::dir/$_&quot;;
         $url =~ s|$scripts_root_dir/?|/|;
         warn &quot;pre-loading $url\n&quot;;
           # preload $url
         my $status = $rl-&gt;handler($url);
         unless($status == 200) {
           warn &quot;pre-load of `$url' failed, status=$status\n&quot;;
         }
       },
       $scripts_root_dir);
  }</pre>
        </td>
	    
      </tr>
    </table>
    <P>
Note that we didn't use the second argument to <CODE>handler()</CODE> here, as in the first example. To make the loader smarter about the URI to
filename translation, you might need to provide a <CODE>trans()</CODE> function to translate the URI to filename. URI to filename translation
normally doesn't happen until HTTP request time, so the module is forced to
roll its own translation. If filename is omitted and a
<CODE>trans()</CODE> function was not defined, the loader will try using the URI relative to <STRONG>ServerRoot</STRONG>.

<P>
A simple <CODE>trans()</CODE> function can be something like that:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  sub mytrans {
    my $uri = shift;
    $uri =~ s|^/perl/|/home/httpd/perl/|;
    return $uri;
  }</pre>
        </td>
	    
      </tr>
    </table>
    <P>
You can easily derive the right translation by looking at the <CODE>Alias</CODE>
directive. The above <CODE>mytrans()</CODE> function is matching our <CODE>Alias</CODE>:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  Alias /perl/ /home/httpd/perl/</pre>
        </td>
	    
      </tr>
    </table>
    <P>
After defining the URI to filename translation function you should pass it
during the creation of the <CODE>Apache::RegistryLoader</CODE> object:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  my $rl = Apache::RegistryLoader-&gt;new(trans =&gt; \&amp;mytrans);</pre>
        </td>
	    
      </tr>
    </table>
    <P>
I won't show any benchmarks here, since the effect is absolutely the same
as with preloading modules.

<P>
See also <A HREF="././porting.html#BEGIN_blocks">BEGIN blocks</A>



<P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H3><A NAME="Modules_Initializing_at_Server_S">Modules Initializing at Server Startup</A></H3></CENTER>
<P>
We have just learned that it's important to preload the modules and scripts
at the server startup. It turns out that it's not enough for some modules
and you have to prerun their initialization code to get more memory pages
shared. Basically you will find an information about specific modules in
their respective manpages. We will present a few examples of widely used
modules where the code can be initialized.

<P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H4><A NAME="Initializing_DBI_pm">Initializing DBI.pm</A></H4></CENTER>
<P>
The first example is the <CODE>DBI</CODE> module. As you know <CODE>DBI</CODE> works with many database drivers falling into the <CODE>DBD::</CODE> category, e.g. <CODE>DBD::mysql</CODE>. It's not enough to preload <CODE>DBI</CODE>, you should initialize <CODE>DBI</CODE> with <CODE>driver(s)</CODE> that you are going to use (usually a single
driver is used), if you want to minimize memory use after forking the child
processes. Note that you want to do this under mod_perl and other
environments where the shared memory is very important. Otherwise you
shouldn't initialize drivers.

<P>
You probably know already that under mod_perl you should use the
<CODE>Apache::DBI</CODE> module to get the connection persistence, unless you open a separate
connection for each user--in this case you should not use this module. <CODE>Apache::DBI</CODE> automatically loads <CODE>DBI</CODE> and overrides some of its methods, so you should continue coding like there
is only a <CODE>DBI</CODE> module.

<P>
Just as with modules preloading our goal is to find the startup environment
that will lead to the smallest <EM>"difference"</EM> between the shared and normal memory reported, therefore a smaller total
memory usage.

<P>
And again in order to have an easy measurement we will use only one child
process, therefore we will use this setting in <EM>httpd.conf</EM>:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  MinSpareServers 1
  MaxSpareServers 1
  StartServers 1
  MaxClients 1
  MaxRequestsPerChild 100</pre>
        </td>
	    
      </tr>
    </table>
    <P>
We always preload these modules:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  use Gtop();
  use Apache::DBI(); # preloads DBI as well</pre>
        </td>
	    
      </tr>
    </table>
    <P>
We are going to run memory benchmarks on five different versions of the <EM>startup.pl</EM> file. 

<DL>
<P><DT><STRONG><A NAME="item_option">option 1</A></STRONG><DD>
<P>
Leave the file unmodified.

<P><DT><STRONG>option 2</STRONG><DD>
<P>
Install MySQL driver (we will use MySQL RDBMS for our test):

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  DBI-&gt;install_driver(&quot;mysql&quot;);</pre>
        </td>
	    
      </tr>
    </table>
    <P>
It's safe to use this method, since just like with <CODE>use()</CODE>, if it can't be installed it'll <CODE>die().</CODE>

<P><DT><STRONG>option 3</STRONG><DD>
<P>
Preload MySQL driver module:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  use DBD::mysql;</pre>
        </td>
	    
      </tr>
    </table>
    <P><DT><STRONG>option 4</STRONG><DD>
<P>
Tell <CODE>Apache::DBI</CODE> to connect to the database when the child process starts (<CODE>ChildInitHandler</CODE>), no driver is preload before the child gets spawned!

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  Apache::DBI-&gt;connect_on_init('DBI:mysql:test::localhost',
                             &quot;&quot;,
                             &quot;&quot;,
                             {
                              PrintError =&gt; 1, # warn() on errors
                              RaiseError =&gt; 0, # don't die on error
                              AutoCommit =&gt; 1, # commit executes
                              # immediately
                             }
                            )
  or die &quot;Cannot connect to database: $DBI::errstr&quot;;</pre>
        </td>
	    
      </tr>
    </table>
    <P><DT><STRONG>option 5</STRONG><DD>
<P>
Options 2 and 4: using <CODE>connect_on_init()</CODE> and
<CODE>install_driver().</CODE>

</DL>
<P>
Here is the <CODE>Apache::Registry</CODE> test script that we have used:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  preload_dbi.pl
  --------------
  use strict;
  use GTop ();
  use DBI ();
    
  my $dbh = DBI-&gt;connect(&quot;DBI:mysql:test::localhost&quot;,
                         &quot;&quot;,
                         &quot;&quot;,
                         {
                          PrintError =&gt; 1, # warn() on errors
                          RaiseError =&gt; 0, # don't die on error
                          AutoCommit =&gt; 1, # commit executes
                                           # immediately
                         }
                        )
    or die &quot;Cannot connect to database: $DBI::errstr&quot;;
  
  my $r = shift;
  $r-&gt;send_http_header('text/plain');
  
  my $do_sql = &quot;show tables&quot;;
  my $sth = $dbh-&gt;prepare($do_sql);
  $sth-&gt;execute();
  my @data = ();
  while (my @row = $sth-&gt;fetchrow_array){
    push @data, @row;
  }
  print &quot;Data: @data\n&quot;;
  $dbh-&gt;disconnect(); # NOP under Apache::DBI
  
  my $proc_mem = GTop-&gt;new-&gt;proc_mem($$);
  my $size  = $proc_mem-&gt;size;
  my $share = $proc_mem-&gt;share;
  my $diff  = $size - $share;
  printf &quot;%8s %8s %8s\n&quot;, qw(Size Shared Diff);
  printf &quot;%8d %8d %8d (bytes)\n&quot;,$size,$share,$diff;</pre>
        </td>
	    
      </tr>
    </table>
    <P>
The script opens a opens a connection to the database <EM>'test'</EM> and issues a query to learn what tables the databases has. When the data is
collected and printed the connection would be closed in the regular case,
but <CODE>Apache::DBI</CODE> overrides it with empty method. When the data is processed a familiar to
you already code to print the memory usage follows.

<P>
The server was restarted before each new test.

<P>
So here are the results of the five tests that were conducted, sorted by
the <EM>Diff</EM> column:

<OL>
<P><LI>
<P>
After the first request:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  Test type                              Size   Shared     Diff
  --------------------------------------------------------------
  install_driver (2)                   3465216  2621440   843776
  install_driver &amp; connect_on_init (5) 3461120  2609152   851968
  preload driver (3)                   3465216  2605056   860160
  nothing added (1)                    3461120  2494464   966656
  connect_on_init (4)                  3461120  2482176   978944</pre>
        </td>
	    
      </tr>
    </table>
    <P><LI>
<P>
After the second request (all the subsequent request showed the same
results):

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  Test type                              Size   Shared     Diff
  --------------------------------------------------------------
  install_driver (2)                   3469312  2609152   860160
  install_driver &amp; connect_on_init (5) 3481600  2605056   876544
  preload driver (3)                   3469312  2588672   880640
  nothing added  (1)                   3477504  2482176   995328
  connect_on_init (4)                  3481600  2469888  1011712</pre>
        </td>
	    
      </tr>
    </table>
    </OL>
<P>
Now what do we conclude from looking at these numbers. First we see that
only after a second reload we get the final memory footprint for a specific
request in question (if you pass different arguments the memory usage might
and will be different).

<P>
But both tables show the same pattern of memory usage. We can clearly see
that the real winner is the <EM>startup.pl</EM> file's version where the MySQL driver was installed (2). Since we want to
have a connection ready for the first request made to the freshly spawned
child process, we generally use the version (5) which uses somewhat more
memory, but has almost the same number of shared memory pages. The version
(3) only preloads the driver which results in smaller shared memory. The
last two versions having nothing initialized (1) and having only the
<CODE>connect_on_init()</CODE> method used (4). The former is a little bit
better than the latter, but both significantly worse than the first two
versions.

<P>
To remind you why do we look for the smallest value in the column
<EM>diff</EM>, recall the real memory usage formula:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  RAM_dedicated_to_mod_perl = diff * number_of_processes
                            + the_processes_with_largest_shared_memory</pre>
        </td>
	    
      </tr>
    </table>
    <P>
Notice that the smaller the diff is, the bigger the number of processes you
can have using the same amount of RAM. Therefore every 100K difference
counts, when you multiply it by the number of processes. If we take the
number from the version (2) vs. (4) and assume that we have 256M of memory
dedicated to mod_perl processes we will get the following numbers using the
formula derived from the above formula:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>               RAM - largest_shared_size
  N_of Procs = -------------------------
                        Diff</pre>
        </td>
	    
      </tr>
    </table>
    <P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>                268435456 - 2609152
  (ver 2)  N =  ------------------- = 309
                      860160</pre>
        </td>
	    
      </tr>
    </table>
    <P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>                268435456 - 2469888
  (ver 4)  N =  ------------------- = 262
                     1011712</pre>
        </td>
	    
      </tr>
    </table>
    <P>
So you can tell the difference (17% more child processes in the first
version).

<P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H4><A NAME="Initializing_CGI_pm">Initializing CGI.pm</A></H4></CENTER>
<P>
<CODE>CGI.pm</CODE> is a big module that by default postpones the compilation of its methods
until they are actually needed, thus making it possible to use it under a
slow mod_cgi handler without adding a big overhead. That's not what we want
under mod_perl and if you use
<CODE>CGI.pm</CODE> you should precompile the methods that you are going to use at the server
startup in addition to preloading the module. Use the compile method for
that:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  use CGI;
  CGI-&gt;compile(':all');</pre>
        </td>
	    
      </tr>
    </table>
    <P>
where you should replace the tag group <CODE>:all</CODE> with the real tags and group tags that you are going to use if you want to
optimize the memory usage.

<P>
We are going to compare the shared memory foot print by using the script
which is back compatible with mod_cgi. You will see that you can improve
performance of this kind of scripts as well, but if you really want a fast
code think about porting it to use
<CODE>Apache::Request</CODE> for CGI interface and some other module for HTML generation.

<P>
So here is the <CODE>Apache::Registry</CODE> script that we are going to use to make the comparison:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  preload_cgi_pm.pl
  -----------------
  use strict;
  use CGI ();
  use GTop ();</pre>
        </td>
	    
      </tr>
    </table>
    <P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  my $q = new CGI;
  print $q-&gt;header('text/plain');
  print join &quot;\n&quot;, map {&quot;$_ =&gt; &quot;.$q-&gt;param($_) } $q-&gt;param;
  print &quot;\n&quot;;
  
  my $proc_mem = GTop-&gt;new-&gt;proc_mem($$);
  my $size  = $proc_mem-&gt;size;
  my $share = $proc_mem-&gt;share;
  my $diff  = $size - $share;
  printf &quot;%8s %8s %8s\n&quot;, qw(Size Shared Diff);
  printf &quot;%8d %8d %8d (bytes)\n&quot;,$size,$share,$diff;</pre>
        </td>
	    
      </tr>
    </table>
    <P>
The script initializes the <CODE>CGI</CODE> object, sends HTTP header and then print all the arguments and values that
were passed to the script if at all. At the end as usual we print the
memory usage.

<P>
As usual we are going to use a single child process, therefore we will use
this setting in <EM>httpd.conf</EM>:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  MinSpareServers 1
  MaxSpareServers 1
  StartServers 1
  MaxClients 1
  MaxRequestsPerChild 100</pre>
        </td>
	    
      </tr>
    </table>
    <P>
We are going to run memory benchmarks on three different versions of the <EM>startup.pl</EM> file. We always preload this module:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  use Gtop();</pre>
        </td>
	    
      </tr>
    </table>
    <DL>
<P><DT><STRONG>option 1</STRONG><DD>
<P>
Leave the file unmodified.

<P><DT><STRONG>option 2</STRONG><DD>
<P>
Preload <CODE>CGI.pm</CODE>:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  use CGI ();</pre>
        </td>
	    
      </tr>
    </table>
    <P><DT><STRONG>option 3</STRONG><DD>
<P>
Preload <CODE>CGI.pm</CODE> and pre-compile the methods that we are going to use in the script:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  use CGI ();
  CGI-&gt;compile(qw(header param));</pre>
        </td>
	    
      </tr>
    </table>
    </DL>
<P>
The server was restarted before each new test.

<P>
So here are the results of the five tests that were conducted, sorted by
the <EM>Diff</EM> column:

<OL>
<P><LI>
<P>
After the first request:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  Version     Size   Shared     Diff        Test type
  --------------------------------------------------------------------
        1  3321856  2146304  1175552  not preloaded
        2  3321856  2326528   995328  preloaded
        3  3244032  2465792   778240  preloaded &amp; methods+compiled</pre>
        </td>
	    
      </tr>
    </table>
    <P><LI>
<P>
After the second request (all the subsequent request showed the same
results):

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  Version     Size   Shared    Diff         Test type
  --------------------------------------------------------------------
        1  3325952  2134016  1191936 not preloaded
        2  3325952  2314240  1011712 preloaded
        3  3248128  2445312   802816 preloaded &amp; methods+compiled</pre>
        </td>
	    
      </tr>
    </table>
    </OL>
<P>
The first version shows the results of the script execution when
<CODE>CGI.pm</CODE> wasn't preloaded. The second version with module preloaded. The third when
it's both preloaded and the methods that are going to be used are
precompiled at the server startup.

<P>
By looking at the version one of the second table we can conclude that,
preloading adds about 20K of shared size. As we have mention at the
beginning of this section that's how <CODE>CGI.pm</CODE> was implemented--to reduce the load overhead. Which means that preloading
CGI is almost hardly change a thing. But if we compare the second and the
third versions we will see a very significant difference of 207K
(1011712-802816), and we have used only a few methods (the <EM>header</EM>
method loads a few more method transparently for a user). Imagine how much
memory we are going to save if we are going to precompile all the methods
that we are using in other scripts that use <CODE>CGI.pm</CODE> and do a little bit more than the script that we have used in the test.

<P>
But even in our very simple case using the same formula, what do we see?
(assuming that we have 256MB dedicated for mod_perl)

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>               RAM - largest_shared_size
  N_of Procs = -------------------------
                        Diff</pre>
        </td>
	    
      </tr>
    </table>
    <P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>                268435456 - 2134016
  (ver 1)  N =  ------------------- = 223
                      1191936</pre>
        </td>
	    
      </tr>
    </table>
    <P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>                268435456 - 2445312
  (ver 3)  N =  ------------------- = 331
                     802816</pre>
        </td>
	    
      </tr>
    </table>
    <P>
If we preload <CODE>CGI.pm</CODE> and precompile a few methods that we use in the test script, we can have
50% more child processes than when we don't preload and precompile the
methods that we are going to use.

<P>
META: I've heard that the 3.x generation will be less bloated, so probably
I'll have to rerun this using the new version.

<P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H2><A NAME="Increasing_Shared_Memory_With_me">Increasing Shared Memory With mergemem</A></H2></CENTER>
<P>
<CODE>mergemem</CODE> is an experimental utility for linux, which looks <EM>very</EM>
interesting for us mod_perl users: <A
HREF="http://www.complang.tuwien.ac.at/ulrich/mergemem/">http://www.complang.tuwien.ac.at/ulrich/mergemem/</A>


<P>
It looks like it could be run periodically on your server to find and merge
duplicate pages. It won't halt your httpds during the merge, this aspect
has been taken into consideration already during the design of mergemem:
Merging is not performed with one big systemcall. Instead most operation is
in userspace, making a lot of small systemcalls.

<P>
Therefore blocking of the system should not happen. And, if it really
should turn out to take too much time you can reduce the priority of the
process.

<P>
The worst case that can happen is this: <CODE>mergemem</CODE> merges two pages and immediately afterwards they will be split. The split
costs about the same as the time consumed by merging.

<P>
This software comes with a utility called <CODE>memcmp</CODE> to tell you how much you might save.

<P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H2><A NAME="Forking_and_Executing_Subprocess">Forking and Executing Subprocesses from mod_perl</A></H2></CENTER>
<P>
It's desirable to avoid forking under mod_perl. Since when you do, you are
forking the entire Apache server, lock, stock and barrel. Not only is your
Perl code and Perl interpreter being duplicated, but so is mod_ssl,
mod_rewrite, mod_log, mod_proxy, mod_speling (it's not a typo!) or whatever
modules you have used in your server, all the core routines, etc.

<P>
Modern Operating Systems come with a very light version of fork which adds
a little overhead when called, since it was optimized to do the absolute
minimum of memory pages duplications. The <EM>copy-on-write</EM>
technique is the one that allows to do so. The gist of this technique is as
follows: the parent process memory pages aren't immediately copied to the
child's space on <CODE>fork(),</CODE> but this is done only when the child
or the parent modifies the data in some memory pages. Before the pages get
modified they get marked as dirty and the child has no choice but to copy
the pages that are to be modified since they cannot be shared any more.

<P>
If you need to call a Perl program from your mod_perl code, it's better to
try to covert the program into a module and call it a function without
spawning a special process to do that. Of course if you cannot do that or
the program is not written in Perl, you have to call via
<CODE>system()</CODE> or is equivalent, which spawn a new process. If the
program written in C, you may try to write a Perl glue code with help of XS
or SWIG architectures, and then the program will be executed as a perl
subroutine.

<P>
Also by trying to spawn a sub-process, you might be trying to do the
<EM>"wrong thing"</EM>. If what you really want is to send information to the browser and then do
some post-processing, look into the
<CODE>PerlCleanupHandler</CODE> directive. The latter allows you to tell the child process after request
has been processed and user has received the response. This doesn't release
the mod_perl process to serve other requests, but it allows to send the
response to the client faster. If this is the situation and you need to run
some cleanup code, you may want to register this code during the request
processing via:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  my $r = shift;
  $r-&gt;register_cleanup(\&amp;do_cleanup);
  sub do_cleanup{ #some clean-up code here }</pre>
        </td>
	    
      </tr>
    </table>
    <P>
But when a long term process needs to be spawned, there is not much choice,
but to use <CODE>fork().</CODE> We cannot just run this long term process
within Apache process, since it'll first keep the Apache process busy,
instead of letting it do the job it was designed for. And second, if Apache
will be stopped the long term process might be terminated as well, unless
coded properly to detach from Apache processes group.

<P>
In the following sections we are going to discuss how to properly spawn new
processes under mod_perl.

<P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H3><A NAME="Forking_a_New_Process">Forking a New Process</A></H3></CENTER>
<P>
This is a typical way to call <CODE>fork()</CODE> under mod_perl:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  defined (my $kid = fork) or die &quot;Cannot fork: $!\n&quot;;
  if ($kid) {
    # Parent runs this block
  } else {
    # Child runs this block
    # some code comes here
    CORE::exit(0);
  }
  # possibly more code here usually run by the parent</pre>
        </td>
	    
      </tr>
    </table>
    <P>
When using <CODE>fork(),</CODE> you should check its return value, since if
it returns <CODE>undef</CODE> it means that the call was unsuccessful and no process was spawned.
Something that can happen when the system is running too many processes and
cannot spawn new ones.

<P>
When the process is successfully forked--the parent receives the PID of the
newly spawned child as a returned value of the <CODE>fork()</CODE> call and
the child receives 0. Now the program splits into two. In the above example
the code inside the first block after <EM>if</EM> will be executed by the parent and the code inside the first block after <EM>else</EM> will be executed by the child process.

<P>
It's important not to forget to explicitly call <CODE>exit()</CODE> at the
end of the child code when forking. Since if you don't and there is some
code outside the <EM>if/else block</EM>, the child process will execute it as well. But under mod_perl there is
another nuance--you must use
<CODE>CORE::exit()</CODE> and not <CODE>exit()</CODE>, which would be automatically overriden by <CODE>Apache::exit()</CODE> if used in conjunction with
<CODE>Apache::Registry</CODE> and similar modules. And we want the spawned process to quit when its work
is done, otherwise it'll just stay alive use resources and do nothing.

<P>
The parent process usually completes its execution path and enters the pool
of free servers to wait for a new assignment. If the execution path is to
be aborted earlier for some reason one should use Apache::exit() or
<CODE>die(),</CODE> in the case of <CODE>Apache::Registry</CODE> or
<CODE>Apache::PerlRun</CODE> handlers a simple <CODE>exit()</CODE> will do the right thing.

<P>
The child shares with parent its memory pages until it has to modify some
of them, which triggers a <EM>copy-on-write</EM> process which copies these pages to the child's domain before the child is
allowed to modify them. But this all happens afterwards. At the moment the
<CODE>fork()</CODE> call executed, the only work to be done before the
child process goes on its separate way is setting up the page tables for
the virtual memory, which imposes almost no delay at all.

<P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H3><A NAME="Freeing_the_Parent_Process">Freeing the Parent Process</A></H3></CENTER>
<P>
In the child code you must also close all the pipes to the connection
socket that were opened by the parent process (i.e. <CODE>STDIN</CODE> and
<CODE>STDOUT</CODE>) and inherited by the child, so the parent will be able to complete the
request and free itself for serving other requests. If you need the <CODE>STDIN</CODE> and/or <CODE>STDOUT</CODE> streams you should re-open them. You may need to close or re-open the <CODE>STDERR</CODE> filehandle. It's opened to append to the <EM>error_log</EM> file as inherited from its parent, so chances are that you will want to
leave it untouched.

<P>
Under mod_perl, the spawned process also inherits the file descriptor
that's tied to the socket through which all the communications between the
server and the client happen. Therefore we need to free this stream in the
forked process. If we don't do that, the server cannot be restarted while
the spawned process is still running. If an attempt is made to restart the
server you will get the following error:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  [Mon Dec 11 19:04:13 2000] [crit] 
  (98)Address already in use: make_sock:
    could not bind to address 127.0.0.1 port 8000</pre>
        </td>
	    
      </tr>
    </table>
    <P>
<CODE>Apache::SubProcess</CODE> comes to help and provides a method <CODE>cleanup_for_exec()</CODE> which
takes care of closing this file descriptor.

<P>
So the simplest way is to freeing the parent process is to close all three
STD* streams if we don't need them and untie the Apache socket. In addition
you may want to change process' current directory to <EM>/</EM> so the forked process won't keep the mounted partition busy, if this is to
be unmounted at a later time. To summarize all this issues, here is an
example of the fork that takes care of freeing the parent process.

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  use Apache::SubProcess;
  defined (my $kid = fork) or die &quot;Cannot fork: $!\n&quot;;
  if ($kid) {
    # Parent runs this block
  } else {
    # Child runs this block
      $r-&gt;cleanup_for_exec(); # untie the socket
      chdir '/' or die &quot;Can't chdir to /: $!&quot;;
      close STDIN;
      close STDOUT;
      close STDERR;
  
    # some code comes here
  
      CORE::exit(0);
  }
  # possibly more code here usually run by the parent</pre>
        </td>
	    
      </tr>
    </table>
    <P>
Of course between the freeing the parent code and child process termination
the real code is to be placed.

<P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H3><A NAME="Detaching_the_Forked_Process">Detaching the Forked Process</A></H3></CENTER>
<P>
Now what happens if the forked process is running and we decided that we
need to restart the web-server? This forked process will be aborted, since
when parent process will die during the restart it'll kill its child
processes as well. In order to avoid this we need to detach the process
from its parent session, by opening a new session with help of
<CODE>setsid()</CODE> system call, provided by the <CODE>POSIX</CODE> module:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  use POSIX 'setsid';
  
  defined (my $kid = fork) or die &quot;Cannot fork: $!\n&quot;;
  if ($kid) {
    # Parent runs this block
  } else {
    # Child runs this block
      setsid or die &quot;Can't start a new session: $!&quot;;
      ...
  }</pre>
        </td>
	    
      </tr>
    </table>
    <P>
Now the spawned child process has a life of its own, and it doesn't depend
on the parent anymore.

<P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H3><A NAME="Avoiding_Zombie_Processes">Avoiding Zombie Processes</A></H3></CENTER>
<P>
Now let's talk about zombie processes.

<P>
Normally, every process has its parent. Many processes are children of the <CODE>init</CODE> process, whose <CODE>PID</CODE> is <CODE>1</CODE>. When you fork a process you must <CODE>wait()</CODE> or
<CODE>waitpid()</CODE> for it to finish. If you don't <CODE>wait()</CODE>
for it, it becomes a zombie.

<P>
A zombie is a process that doesn't have a parent. When the child quits, it
reports the termination to its parent. If no parent <CODE>wait()s</CODE> to
collect the exit status of the child, it gets <EM>"confused"</EM> and becomes a ghost process, that can be seen as a process, but not killed.
It will be killed only when you stop the parent process that spawned it!

<P>
Generally the <CODE>ps(1)</CODE> utility displays these processes with the
<CODE>&lt;defunc&gt;</CODE> tag, and you will see the zombies counter increment when doing
<CODE>top().</CODE> These zombie processes can take up system resources and
are generally undesirable.

<P>
So the proper way to do a fork is:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  my $r = shift;
  $r-&gt;send_http_header('text/plain');
  
  defined (my $kid = fork) or die &quot;Cannot fork: $!&quot;;
  if ($kid) {
    waitpid($kid,0);
    print &quot;Parent has finished\n&quot;;
  } else {
      # do something
      CORE::exit(0);
  }</pre>
        </td>
	    
      </tr>
    </table>
    <P>
In most cases the only reason you would want to fork is when you need to
spawn a process that will take a long time to complete. So if the Apache
process that spawns this new child process has to wait for it to finish,
you have gained nothing. You can neither wait for its completion (because
you don't have the time to), nor continue because you will get yet another
zombie process. This is called a blocking call, since the process is
blocked to do anything else before this call gets completed.

<P>
The simplest solution is to ignore your dead children. Just add this line
before the <CODE>fork()</CODE> call:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  $SIG{CHLD} = 'IGNORE';</pre>
        </td>
	    
      </tr>
    </table>
    <P>
When you set the <CODE>CHLD</CODE> (<CODE>SIGCHLD</CODE> in C) signal handler to
<CODE>'IGNORE'</CODE>, all the processes will be collected by the <CODE>init</CODE> process and are therefore prevented from becoming zombies. This doesn't
work everywhere, however. It proved to work at least on Linux OS.

<P>
Note that you cannot localize this setting with <CODE>local()</CODE>. If you do, it won't have the desired effect.

<P>
[META: Can anyone explain why localization doesn't work?]

<P>
So now the code would look like this:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  my $r = shift;
  $r-&gt;send_http_header('text/plain');
  
  $SIG{CHLD} = 'IGNORE';
  
  defined (my $kid = fork) or die &quot;Cannot fork: $!\n&quot;;
  if ($kid) {
    print &quot;Parent has finished\n&quot;;
  } else {
      # do something time-consuming
      CORE::exit(0);
  }</pre>
        </td>
	    
      </tr>
    </table>
    <P>
Note that <CODE>waitpid()</CODE> call has gone. The $SIG{CHLD}&nbsp;=&nbsp;'IGNORE';
statement protects us from zombies, as explained above.

<P>
Another, more portable, but slightly more expensive solution is to use a
double fork approach.

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  my $r = shift;
  $r-&gt;send_http_header('text/plain');
  
  defined (my $kid = fork) or die &quot;Cannot fork: $!\n&quot;;
  if ($kid) {
    waitpid($kid,0);
  } else {
    defined (my $grandkid = fork) or die &quot;Kid cannot fork: $!\n&quot;;
    if ($grandkid) {
      CORE::exit(0);
    } else {
      # code here
      # do something long lasting
      CORE::exit(0);
    }
  }</pre>
        </td>
	    
      </tr>
    </table>
    <P>
Grandkid becomes a <EM>"child of init"</EM>, i.e. the child of the process whose PID is 1.

<P>
Note that the previous two solutions do allow you to know the exit status
of the process, but in our example we didn't care about it.

<P>
Another solution is to use a different <EM>SIGCHLD</EM> handler:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  use POSIX 'WNOHANG';
  $SIG{CHLD} = sub { while( waitpid(-1,WNOHANG)&gt;0 ) {} };</pre>
        </td>
	    
      </tr>
    </table>
    <P>
Which is useful when you <CODE>fork()</CODE> more than one process. The
handler could call <CODE>wait()</CODE> as well, but for a variety of
reasons involving the handling of stopped processes and the rare event in
which two children exit at nearly the same moment, the best technique is to
call <CODE>waitpid()</CODE> in a tight loop with a first argument of <CODE>-1</CODE> and a second argument of <CODE>WNOHANG</CODE>. Together these arguments tell <CODE>waitpid()</CODE> to reap the next
child that's available, and prevent the call from blocking if there happens
to be no child ready for reaping. The handler will loop until
<CODE>waitpid()</CODE> returns a negative number or zero, indicating that
no more reapable children remain.

<P>
While you test and debug your code that uses one of the above examples, You
might want to write some debug information to the error_log file so you
know what happens.

<P>
Read <EM>perlipc</EM> manpage for more information about signal handlers.

<P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H3><A NAME="A_Complete_Fork_Example">A Complete Fork Example</A></H3></CENTER>
<P>
Now let's put all the bits of code together and show a well written fork
code that solves all the problems discussed so far. We will use an
&lt;Apache::Registry&gt; script for this purpose:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  proper_fork1.pl
  ---------------
  use strict;
  use POSIX 'setsid';
  use Apache::SubProcess;
  
  my $r = shift;
  $r-&gt;send_http_header(&quot;text/plain&quot;);
  
  $SIG{CHLD} = 'IGNORE';
  defined (my $kid = fork) or die &quot;Cannot fork: $!\n&quot;;
  if ($kid) {
    print &quot;Parent $$ has finished, kid's PID: $kid\n&quot;;
  } else {
      $r-&gt;cleanup_for_exec(); # untie the socket
      chdir '/'                or die &quot;Can't chdir to /: $!&quot;;
      open STDIN, '/dev/null'  or die &quot;Can't read /dev/null: $!&quot;;
      open STDOUT, '&gt;/dev/null'
          or die &quot;Can't write to /dev/null: $!&quot;;
      open STDERR, '&gt;/tmp/log' or die &quot;Can't write to /tmp/log: $!&quot;;
      setsid or die &quot;Can't start a new session: $!&quot;;
  
      my $oldfh = select STDERR;
      local $| = 1;
      select $oldfh;
      warn &quot;started\n&quot;;
      # do something time-consuming
      sleep 1, warn &quot;$_\n&quot; for 1..20;
      warn &quot;completed\n&quot;;
  
      CORE::exit(0); # terminate the process
  }</pre>
        </td>
	    
      </tr>
    </table>
    <P>
The script starts with the usual declaration of the strict mode, loading
the <CODE>POSIX</CODE> and <CODE>Apache::SubProcess</CODE> modules and importing of the <CODE>setsid()</CODE> symbol from the <CODE>POSIX</CODE> package.

<P>
The HTTP header is sent next, with the <EM>Content-type</EM> of
<EM>text/plain</EM>. The parent process gets ready to ignore the child, to avoid zombies and
the fork is called.

<P>
The program gets its personality split after fork and the if conditional
evaluates to a true value for the parent process, and to a false value for
the child process, therefore the first block is executed by the parent and
the second by the child.

<P>
The parent process announces his PID and the PID of the spawned process and
finishes its block. If there will be any code outside it will be executed
by the parent as well.

<P>
The child process starts its code by disconnecting from the socket,
changing its current directory to <CODE>/</CODE>, opening the STDIN and STDOUT streams to <EM>/dev/null</EM>, which in effect closes them both before opening. In fact in this example
we don't need neither of these, so we could just <CODE>close()</CODE> both.
The child process completes its disengagement from the parent process by
opening the STDERR stream to <EM>/tmp/log</EM>, so it could write there, and creating a new session with help of
<CODE>setsid().</CODE> Now the child process has nothing to do with the
parent process and can do the actual processing that it has to do. In our
example it performs a simple series of warnings, which are logged into
<EM>/tmp/log</EM>:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>      my $oldfh = select STDERR;
      local $| = 1;
      select $oldfh;
      warn &quot;started\n&quot;;
      # do something time-consuming
      sleep 1, warn &quot;$_\n&quot; for 1..20;
      warn &quot;completed\n&quot;;</pre>
        </td>
	    
      </tr>
    </table>
    <P>
The localized setting of <CODE>$|=1</CODE> unbuffers the STDERR stream, so we can immediately see the debug output
generated by the program. In fact this setting is not required when the
output is generated by <CODE>warn().</CODE>

<P>
Finally the child process terminates by calling:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>      CORE::exit(0);</pre>
        </td>
	    
      </tr>
    </table>
    <P>
which make sure that it won't get out of the block and run some code that
it's not supposed to run.

<P>
This code example will allow you to verify that indeed the spawned child
process has its own life, and its parent is free as well. Simply issue a
request that will run this script, watch that the warnings are started to
be written into the <EM>/tmp/log</EM> file and issue a complete server stop and start. If everything is correct,
the server will successfully restart and the long term process will still
be running. You will know that it's still running, if the warnings will
still be printed into the <EM>/tmp/log</EM> file. You may need to raise the number of warnings to do above 20, to make
sure that you don't miss the end of the run.

<P>
If there are only 5 warnings to be printed, you should see the following
output in this file:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  started
  1
  2
  3
  4
  5
  completed</pre>
        </td>
	    
      </tr>
    </table>
    <P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H3><A NAME="Starting_a_Long_Running_External">Starting a Long Running External Program</A></H3></CENTER>
<P>
But what happens if we cannot just run a Perl code from the spawned process
and we have a compiled utility, i.e. a program written in C. Or we have a
Perl program which cannot be easily converted into a module, and thus
called as a function. Of course in this case we have to use
<CODE>system(),</CODE> <CODE>exec(),</CODE> <CODE>qx()</CODE> or
&lt;``&gt;(back ticks) to start it.

<P>
When using any of these methods and when the <EM>Taint</EM> mode is enabled, we must at least add the following code to untaint the <EM>PATH</EM>
environment variable and delete a few other insecure environment variables.
This information can be found in the <EM>perlsec</EM> manpage.

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  $ENV{'PATH'} = '/bin:/usr/bin';
  delete @ENV{'IFS', 'CDPATH', 'ENV', 'BASH_ENV'};</pre>
        </td>
	    
      </tr>
    </table>
    <P>
Now all we have to do is to reuse the code from the previous section.

<P>
First we move the core program into the <EM>external.pl</EM> file, add the shebang first line so the program will be executed by Perl,
tell the program to run under <EM>Taint</EM> mode (-T) and possibly enable the
<EM>warnings</EM> mode (-w) and make it executable:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  external.pl
  -----------
  #!/usr/bin/perl -Tw
  
  open STDIN, '/dev/null'  or die &quot;Can't read /dev/null: $!&quot;;
  open STDOUT, '&gt;/dev/null'
      or die &quot;Can't write to /dev/null: $!&quot;;
  open STDERR, '&gt;/tmp/log' or die &quot;Can't write to /tmp/log: $!&quot;;
  
  my $oldfh = select STDERR;
  local $| = 1;
  select $oldfh;
  warn &quot;started\n&quot;;
  # do something time-consuming
  sleep 1, warn &quot;$_\n&quot; for 1..20;
  warn &quot;completed\n&quot;;</pre>
        </td>
	    
      </tr>
    </table>
    <P>
Now we replace the code that moved into the external program with
<CODE>exec()</CODE> to call it:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  proper_fork_exec.pl
  -------------------
  use strict;
  use POSIX 'setsid';
  use Apache::SubProcess;
  
  $ENV{'PATH'} = '/bin:/usr/bin';
  delete @ENV{'IFS', 'CDPATH', 'ENV', 'BASH_ENV'};
  
  my $r = shift;
  $r-&gt;send_http_header(&quot;text/html&quot;);
  
  $SIG{CHLD} = 'IGNORE';
  
  defined (my $kid = fork) or die &quot;Cannot fork: $!\n&quot;;
  if ($kid) {
    print &quot;Parent has finished, kid's PID: $kid\n&quot;;
  } else {
      $r-&gt;cleanup_for_exec(); # untie the socket
      chdir '/'                or die &quot;Can't chdir to /: $!&quot;;
      open STDIN, '/dev/null'  or die &quot;Can't read /dev/null: $!&quot;;
      open STDOUT, '&gt;/dev/null'
          or die &quot;Can't write to /dev/null: $!&quot;;
      open STDERR, '&gt;&amp;STDOUT'  or die &quot;Can't dup stdout: $!&quot;;
      setsid or die &quot;Can't start a new session: $!&quot;;
  
      exec &quot;/home/httpd/perl/external.pl&quot; or die &quot;Cannot execute exec: $!&quot;;
  }</pre>
        </td>
	    
      </tr>
    </table>
    <P>
Notice that <CODE>exec()</CODE> never returns unless it fails to start the
process. Therefore you shouldn't put any code after <CODE>exec()--it</CODE>
will be not executed in the case of success. Use <CODE>system()</CODE> or
back-ticks instead if you want to continue doing other things in the
process. But then you probably will want to terminate the process after the
program has finished. So you will have to write:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>      system &quot;/home/httpd/perl/external.pl&quot; or die &quot;Cannot execute system: $!&quot;;
      CORE::exit(0);</pre>
        </td>
	    
      </tr>
    </table>
    <P>
Another important nuance is that we have to close all STD* stream in the
forked process, even if the called program does that.

<P>
If the external program is written in Perl you may pass complicated data
stuctures to it using one of the methods to serialize Perl data and then to
restore it. The <CODE>Storable</CODE> and <CODE>FreezeThaw</CODE> modules come handy. Let's say that we have program <EM>master.pl</EM> calling program
<EM>slave.pl</EM>:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  master.pl
  ---------
  # we are within the mod_perl code
  use Storable ();
  my @params = (foo =&gt; 1, bar =&gt; 2);
  my $params = Storable::freeze(\@params);
  exec &quot;./slave.pl&quot;, $params or die &quot;Cannot execute exec: $!&quot;;</pre>
        </td>
	    
      </tr>
    </table>
    <P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  slave.pl
  --------
  #!/usr/bin/perl -w
  use Storable ();
  my @params = @ARGV ? @{ Storable::thaw(shift)||[] } : ();
  # do something</pre>
        </td>
	    
      </tr>
    </table>
    <P>
As you can see, <EM>master.pl</EM> serializes the <CODE>@params</CODE> data structure with <CODE>Storable::freeze</CODE> and passes it to <EM>slave.pl</EM> as a single argument. <EM>slave.pl</EM> restores the it with <CODE>Storable::thaw</CODE>, by shifting the first value of the <CODE>ARGV</CODE> array if available. The
<CODE>FreezeThaw</CODE> module does a very similar thing.

<P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H3><A NAME="Starting_a_Short_Running_Externa">Starting a Short Running External Program</A></H3></CENTER>
<P>
Sometimes you need to call an external program and you cannot continue
before this program completes its run and optionally returns some result.
In this case the fork solution doesn't help. But we have a few ways to
execute this program. First using <CODE>system():</CODE>

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  system &quot;perl -e 'print 5+5'&quot;</pre>
        </td>
	    
      </tr>
    </table>
    <P>
We believe that you will never call the perl interperter for doing this
simple calculation, but for the sake of a simple example it's good enough.

<P>
The problem with this approach is that we cannot get the results printed to <CODE>STDOUT</CODE>, and that's where back-ticks or <CODE>qx()</CODE> come to help. If you use
either:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  my $result = `perl -e 'print 5+5'`;</pre>
        </td>
	    
      </tr>
    </table>
    <P>
or:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  my $result = qx{perl -e 'print 5+5'};</pre>
        </td>
	    
      </tr>
    </table>
    <P>
the whole output of the external program will be stored in the
<CODE>$result</CODE> variable.

<P>
Of course you can use other solutions, like opening a pipe (<CODE>|</CODE> to the program) if you need to submit many arguments and more evolved
solutions provided by other Perl modules like <CODE>IPC::Open2</CODE> which allows to open a process for both reading and writing.

<P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H3><A NAME="Executing_system_or_exec_in_">Executing system() or exec() in the Right Way</A></H3></CENTER>
<P>
The <CODE>exec()</CODE> and <CODE>system()</CODE> system calls behave
identically in the way they spawn a program. For example let's use
<CODE>system()</CODE> as an example. Consider the following code:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  system(&quot;echo&quot;,&quot;Hi&quot;);</pre>
        </td>
	    
      </tr>
    </table>
    <P>
Perl will use the first argument as a program to execute, find
<CODE>/bin/echo</CODE> along the search path, invoke it directly and pass the
<EM>Hi</EM> string as an argument.

<P>
Perl's <CODE>system()</CODE> is <STRONG>not</STRONG> the <CODE>system(3)</CODE> call [C-library]. This is how the arguments to <CODE>system()</CODE> get
interpreted. When there is a single argument to <CODE>system(),</CODE>
it'll be checked for for having shell metacharacters first (like <CODE>*</CODE>,<CODE>?</CODE>), and if there are any--Perl interpreter invokes a real shell program (/bin/sh&nbsp;-c on Unix platforms). If you pass a list of arguments to
<CODE>system(),</CODE> they will be not checked for metacharacters, but
split into words if required and passed directly to the C-level <CODE>execvp()</CODE> system call, which is more efficient. That's a <EM>very</EM> nice optimization. In other words, only if you do:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  system &quot;sh -c 'echo *'&quot;</pre>
        </td>
	    
      </tr>
    </table>
    <P>
will the operating system actually <CODE>exec()</CODE> a copy of <CODE>/bin/sh</CODE> to parse your command. But even then since <EM>sh</EM> is almost certainly already running somewhere, the system will notice that
(via the disk inode reference) and replace your virtual memory page table
with one pointing to the existing program code plus your data space, thus
will not create this overhead.

<P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H2><A NAME="OS_Specific_Parameters_for_Proxy">OS Specific Parameters for Proxying</A></H2></CENTER>
<P>
Most of the mod_perl enabled servers use a proxy front-end server. This is
done in order to avoid serving static objects, and also so that generated
output which might be received by slow clients does not cause the heavy but
very fast mod_perl servers from idly waiting.

<P>
There are very important OS parameters that you might want to change in
order to improve the server performance. This topic is discussed in the
section: <A HREF="././scenario.html#Setting_the_Buffering_Limits_on_">Setting the Buffering Limits on Various OSes</A>



<P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H1><A NAME="Performance_Tuning_by_Tweaking_A">Performance Tuning by Tweaking Apache Configuration</A></H1></CENTER>
<P>
Correct configuration of the <CODE>MinSpareServers</CODE>, <CODE>MaxSpareServers</CODE>,
<CODE>StartServers</CODE>, <CODE>MaxClients</CODE>, and <CODE>MaxRequestsPerChild</CODE> parameters is very important. There are no defaults. If they are too low,
you will under-use the system's capabilities. If they are too high, the
chances are that the server will bring the machine to its knees.

<P>
All the above parameters should be specified on the basis of the resources
you have. With a plain apache server, it's no big deal if you run many
servers since the processes are about 1Mb and don't eat a lot of your RAM.
Generally the numbers are even smaller with memory sharing. The situation
is different with mod_perl. I have seen mod_perl processes of 20Mb and
more. Now if you have <CODE>MaxClients</CODE>
set to 50: 50x20Mb = 1Gb. Do you have 1Gb of RAM? Maybe not. So how do you
tune the parameters? Generally by trying different combinations and
benchmarking the server. Again mod_perl processes can be of much smaller
size with memory sharing.

<P>
Before you start this task you should be armed with the proper weapon. You
need the <STRONG>crashme</STRONG> utility, which will load your server with the mod_perl scripts you possess.
You need it to have the ability to emulate a multiuser environment and to
emulate the behavior of multiple clients calling the mod_perl scripts on
your server simultaneously. While there are commercial solutions, you can
get away with free ones which do the same job. You can use the
<A HREF="././performance.html#Configuration_Tuning_with_Apache">ApacheBench</A>  <STRONG><CODE>ab</CODE></STRONG> utility which comes with the Apache distribution, the <A HREF="././performance.html#the_crashme_Script">crashme script</A> which uses
<CODE>LWP::Parallel::UserAgent</CODE>,
<A HREF="././performance.html#httperf">httperf</A> or
<A HREF="././performance.html#http_load">http_load</A>.

<P>
It is important to make sure that you run the load generator (the client
which generates the test requests) on a system that is more powerful than
the system being tested. After all we are trying to simulate Internet
users, where many users are trying to reach your service at once. Since the
number of concurrent users can be quite large, your testing machine must be
very powerful and capable of generating a heavy load. Of course you should
not run the clients and the server on the same machine. If you do, your
test results would be invalid. Clients will eat CPU and memory that should
be dedicated to the server, and vice versa.

<P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H2><A NAME="Configuration_Tuning_with_Apache">Configuration Tuning with ApacheBench</A></H2></CENTER>
<P>
We are going to use <CODE>ApacheBench</CODE> (<CODE>ab</CODE>) utility to tune our server's configuration. We will simulate 10 users
concurrently requesting a very light script at
<CODE>http://www.example.com/perl/access/access.cgi</CODE>. Each simulated user makes 10 requests.

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  % ./ab -n 100 -c 10 <A HREF="http://www.example.com/perl/access/access.cgi">http://www.example.com/perl/access/access.cgi</A></pre>
        </td>
	    
      </tr>
    </table>
    <P>
The results are:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  Document Path:          /perl/access/access.cgi
  Document Length:        16 bytes
  
  Concurrency Level:      10
  Time taken for tests:   1.683 seconds
  Complete requests:      100
  Failed requests:        0
  Total transferred:      16100 bytes
  HTML transferred:       1600 bytes
  Requests per second:    59.42
  Transfer rate:          9.57 kb/s received
  
  Connnection Times (ms)
                min   avg   max
  Connect:        0    29   101
  Processing:    77   124  1259
  Total:         77   153  1360</pre>
        </td>
	    
      </tr>
    </table>
    <P>
The only numbers we really care about are:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  Complete requests:      100
  Failed requests:        0
  Requests per second:    59.42</pre>
        </td>
	    
      </tr>
    </table>
    <P>
Let's raise the request load to 100 x 10 (10 users, each makes 100
requests):

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  % ./ab -n 1000 -c 10  <A HREF="http://www.example.com/perl/access/access.cgi">http://www.example.com/perl/access/access.cgi</A>
  Concurrency Level:      10
  Complete requests:      1000
  Failed requests:        0
  Requests per second:    139.76</pre>
        </td>
	    
      </tr>
    </table>
    <P>
As expected, nothing changes -- we have the same 10 concurrent users. Now
let's raise the number of concurrent users to 50:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  % ./ab -n 1000 -c 50  <A HREF="http://www.example.com/perl/access/access.cgi">http://www.example.com/perl/access/access.cgi</A>
  Complete requests:      1000
  Failed requests:        0
  Requests per second:    133.01</pre>
        </td>
	    
      </tr>
    </table>
    <P>
We see that the server is capable of serving 50 concurrent users at 133
requests per second! Let's find the upper limit. Using <CODE>-n
10000 -c 1000</CODE> failed to get results (Broken Pipe?). Using <CODE>-n 10000
-c 500</CODE> resulted in 94.82 requests per second. The server's performance went down
with the high load.

<P>
The above tests were performed with the following configuration:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  MinSpareServers 8
  MaxSpareServers 6
  StartServers 10
  MaxClients 50
  MaxRequestsPerChild 1500</pre>
        </td>
	    
      </tr>
    </table>
    <P>
Now let's kill each child after it serves a single request. We will use the
following configuration:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  MinSpareServers 8
  MaxSpareServers 6
  StartServers 10
  MaxClients 100
  MaxRequestsPerChild 1</pre>
        </td>
	    
      </tr>
    </table>
    <P>
Simulate 50 users each generating a total of 20 requests:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  % ./ab -n 1000 -c 50  <A HREF="http://www.example.com/perl/access/access.cgi">http://www.example.com/perl/access/access.cgi</A></pre>
        </td>
	    
      </tr>
    </table>
    <P>
The benchmark timed out with the above configuration.... I watched the
output of <STRONG><CODE>ps</CODE></STRONG> as I ran it, the parent process just wasn't capable of respawning the
killed children at that rate. When I raised the
<CODE>MaxRequestsPerChild</CODE> to 10, I got 8.34 requests per second. Very bad - 18 times slower! You
can't benchmark the importance of the
<CODE>MinSpareServers</CODE>, <CODE>MaxSpareServers</CODE> and <CODE>StartServers</CODE> with this kind of test.

<P>
Now let's reset <CODE>MaxRequestsPerChild</CODE> to 1500, but reduce
<CODE>MaxClients</CODE> to 10 and run the same test:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  MinSpareServers 8
  MaxSpareServers 6
  StartServers 10
  MaxClients 10
  MaxRequestsPerChild 1500</pre>
        </td>
	    
      </tr>
    </table>
    <P>
I got 27.12 requests per second, which is better but still 4-5 times
slower. (I got 133 with <CODE>MaxClients</CODE> set to 50.)

<P>
<STRONG>Summary:</STRONG> I have tested a few combinations of the server configuration variables (<CODE>MinSpareServers</CODE>, <CODE>MaxSpareServers</CODE>,
<CODE>StartServers</CODE>, <CODE>MaxClients</CODE> and <CODE>MaxRequestsPerChild</CODE>). The results I got are as follows:

<P>
<CODE>MinSpareServers</CODE>, <CODE>MaxSpareServers</CODE> and <CODE>StartServers</CODE> are only important for user response times. Sometimes users will have to
wait a bit.

<P>
The important parameters are <CODE>MaxClients</CODE> and <CODE>MaxRequestsPerChild</CODE>.
<CODE>MaxClients</CODE> should be not too big, so it will not abuse your machine's memory
resources, and not too small, for if it is your users will be forced to
wait for the children to become free to serve them.
<CODE>MaxRequestsPerChild</CODE> should be as large as possible, to get the full benefit of mod_perl, but
watch your server at the beginning to make sure your scripts are not
leaking memory, thereby causing your server (and your service) to die very
fast.

<P>
Also it is important to understand that we didn't test the response times
in the tests above, but the ability of the server to respond under a heavy
load of requests. If the test script was heavier, the numbers would be
different but the conclusions very similar.

<P>
The benchmarks were run with:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  HW: RS6000, 1Gb RAM
  SW: AIX 4.1.5 . mod_perl 1.16, apache 1.3.3
  Machine running only mysql, httpd docs and mod_perl servers.
  Machine was _completely_ unloaded during the benchmarking.</pre>
        </td>
	    
      </tr>
    </table>
    <P>
After each server restart when I changed the server's configuration, I made
sure that the scripts were preloaded by fetching a script at least once for
every child.

<P>
It is important to notice that none of the requests timed out, even if it
was kept in the server's queue for more than a minute! That is the way <STRONG>ab</STRONG> works, which is OK for testing purposes but will be unacceptable in the
real world - users will not wait for more than five to ten seconds for a
request to complete, and the client (i.e. the browser) will time out in a
few minutes.

<P>
Now let's take a look at some real code whose execution time is more than a
few milliseconds. We will do some real testing and collect the data into
tables for easier viewing.

<P>
I will use the following abbreviations:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  NR    = Total Number of Request
  NC    = Concurrency
  MC    = MaxClients
  MRPC  = MaxRequestsPerChild
  RPS   = Requests per second</pre>
        </td>
	    
      </tr>
    </table>
    <P>
Running a mod_perl script with lots of mysql queries (the script under test
is mysqld limited)
(http://www.example.com/perl/access/access.cgi?do_sub=query_form), with the
configuration:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  MinSpareServers        8
  MaxSpareServers       16
  StartServers          10
  MaxClients            50
  MaxRequestsPerChild 5000</pre>
        </td>
	    
      </tr>
    </table>
    <P>
gives us:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>     NR   NC    RPS     comment
  ------------------------------------------------
     10   10    3.33    # not a reliable figure
    100   10    3.94    
   1000   10    4.62    
   1000   50    4.09    </pre>
        </td>
	    
      </tr>
    </table>
    <P>
<STRONG>Conclusions:</STRONG> Here I wanted to show that when the application is slow (not due to perl
loading, code compilation and execution, but limited by some external
operation) it almost does not matter what load we place on the server. The
RPS (Requests per second) is almost the same. Given that all the requests
have been served, you have the ability to queue the clients, but be aware
that anything that goes into the queue means a waiting client and a client
(browser) that might time out!

<P>
Now we will benchmark the same script without using the mysql (code limited
by perl only): (http://www.example.com/perl/access/access.cgi), it's the
same script but it just returns the HTML form, without making SQL queries.

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  MinSpareServers        8
  MaxSpareServers       16
  StartServers          10
  MaxClients            50
  MaxRequestsPerChild 5000</pre>
        </td>
	    
      </tr>
    </table>
    <P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>     NR   NC      RPS   comment
  ------------------------------------------------
     10   10    26.95   # not a reliable figure
    100   10    30.88   
   1000   10    29.31
   1000   50    28.01
   1000  100    29.74
  10000  200    24.92
 100000  400    24.95</pre>
        </td>
	    
      </tr>
    </table>
    <P>
<STRONG>Conclusions:</STRONG> This time the script we executed was pure perl (not limited by I/O or
mysql), so we see that the server serves the requests much faster. You can
see the number of requests per second is almost the same for any load, but
goes lower when the number of concurrent clients goes beyond <CODE>MaxClients</CODE>. With 25 RPS, the machine simulating a load of 400 concurrent clients will
be served in 16 seconds. To be more realistic, assuming a maximum of 100
concurrent clients and 30 requests per second, the client will be served in
3.5 seconds. Pretty good for a highly loaded server.

<P>
Now we will use the server to its full capacity, by keeping all
<CODE>MaxClients</CODE> clients alive all the time and having a big
<CODE>MaxRequestsPerChild</CODE>, so that no child will be killed during the benchmarking.

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  MinSpareServers       50
  MaxSpareServers       50
  StartServers          50
  MaxClients            50
  MaxRequestsPerChild 5000
  
     NR   NC      RPS   comment
  ------------------------------------------------
    100   10    32.05
   1000   10    33.14
   1000   50    33.17
   1000  100    31.72
  10000  200    31.60</pre>
        </td>
	    
      </tr>
    </table>
    <P>
Conclusion: In this scenario there is no overhead involving the parent
server loading new children, all the servers are available, and the only
bottleneck is contention for the CPU.

<P>
Now we will change <CODE>MaxClients</CODE> and watch the results: Let's reduce
<CODE>MaxClients</CODE> to 10.

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  MinSpareServers        8
  MaxSpareServers       10
  StartServers          10
  MaxClients            10
  MaxRequestsPerChild 5000
  
     NR   NC      RPS   comment
  ------------------------------------------------
     10   10    23.87   # not a reliable figure
    100   10    32.64 
   1000   10    32.82
   1000   50    30.43
   1000  100    25.68
   1000  500    26.95
   2000  500    32.53</pre>
        </td>
	    
      </tr>
    </table>
    <P>
<STRONG>Conclusions:</STRONG> Very little difference! Ten servers were able to serve almost with the same
throughput as 50 servers. Why? My guess is because of CPU throttling. It
seems that 10 servers were serving requests 5 times faster than when we
worked with 50 servers. In that case, each child received its CPU time
slice five times less frequently. So having a big value for <CODE>MaxClients</CODE>, doesn't mean that the performance will be better. You have just seen the
numbers!

<P>
Now we will start drastically to reduce <CODE>MaxRequestsPerChild</CODE>:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  MinSpareServers        8
  MaxSpareServers       16
  StartServers          10
  MaxClients            50</pre>
        </td>
	    
      </tr>
    </table>
    <P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>     NR   NC    MRPC     RPS    comment
  ------------------------------------------------
    100   10      10    5.77 
    100   10       5    3.32
   1000   50      20    8.92
   1000   50      10    5.47
   1000   50       5    2.83
   1000  100      10    6.51</pre>
        </td>
	    
      </tr>
    </table>
    <P>
<STRONG>Conclusions:</STRONG> When we drastically reduce <CODE>MaxRequestsPerChild</CODE>, the performance starts to become closer to plain mod_cgi. 

<P>
Here are the numbers of this run with mod_cgi, for comparison:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  MinSpareServers        8
  MaxSpareServers       16
  StartServers          10
  MaxClients            50
  
     NR   NC    RPS     comment
  ------------------------------------------------
    100   10    1.12
   1000   50    1.14
   1000  100    1.13</pre>
        </td>
	    
      </tr>
    </table>
    <P>
<STRONG>Conclusion</STRONG>: mod_cgi is much slower. :) In the first test, when NR/NC was 100/10,
mod_cgi was capable of 1.12 requests per second. In the same circumstances,
mod_perl was capable of 32 requests per second, nearly 30 times faster! In
the first test each client waited about 100 seconds to be served. In the
second and third tests they waited 1000 seconds!

<P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H2><A NAME="Choosing_MaxClients">Choosing MaxClients</A></H2></CENTER>
<P>
The <CODE>MaxClients</CODE> directive sets the limit on the number of simultaneous requests that can be
supported. No more than this number of child server processes will be
created. To configure more than 256 clients, you must edit the <CODE>HARD_SERVER_LIMIT</CODE> entry in <CODE>httpd.h</CODE>
and recompile. In our case we want this variable to be as small as
possible, because in this way we can limit the resources used by the server
children. Since we can restrict each child's process size (see
<A HREF="././performance.html#Limiting_the_Size_of_the_Process">Limiting the size of the processes</A>), the calculation of <CODE>MaxClients</CODE> is pretty straightforward:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>               Total RAM Dedicated to the Webserver
  MaxClients = ------------------------------------
                     MAX child's process size</pre>
        </td>
	    
      </tr>
    </table>
    <P>
So if I have 400Mb left for the webserver to run with, I can set
<CODE>MaxClients</CODE> to be of 40 if I know that each child is limited to 10Mb of memory (e.g.
with
<A HREF="././performance.html#Limiting_the_Size_of_the_Process"><CODE>Apache::SizeLimit</CODE></A>).

<P>
You will be wondering what will happen to your server if there are more
concurrent users than <CODE>MaxClients</CODE> at any time. This situation is signified by the following warning message
in the <CODE>error_log</CODE>:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  [Sun Jan 24 12:05:32 1999] [error] server reached MaxClients setting,
  consider raising the MaxClients setting</pre>
        </td>
	    
      </tr>
    </table>
    <P>
There is no problem -- any connection attempts over the <CODE>MaxClients</CODE>
limit will normally be queued, up to a number based on the
<CODE>ListenBacklog</CODE> directive. When a child process is freed at the end of a different request,
the connection will be served.

<P>
It <STRONG>is an error</STRONG> because clients are being put in the queue rather than getting served
immediately, despite the fact that they do not get an error response. The
error can be allowed to persist to balance available system resources and
response time, but sooner or later you will need to get more RAM so you can
start more child processes. The best approach is to try not to have this
condition reached at all, and if you reach it often you should start to
worry about it.

<P>
It's important to understand how much real memory a child occupies. Your
children can share memory between them when the OS supports that. You must
take action to allow the sharing to happen - See <A HREF="././performance.html#Preloading_Perl_Modules_at_Serve">Preload Perl modules at server startup</A>. If you do this, the chances are that your <CODE>MaxClients</CODE> can be even higher. But it seems that it's not so simple to calculate the
absolute number. If you come up with a solution please let us know! If the
shared memory was of the same size throughout the child's life, we could
derive a much better formula:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>               Total_RAM + Shared_RAM_per_Child * (MaxClients - 1)
  MaxClients = ---------------------------------------------------
                              Max_Process_Size</pre>
        </td>
	    
      </tr>
    </table>
    <P>
which is:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>                    Total_RAM - Shared_RAM_per_Child
  MaxClients = ---------------------------------------
               Max_Process_Size - Shared_RAM_per_Child</pre>
        </td>
	    
      </tr>
    </table>
    <P>
Let's roll some calculations:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  Total_RAM            = 500Mb
  Max_Process_Size     =  10Mb
  Shared_RAM_per_Child =   4Mb</pre>
        </td>
	    
      </tr>
    </table>
    <P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>              500 - 4
 MaxClients = --------- = 82
               10 - 4</pre>
        </td>
	    
      </tr>
    </table>
    <P>
With no sharing in place

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>                 500
  MaxClients = --------- = 50
                 10</pre>
        </td>
	    
      </tr>
    </table>
    <P>
With sharing in place you can have 64% more servers without buying more
RAM.

<P>
If you improve sharing and keep the sharing level, let's say:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  Total_RAM            = 500Mb
  Max_Process_Size     =  10Mb
  Shared_RAM_per_Child =   8Mb
 
               500 - 8
  MaxClients = --------- = 246
                10 - 8</pre>
        </td>
	    
      </tr>
    </table>
    <P>
392% more servers! Now you can feel the importance of having as much shared
memory as possible.

<P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H2><A NAME="Choosing_MaxRequestsPerChild">Choosing MaxRequestsPerChild</A></H2></CENTER>
<P>
The <CODE>MaxRequestsPerChild</CODE> directive sets the limit on the number of requests that an individual child
server process will handle. After
<CODE>MaxRequestsPerChild</CODE> requests, the child process will die. If
<CODE>MaxRequestsPerChild</CODE> is 0, then the process will live forever.

<P>
Setting <CODE>MaxRequestsPerChild</CODE> to a non-zero limit solves some memory leakage problems caused by sloppy
programming practices, whereas a child process consumes more memory after
each request.

<P>
If left unbounded, then after a certain number of requests the children
will use up all the available memory and leave the server to die from
memory starvation. Note that sometimes standard system libraries leak
memory too, especially on OSes with bad memory management (e.g. Solaris 2.5
on x86 arch).

<P>
If this is your case you can set <CODE>MaxRequestsPerChild</CODE> to a small number. This will allow the system to reclaim the memory that a
greedy child process consumed, when it exits after
<CODE>MaxRequestsPerChild</CODE> requests.

<P>
But beware -- if you set this number too low, you will lose some of the
speed bonus you get from mod_perl. Consider using
<CODE>Apache::PerlRun</CODE> if this is the case.

<P>
Another approach is to use the
<A HREF="././performance.html#Limiting_the_Size_of_the_Process">Apache::SizeLimit</A> or the <A HREF="././performance.html#Keeping_the_Shared_Memory_Limit">Apache::GTopLimit</A>
modules. By using either of these modules you should be able to discontinue
using the <CODE>MaxRequestPerChild</CODE>, although for some developers, using both in combination does the job. In
addition the latter module allows you to kill any servers whose shared
memory size drops below a specified limit.

<P>
See also <A HREF="././performance.html#Preloading_Perl_Modules_at_Serve">Preload Perl modules at server startup</A> and <A HREF="././performance.html#Sharing_Memory">Sharing Memory</A>. 

<P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H2><A NAME="Choosing_MinSpareServers_MaxSpa">Choosing MinSpareServers, MaxSpareServers and StartServers</A></H2></CENTER>
<P>
With mod_perl enabled, it might take as much as 20 seconds from the time
you start the server until it is ready to serve incoming requests. This
delay depends on the OS, the number of preloaded modules and the process
load of the machine. It's best to set
<CODE>StartServers</CODE> and <CODE>MinSpareServers</CODE> to high numbers, so that if you get a high load just after the server has
been restarted the fresh servers will be ready to serve requests
immediately. With mod_perl, it's usually a good idea to raise all 3
variables higher than normal.

<P>
In order to maximize the benefits of mod_perl, you don't want to kill
servers when they are idle, rather you want them to stay up and available
to handle new requests immediately. I think an ideal configuration is to
set <CODE>MinSpareServers</CODE> and <CODE>MaxSpareServers</CODE> to similar values, maybe even the same. Having the <CODE>MaxSpareServers</CODE>
close to <CODE>MaxClients</CODE> will completely use all of your resources (if
<CODE>MaxClients</CODE> has been chosen to take the full advantage of the resources), but it'll
make sure that at any given moment your system will be capable of
responding to requests with the maximum speed (assuming that number of
concurrent requests is not higher than
<CODE>MaxClients</CODE>).

<P>
Let's try some numbers. For a heavily loaded web site and a dedicated
machine I would think of (note 400Mb is just for example):

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  Available to webserver RAM:   400Mb
  Child's memory size bounded:  10Mb
  MaxClients:                   400/10 = 40 (larger with mem sharing)
  StartServers:                 20
  MinSpareServers:              20
  MaxSpareServers:              35</pre>
        </td>
	    
      </tr>
    </table>
    <P>
However if I want to use the server for many other tasks, but make it
capable of handling a high load, I'd think of:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  Available to webserver RAM:   400Mb
  Child's memory size bounded:  10Mb
  MaxClients:                   400/10 = 40
  StartServers:                 5
  MinSpareServers:              5
  MaxSpareServers:              10</pre>
        </td>
	    
      </tr>
    </table>
    <P>
These numbers are taken off the top of my head, and shouldn't be used as a
rule, but rather as examples to show you some possible scenarios. Use this
information with caution!

<P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H2><A NAME="Summary_of_Benchmarking_to_tune_">Summary of Benchmarking to tune all 5 parameters</A></H2></CENTER>
<P>
OK, we've run various benchmarks -- let's summarize the conclusions:

<UL>
<P><LI><STRONG><A NAME="item_MaxRequestsPerChild">MaxRequestsPerChild</A></STRONG>
<P>
If your scripts are clean and don't leak memory, set this variable to a
number as large as possible (10000?). If you use
<CODE>Apache::SizeLimit</CODE>, you can set this parameter to 0 (treated as infinity). You will want this
parameter to be smaller if your code becomes unshared over the process'
life. And <CODE>Apache::GTopLimit</CODE>
comes into the picture with the shared memory limitation feature.

<P><LI><STRONG><A NAME="item_StartServers">StartServers</A></STRONG>
<P>
If you keep a small number of servers active most of the time, keep this
number low. Keep it low especially if <CODE>MaxSpareServers</CODE> is also low, as if there is no load Apache will kill its children before
they have been utilized at all. If your service is heavily loaded, make
this number close to <CODE>MaxClients</CODE>, and keep <CODE>MaxSpareServers</CODE> equal to <CODE>MaxClients</CODE>.

<P><LI><STRONG><A NAME="item_MinSpareServers">MinSpareServers</A></STRONG>
<P>
If your server performs other work besides web serving, make this low so
the memory of unused children will be freed when the load is light. If your
server's load varies (you get loads in bursts) and you want fast response
for all clients at any time, you will want to make it high, so that new
children will be respawned in advance and are waiting to handle bursts of
requests.

<P><LI><STRONG><A NAME="item_MaxSpareServers">MaxSpareServers</A></STRONG>
<P>
The logic is the same as for <CODE>MinSpareServers</CODE> - low if you need the machine for other tasks, high if it's a dedicated web
host and you want a minimal delay between the request and the response.

<P><LI><STRONG><A NAME="item_MaxClients">MaxClients</A></STRONG>
<P>
Not too low, so you don't get into a situation where clients are waiting
for the server to start serving them (they might wait, but not for very
long). However, do not set it too high. With a high MaxClients, if you get
a high load the server will try to serve all requests immediately. Your CPU
will have a hard time keeping up, and if the child size * number of running
children is larger than the total available RAM your server will start
swapping. This will slow down everything, which in turn will make things
even slower, until eventually your machine will die. It's important that
you take pains to ensure that swapping does not normally happen. Swap space
is an emergency pool, not a resource to be used routinely. If you are low
on memory and you badly need it, buy it. Memory is cheap.

<P>
But based on the test I conducted above, even if you have plenty of memory
like I have (1Gb), increasing <CODE>MaxClients</CODE> sometimes will give you no improvement in performance. The more clients are
running, the more CPU time will be required, the less CPU time slices each
process will receive. The response latency (the time to respond to a
request) will grow, so you won't see the expected improvement. The best
approach is to find the minimum requirement for your kind of service and
the maximum capability of your machine. Then start at the minimum and test
like I did, successively raising this parameter until you find the region
on the curve of the graph of latency and/or throughput against MaxClients
where the improvement starts to diminish. Stop there and use it. When you
make the measurements on a production server you will have the ability to
tune them more precisely, since you will see the real numbers.

<P>
Don't forget that if you add more scripts, or even just modify the existing
ones, the processes will grow in size as you compile in more code. Probably
the parameters will need to be recalculated.

</UL>
<P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H2><A NAME="KeepAlive">KeepAlive</A></H2></CENTER>
<P>
If your mod_perl server's <EM>httpd.conf</EM> includes the following directives:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  KeepAlive On
  MaxKeepAliveRequests 100
  KeepAliveTimeout 15</pre>
        </td>
	    
      </tr>
    </table>
    <P>
you have a real performance penalty, since after completing the processing
for each request, the process will wait for
<CODE>KeepAliveTimeout</CODE> seconds before closing the connection and will therefore not be serving
other requests during this time. With this configuration you will need many
more concurrent processes on a server with high traffic.

<P>
If you use some server status reporting tools, you will see the process in <EM>K</EM> status when it's in <CODE>KeepAlive</CODE> status.

<P>
The chances are that you don't want this feature enabled. Set it Off with:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  KeepAlive Off</pre>
        </td>
	    
      </tr>
    </table>
    <P>
the other two directives don't matter if <CODE>KeepAlive</CODE> is <CODE>Off</CODE>.

<P>
You might want to consider enabling this option if the client's browser
needs to request more than one object from your server for a single HTML
page. If this is the situation the by setting
<CODE>KeepAlive</CODE>  <CODE>On</CODE> then for each page you save the HTTP connection overhead for all requests
but the first one.

<P>
For example if you have a page with 10 ad banners, which is not uncommon
today, you server will work more effectively if a single process serves
them all during a single connection. However, your client will see a
slightly slower response, since banners will be brought one at a time and
not concurrently as is the case if each
<CODE>IMG</CODE> tag opens a separate connection.

<P>
Since keepalive connections will not incur the additional three-way TCP
handshake, turning it off will be kinder to the network.

<P>
SSL connections benefit the most from <CODE>KeepAlive</CODE> in case you didn't configure the server to cache session ids.

<P>
You have probably followed the advice to send all the requests for static
objects to a plain Apache server. Since most pages include more than one
unique static image, you should keep the default
<CODE>KeepAlive</CODE> setting of the non-mod_perl server, i.e. keep it <CODE>On</CODE>. It will probably be a good idea also to reduce the timeout a little.

<P>
One option would be for the proxy/accelerator to keep the connection open
to the client but make individual connections to the server, read the
response, buffer it for sending to the client and close the server
connection. Obviously you would make new connections to the server as
required by the client's requests.

<P>
Also you should know that <CODE>KeepAlive</CODE> requests only work with responses that contain a <CODE>Content-Length</CODE> header. To send this header do:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  $r-&gt;header_out('Content-Length', $length);</pre>
        </td>
	    
      </tr>
    </table>
    <P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H2><A NAME="PerlSetupEnv_Off">PerlSetupEnv Off</A></H2></CENTER>
<P>
<CODE>PerlSetupEnv Off</CODE> is another optimization you might consider. This directive requires
mod_perl 1.25 or later.

<P>
<EM>mod_perl</EM> fiddles with the environment to make it appear as if the script were being
called under the CGI protocol. For example, the
<CODE>$ENV{QUERY_STRING}</CODE> environment variable is initialized with the contents of <EM>Apache::args()</EM>, and the value returned by
<EM>Apache::server_hostname()</EM> is put into <CODE>$ENV{SERVER_NAME}</CODE>.

<P>
But <CODE>%ENV</CODE> population is expensive. Those who have moved to the Perl Apache API no
longer need this extra <CODE>%ENV</CODE> population, and can gain by turning it <STRONG>Off</STRONG>. Scripts using the <CODE>CGI.pm</CODE> module require
<CODE>PerlSetupEnv On</CODE> because that module relies on a properly populated CGI environment table.

<P>
By default it is On.

<P>
Note that you can still set environment variables. For example when you use
the following configuration:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  PerlSetupEnv Off
  PerlModule Apache::RegistryNG
  &lt;Location /perl&gt;
    PerlSetupEnv On
    PerlSetEnv TEST hi
    SetHandler perl-script
    PerlHandler Apache::RegistryNG
    Options +ExecCGI
  &lt;/Location&gt;</pre>
        </td>
	    
      </tr>
    </table>
    <P>
and you issue a request (for example <A
HREF="http://localhost/perl/setupenvoff.pl">http://localhost/perl/setupenvoff.pl</A>)
for this script:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  setupenvoff.pl
  --------------
  use Data::Dumper;
  my $r = Apache-&gt;request();
  $r-&gt;send_http_header('text/plain');
  print Dumper(\%ENV);</pre>
        </td>
	    
      </tr>
    </table>
    <P>
you should see something like this:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  $VAR1 = {
            'GATEWAY_INTERFACE' =&gt; 'CGI-Perl/1.1',
            'MOD_PERL' =&gt; 'mod_perl/1.25',
            'PATH' =&gt; '/usr/lib/perl5/5.00503:... snipped ...',
            'TEST' =&gt; 'hi'
          };</pre>
        </td>
	    
      </tr>
    </table>
    <P>
Notice that we have got the value of the environment variable <EM>TEST</EM>.

<P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H2><A NAME="Reducing_the_Number_of_stat_Ca">Reducing the Number of stat() Calls Made by Apache</A></H2></CENTER>
<P>
If you watch the system calls that your server makes (using <EM>truss</EM>
or <EM>strace</EM> while processing a request, you will notice that a few <CODE>stat()</CODE>
calls are made. For example when I fetch <A
HREF="http://localhost/perl-status">http://localhost/perl-status</A> and I
have my DocRoot set to
<EM>/home/httpd/docs</EM> I see:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  [snip]
  stat(&quot;/home/httpd/docs/perl-status&quot;, 0xbffff8cc) = -1 
                      ENOENT (No such file or directory)
  stat(&quot;/home/httpd/docs&quot;, {st_mode=S_IFDIR|0755, 
                                 st_size=1024, ...}) = 0
  [snip]</pre>
        </td>
	    
      </tr>
    </table>
    <P>
If you have some dynamic content and your virtual relative URI is something
like <EM>/news/perl/mod_perl/summary</EM> (i.e., there is no such directory on the web server, the path components
are only used for requesting a specific report), this will generate
<CODE>five(!)</CODE> <CODE>stat()</CODE> calls, before the <CODE>DocumentRoot</CODE> is found. You will see something like this:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  stat(&quot;/home/httpd/docs/news/perl/mod_perl/summary&quot;, 0xbffff744) = -1 
                      ENOENT (No such file or directory)
  stat(&quot;/home/httpd/docs/news/perl/mod_perl&quot;,         0xbffff744) = -1
                      ENOENT (No such file or directory)
  stat(&quot;/home/httpd/docs/news/perl&quot;,                  0xbffff744) = -1
                      ENOENT (No such file or directory)
  stat(&quot;/home/httpd/docs/news&quot;,                       0xbffff744) = -1
                      ENOENT (No such file or directory)
  stat(&quot;/home/httpd/docs&quot;, 
                      {st_mode=S_IFDIR|0755, st_size=1024, ...})  =  0</pre>
        </td>
	    
      </tr>
    </table>
    <P>
How expensive those calls are? Let's use the <CODE>Time::HiRes</CODE> module to find out. 

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  stat_call_sample.pl
  -------------------
  use Time::HiRes qw(gettimeofday tv_interval);
  my $calls = 1_000_000;
  
  my $start_time = [ gettimeofday ];
  
  stat &quot;/foo&quot; for 1..$calls;
  
  my $end_time = [ gettimeofday ];
  
  my $elapsed = tv_interval($start_time,$end_time) / $calls;
  
  print &quot;The average execution time: $elapsed seconds\n&quot;;</pre>
        </td>
	    
      </tr>
    </table>
    <P>
This script takes a time sample at the beginnig, then does 1_000_000
<CODE>stat()</CODE> calls to a non-existing file, samples the time at the end and prints the
average time it took to make a single <CODE>stat()</CODE> call. I'm sampling a 1M stats, so I'd get a correct average result.

<P>
Before we actually run the script one should destinguish between two
different situation. When the server is idle the time between the first and
the last system call will be much shorter than the same time measured on
the loaded system. That is because on the idle system, a process can use
CPU very often, and on the loaded system lots of processes compete over it
and each process has to wait for a longer time to get the same amount of
CPU time.

<P>
So first we run the above code on the unloaded system:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  % perl stat_call_sample.pl
  The average execution time: 4.209645e-06 seconds</pre>
        </td>
	    
      </tr>
    </table>
    <P>
So it takes about 4 microseconds to execute a <CODE>stat()</CODE> call. Now
let start a CPU intensive process in one console. The following code keeps
CPU busy all the time.

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  % perl -e '1**1 while 1'</pre>
        </td>
	    
      </tr>
    </table>
    <P>
And now run the <EM>stat_call_sample.pl</EM> script in the other console.

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  % perl stat_call_sample.pl
  The average execution time: 8.777301e-06 seconds</pre>
        </td>
	    
      </tr>
    </table>
    <P>
You can see that the average time has doubled (about 8 microseconds). And
this is obvious, since there were two processes competing over CPU. Now if
run 4 occurences of the above code:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  % perl -e '1**1 while 1' &amp;
  % perl -e '1**1 while 1' &amp;
  % perl -e '1**1 while 1' &amp;
  % perl -e '1**1 while 1' &amp;</pre>
        </td>
	    
      </tr>
    </table>
    <P>
And when running our script in parallel with these processes, we get:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  % perl stat_call_sample.pl
  2.0853558e-05 seconds</pre>
        </td>
	    
      </tr>
    </table>
    <P>
about 20 microseconds. So the average <CODE>stat()</CODE> system call is 5
times longer now. Now if you have 50 mod_perl processes that keep the CPU
busy all the time, the <CODE>stat()</CODE> call will be 50 times slower and
it'll take 0.2 milliseconds to complete a series of call. If you have five
redundant calls as in the strace example above, they adds up to one
millisecond. If you have more processes constantly consuming CPU, this time
adds up. Now multiply this time by the number of processes that you have
and you get a few seconds lost. As usual, for some services this loss is
insignificant, while for others a very significant one.

<P>
So why Apache does all these redundant <CODE>stat()</CODE> calls? You can blame the default installed <CODE>TransHandler</CODE> for this inefficiency. Of course you could supply your own, which will be
smart enough not to look for this virtual path and immediately return <CODE>OK</CODE>. But in cases where you have a virtual host that serves only dynamically
generated documents, you can override the default <CODE>PerlTransHandler</CODE> with this one:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  &lt;VirtualHost 10.10.10.10:80&gt;
    ...
    PerlTransHandler  Apache::OK
    ...
  &lt;/VirtualHost&gt;</pre>
        </td>
	    
      </tr>
    </table>
    <P>
As you see it affects only this specific virtual host.

<P>
This has the effect of short circuiting the normal <CODE>TransHandler</CODE>
processing of trying to find a filesystem component that matches the given
URI -- no more 'stat's!

<P>
Watching your server under strace/truss can often reveal more performance
hits than trying to optimize the code itself!

<P>
For example unless configured correctly, Apache might look for the
<EM>.htaccess</EM> file in many places, if you don't have one and add many <CODE>open()</CODE>
calls.

<P>
Let's start with this simple configuration, and will try to reduce the
number of irrelevant system calls.

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  DocumentRoot &quot;/home/httpd/docs&quot;
  &lt;Location /foo/test&gt;
    SetHandler perl-script
    PerlHandler Apache::Foo
  &lt;/Location&gt;</pre>
        </td>
	    
      </tr>
    </table>
    <P>
The above configuration allows us to make a request to <EM>/foo/test</EM>
and the Perl <CODE>handler()</CODE> defined in <CODE>Apache::Foo</CODE> will be executed. Notice that in the test setup there is no file to be
executed (like in <CODE>Apache::Registry</CODE>). There is no <EM>.htaccess</EM> file as well.

<P>
This is a typical generated trace.

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  stat(&quot;/home/httpd/docs/foo/test&quot;, 0xbffff8fc) = -1 ENOENT 
        (No such file or directory)
  stat(&quot;/home/httpd/docs/foo&quot;,      0xbffff8fc) = -1 ENOENT 
        (No such file or directory)
  stat(&quot;/home/httpd/docs&quot;, 
        {st_mode=S_IFDIR|0755, st_size=1024, ...}) = 0
  open(&quot;/.htaccess&quot;, O_RDONLY)                 = -1 ENOENT 
        (No such file or directory)
  open(&quot;/home/.htaccess&quot;, O_RDONLY)            = -1 ENOENT 
        (No such file or directory)
  open(&quot;/home/httpd/.htaccess&quot;, O_RDONLY)      = -1 ENOENT 
        (No such file or directory)
  open(&quot;/home/httpd/docs/.htaccess&quot;, O_RDONLY) = -1 ENOENT 
        (No such file or directory)
  stat(&quot;/home/httpd/docs/test&quot;, 0xbffff774)    = -1 ENOENT 
        (No such file or directory)
  stat(&quot;/home/httpd/docs&quot;, 
        {st_mode=S_IFDIR|0755, st_size=1024, ...}) = 0</pre>
        </td>
	    
      </tr>
    </table>
    <P>
Now we modify the <CODE>&lt;Directory&gt;</CODE> entry and add AllowOverride&nbsp;None, which among other things disables <EM>.htaccess</EM> files and will not try to open them.

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  &lt;Directory /&gt;
    AllowOverride None
  &lt;/Directory&gt;</pre>
        </td>
	    
      </tr>
    </table>
    <P>
We see that the four <CODE>open()</CODE> calls for <EM>.htaccess</EM> have gone.

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  stat(&quot;/home/httpd/docs/foo/test&quot;, 0xbffff8fc) = -1 ENOENT 
        (No such file or directory)
  stat(&quot;/home/httpd/docs/foo&quot;,      0xbffff8fc) = -1 ENOENT 
        (No such file or directory)
  stat(&quot;/home/httpd/docs&quot;, 
        {st_mode=S_IFDIR|0755, st_size=1024, ...}) = 0
  stat(&quot;/home/httpd/docs/test&quot;, 0xbffff774)    = -1 ENOENT 
        (No such file or directory)
  stat(&quot;/home/httpd/docs&quot;, 
        {st_mode=S_IFDIR|0755, st_size=1024, ...}) = 0</pre>
        </td>
	    
      </tr>
    </table>
    <P>
Let's try to shortcut the <EM>foo</EM> location with:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  Alias /foo /</pre>
        </td>
	    
      </tr>
    </table>
    <P>
Which makes Apache to look for the file in the <EM>/</EM> directory and not under <EM>/home/httpd/docs/foo</EM>. Let's run it:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  stat(&quot;//test&quot;, 0xbffff8fc) = -1 ENOENT (No such file or directory)</pre>
        </td>
	    
      </tr>
    </table>
    <P>
Wow, we've got only one stat call left!

<P>
Let's remove the last <CODE>Alias</CODE> setting and use:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>    PerlTransHandler  Apache::OK</pre>
        </td>
	    
      </tr>
    </table>
    <P>
as explained above. When we issue the request, we see no
<CODE>stat()</CODE> calls. But this is possible only if you serve only
dynamically generated documents, i.e. no CGI scripts. Otherwise you will
have to write your own <EM>PerlTransHandler</EM> to handle requests as desired.

<P>
For example this <EM>PerlTransHandler</EM> will not lookup the file on the filesystem if the URI starts with <EM>/foo</EM>, but will use the default
<EM>PerlTransHandler</EM> otherwise:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  PerlTransHandler 'sub { return shift-&gt;uri() =~ m|^/foo| \
                        ? Apache::OK : Apache::DECLINED;}'</pre>
        </td>
	    
      </tr>
    </table>
    <P>
Let's see the same configuration using the <CODE>&lt;Perl&gt;</CODE> section and a dedicated package:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  &lt;Perl&gt;  
    package My::Trans;
    use Apache::Constants qw(:common);
    sub handler{
       my $r = shift;
       return OK if $r-&gt;uri() =~ m|^/foo|;
       return DECLINED;
    }</pre>
        </td>
	    
      </tr>
    </table>
    <P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>    package Apache::ReadConfig;  
    $PerlTransHandler = &quot;My::Trans&quot;;
  &lt;/Perl&gt;</pre>
        </td>
	    
      </tr>
    </table>
    <P>
As you see we have defined the <CODE>My::Trans</CODE> package and implemented the <CODE>handler()</CODE> function. Then we have
assigned this handler to the
<CODE>PerlTransHandler</CODE>.

<P>
Of course you can move the code in the module into an external file, (e.g. <EM>My/Trans.pm</EM>) and configure the <CODE>PerlTransHandler</CODE> with 

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  PerlTransHandler My::Trans</pre>
        </td>
	    
      </tr>
    </table>
    <P>
in the normal way (no <CODE>&lt;Perl&gt;</CODE> section required).

<P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H1><A NAME="TMTOWTDI_Convenience_and_Habit_">TMTOWTDI: Convenience and Habit vs. Performance</A></H1></CENTER>
<P>
TMTOWTDI (sometimes pronounced <EM>"tim toady"</EM>), or <EM>"There's More
Than One Way To Do It"</EM> is the main motto of Perl. In other words, you can gain the same goal by
coding in many different styles, using different modules and deploying the
same modules in different ways.

<P>
Unfortunately when you come to the point where performance is the goal, you
might have to learn what's more efficient and what's not. Of course it
might mean that you will have to use something that you don't really like,
it might be less convenient or it might be just a matter of habit that one
should change.

<P>
So this section is about performance trade-offs. For almost each comparison
we will provide the theoretical difference and then run benchmarks to
support the theory, since however good the theory its the numbers we get in
practice that matter.

<P>
In the following benchmarks, unless told different the following Apache
configuration has been used:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  MinSpareServers 10
  MaxSpareServers 20
  StartServers 10
  MaxClients 20
  MaxRequestsPerChild 10000</pre>
        </td>
	    
      </tr>
    </table>
    <P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H2><A NAME="Apache_Registry_PerlHandler_vs_">Apache::Registry PerlHandler vs. Custom PerlHandler</A></H2></CENTER>
<P>
At some point you have to decide whether to use <CODE>Apache::Registry</CODE>
and similar handlers and stick to writing scripts for the content
generation or to write pure Perl handlers.

<P>
<CODE>Apache::Registry</CODE> maps a request to a file and generates a subroutine to run the code
contained in that file. If you use a
PerlHandler&nbsp;My::Handler instead of <CODE>Apache::Registry</CODE>, you have a direct mapping from request to subroutine, without the steps
in between. These steps include:

<OL>
<P><LI>
<P>
run the <CODE>stat()</CODE> on the script's filename ($r-&gt;filename)

<P><LI>
<P>
check that the file exists and is executable

<P><LI>
<P>
generate a Perl package name based on the request's URI ($r-&gt;uri)

<P><LI>
<P>
go to the directory the script resides in (chdir basename $r-&gt;filename)

<P><LI>
<P>
compare the file's and stored in memory compiled subroutine's last modified
time (if it was compiled already)

<P><LI>
<P>
if modified or not compiled, compile the subroutine

<P><LI>
<P>
go back to the previous directory (chdir $old_cwd)

</OL>
<P>
If you cut out those steps, you cut out some overhead, plain and simple. Do
you <EM>need</EM> to cut out that overhead? May be yes, may be not. Your requirements
determine that.

<P>
You should take a look at the sister <CODE>Apache::Registry</CODE> modules (e.g.
<CODE>Apache::RegistryNG</CODE> and <CODE>Apache::RegistryBB</CODE>) that don't perform all these steps, so you can still choose to stick to
using scripts to generate the content. The greatest added value of scripts
is that you don't have to modify the configuration file to add the handler
configuration and restarting the server for each newly written content
handler.

<P>
Now let's run benchmarks and compare.

<P>
We want to see the overhead that <CODE>Apache::Registry</CODE> adds compared to the custom handler and whether it becomes insignificant
when used for the heavy and time consuming code. In order to do that we
will run two benchmarks sets: the first so called a <EM>light</EM> set will use an almost empty script, that only sends a basic header and one
word as content; the second will be a <EM>heavy</EM> set which will add some time consuming operation to the script's and the
handler's code.

<P>
For the <EM>light</EM> set we are going to use the <EM>registry.pl</EM> script running under <CODE>Apache::Registry</CODE>:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  benchmarks/registry.pl
  ----------------------
  use strict;
  print &quot;Content-type: text/plain\r\n\r\n&quot;;
  print &quot;Hello&quot;;</pre>
        </td>
	    
      </tr>
    </table>
    <P>
And the following content generation handler:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  Benchmark/Handler.pm
  --------------------
  package Benchmark::Handler;
  use Apache::Constants qw(:common);
  
  sub handler{
    $r = shift;
    $r-&gt;send_http_header('text/html');
    $r-&gt;print(&quot;Hello&quot;);
    return OK;
  }
  1;</pre>
        </td>
	    
      </tr>
    </table>
    <P>
We will add this settings to <EM>httpd.conf</EM>:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  PerlModule Benchmark::Handler
  &lt;Location /benchmark_handler&gt;
    SetHandler perl-script
    PerlHandler Benchmark::Handler
  &lt;/Location&gt;</pre>
        </td>
	    
      </tr>
    </table>
    <P>
The first directive worries to preload and compile the
<CODE>Benchmark::Handler</CODE> module. The rest of the lines tell Apache to execute the subroutine <CODE>Benchmark::Handler::handler</CODE> when a request with relative URI <EM>/benchmark_handler</EM> is made.

<P>
We will use the usual configuration for <CODE>Apache::Registry</CODE> scripts, where all the URIs starting with <EM>/perl</EM> are remapped to the files residing under <EM>/home/httpd/perl/</EM> directory.

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  Alias /perl/ /home/httpd/perl/
  &lt;Location /perl&gt;
    SetHandler perl-script
    PerlHandler +Apache::Registry
    Options ExecCGI
    PerlSendHeader On
  &lt;/Location&gt;</pre>
        </td>
	    
      </tr>
    </table>
    <P>
We will use the <CODE>Apache::RegistryLoader</CODE> to preload and compile the script at the server startup as well, so the
benchmark will be fair through the benchmark and only the processing time
will be measured. To accomplish the preloading we add the following code to
the <EM>startup.pl</EM> file:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  use Apache::RegistryLoader ();
  Apache::RegistryLoader-&gt;new-&gt;handler(
              &quot;/perl/benchmarks/registry.pl&quot;,
   &quot;/home/httpd/perl/benchmarks/registry.pl&quot;);</pre>
        </td>
	    
      </tr>
    </table>
    <P>
To create the <EM>heavy</EM> benchmark set let's leave the above code examples unmodified but add some
CPU intensive processing operation (it can be also an IO operation or a
database query.)

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  my $x = 100;
  my $y = log ($x ** 100)  for (0..10000);</pre>
        </td>
	    
      </tr>
    </table>
    <P>
This code does lots of mathematical processing and therefore very CPU
intensive.

<P>
Now we are ready to proceed with the benchmark. We will generate 5000
requests with 15 as a concurrency level using the <CODE>Apache::Benchmark</CODE>
module.

<P>
Here are the reported results:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  ------------------------------
      name        | avtime   rps
  ------------------------------
  light handler   |     15   911
  light registry  |     21   680
  ------------------------------
  heavy handler   |    183    81
  heavy registry  |    191    77
  ------------------------------</pre>
        </td>
	    
      </tr>
    </table>
    <P>
Let's look at the results and answer the previously asked questions.

<P>
First let's compare the results from the <EM>light</EM> set. We can see that the average overhead added by <CODE>Apache::Registry</CODE> (compared to the custom handler) is about:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  21 - 15 = 6 milliseconds</pre>
        </td>
	    
      </tr>
    </table>
    <P>
per request.

<P>
Thus the difference in speed is about 40% (15 vs. 21). Note that this
doesn't mean that the difference in the real world applications is such
big. And the results of the <EM>heavy</EM> set confirm that.

<P>
In the <EM>heavy</EM> set the average processing time is almost the same for the <CODE>Apache::Registry</CODE> and the custom handler. You can clearly see that the difference between the
two is almost the same one that we have seen in the <EM>light</EM> set's results. It has grown from 6 milliseconds to 8 milliseconds
(191-183). Which means that the identical heavy code that has been added
was running for about 168 milliseconds (183-15). It doesn't mean that the
added code itself has been running for 168 milliseconds. It means that it
took 168 milliseconds for this code to be completed in a multi-process
environment where each process gets a time slice to use the CPU. The more
processes are running the more time the process will have to wait to get
the next time slice when it can use the CPU.

<P>
We have the second question answered as well. You can see that when the
code is not just the <EM>hello</EM> script, the overhead of the extra operations done but the <CODE>Apache::Registry</CODE> module, is almost insignificant. It's a non zero though, so it depends on
your requirements, and if another 5-10 millisecons overhead are quite
tolerable, you may choose to use <CODE>Apache::Registry</CODE>.

<P>
The interesting thing is that when the server under test runs on a very
slow machine the results are completely different. I'll present them here
for comparison:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  ------------------------------
      name        | avtime   rps
  ------------------------------
  light handler   |     50   196
  light registry  |    160    61
  ------------------------------
  heavy handler   |    149    67
  heavy registry  |    822    12
  ------------------------------</pre>
        </td>
	    
      </tr>
    </table>
    <P>
First of all the difference of 6 milliseconds in the average processing
time we have seen on the fast machine when running the
<EM>light</EM> set, now has grown to 110 milliseconds. Which means that a few extra
operations, that <CODE>Apache::Registry</CODE> does, turn to be very expensive on the slow machine.

<P>
Second, you can see that when the <EM>heavy</EM> set is used, there is no preservation of the 110 milliseconds as we have
seen on the fast machine, which we obviously would expect to see, since the
code that was added should take the same time to execute in the handler and
the script. But instead we see a difference of 673 milliseconds (822-149).

<P>
The explanation lies in fact that the difference between the machines isn't
merely in the CPU speed. It's possible that there are many other things
that are different. For example the size of the processor cache. If one
machine has a processor cache large enough to hold the whole handler and
the other doesn't this can be very significant, given that in our <EM>heavy</EM> benchmark set, 99.9% of the CPU activity was dedicated to running the
calculation code.

<P>
But this also shows you again, that none of the results and conclusion made
here should be taken for granted. Certainly, most chances are that you will
see a similar behavior on your machine, but only after you have run the
benchmarks and analyzed the received results, you can be sure what is the
best for you using the setup under test. If you later you happen to use a
different machine, make sure to run the tests again, as they can lead to
complete different decision as we have just seen when we have tried the
same benchmark on a different machine.

<P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H2><A NAME="_Bloatware_modules">&quot;Bloatware&quot; modules</A></H2></CENTER>
<P>
Perl modules like IO:: are very convenient, but let's see what it costs us
to use them. (perl5.6.0 over OpenBSD)

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  % wc `perl -MIO -e 'print join(&quot;\n&quot;, sort values %INC, &quot;&quot;)'`
   124     696    4166 /usr/local/lib/perl5/5.6.0/Carp.pm
   580    2465   17661 /usr/local/lib/perl5/5.6.0/Class/Struct.pm
   400    1495   10455 /usr/local/lib/perl5/5.6.0/Cwd.pm
   313    1589   10377 /usr/local/lib/perl5/5.6.0/Exporter.pm
   225     784    5651 /usr/local/lib/perl5/5.6.0/Exporter/Heavy.pm
    92     339    2813 /usr/local/lib/perl5/5.6.0/File/Spec.pm
   442    1574   10276 /usr/local/lib/perl5/5.6.0/File/Spec/Unix.pm
   115     398    2806 /usr/local/lib/perl5/5.6.0/File/stat.pm
   406    1350   10265 /usr/local/lib/perl5/5.6.0/IO/Socket/INET.pm
   143     429    3075 /usr/local/lib/perl5/5.6.0/IO/Socket/UNIX.pm
  7168   24137  178650 /usr/local/lib/perl5/5.6.0/OpenBSD.i386-openbsd/Config.pm
   230    1052    5995 /usr/local/lib/perl5/5.6.0/OpenBSD.i386-openbsd/Errno.pm
   222     725    5216 /usr/local/lib/perl5/5.6.0/OpenBSD.i386-openbsd/Fcntl.pm
    47     101     669 /usr/local/lib/perl5/5.6.0/OpenBSD.i386-openbsd/IO.pm
   239     769    5005 /usr/local/lib/perl5/5.6.0/OpenBSD.i386-openbsd/IO/Dir.pm
   169     549    3956 /usr/local/lib/perl5/5.6.0/OpenBSD.i386-openbsd/IO/File.pm
   594    2180   14772 /usr/local/lib/perl5/5.6.0/OpenBSD.i386-openbsd/IO/Handle.pm
   252     755    5375 /usr/local/lib/perl5/5.6.0/OpenBSD.i386-openbsd/IO/Pipe.pm
    77     235    1709 /usr/local/lib/perl5/5.6.0/OpenBSD.i386-openbsd/IO/Seekable.pm
   428    1419   10219 /usr/local/lib/perl5/5.6.0/OpenBSD.i386-openbsd/IO/Socket.pm
   452    1401   10554 /usr/local/lib/perl5/5.6.0/OpenBSD.i386-openbsd/Socket.pm
   127     473    3554 /usr/local/lib/perl5/5.6.0/OpenBSD.i386-openbsd/XSLoader.pm
    52     161    1050 /usr/local/lib/perl5/5.6.0/SelectSaver.pm
   139     541    3754 /usr/local/lib/perl5/5.6.0/Symbol.pm
   161     609    4081 /usr/local/lib/perl5/5.6.0/Tie/Hash.pm
   109     390    2479 /usr/local/lib/perl5/5.6.0/strict.pm
    79     370    2589 /usr/local/lib/perl5/5.6.0/vars.pm
   318    1124   11975 /usr/local/lib/perl5/5.6.0/warnings.pm
    30      85     722 /usr/local/lib/perl5/5.6.0/warnings/register.pm
 13733   48195  349869 total</pre>
        </td>
	    
      </tr>
    </table>
    <P>
Moreover, that requires 116 happy trips through the kernel's
<CODE>namei().</CODE> It syscalls <CODE>open()</CODE> a remarkable 57
times, 17 of which failed but leaving 38 that were successful. It also
syscalled <CODE>read()</CODE> a curiously identical 57 times, ingesting a
total of 180,265 plump bytes. To top it off, this <STRONG><EM>increases your resident set size by two megabytes!</EM></STRONG>



<P>
Happy mallocking...

<P>
It seems that <CODE>CGI.pm</CODE> suffers from the same disease:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  % wc `perl -MCGI -le 'print for values %INC'`
  1368    6920   43710 /usr/local/lib/perl5/5.6.0/overload.pm
  6481   26122  200840 /usr/local/lib/perl5/5.6.0/CGI.pm
  7849   33042  244550 total</pre>
        </td>
	    
      </tr>
    </table>
    <P>
You have 16 trips through namei, 7 successful opens, 2 unsuccessful ones,
and 213k of data read in.

<P>
This is a <EM>perlbloat.pl</EM> that shows how much memory is acquired by Perl when you run some. So we can
easily test the overhead of loading some modules.

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  #!/usr/bin/perl -w
  
  use GTop ();
  
  my $gtop = GTop-&gt;new;
  my $before = $gtop-&gt;proc_mem($$)-&gt;size;
  
  for (@ARGV) {
      if (eval &quot;require $_&quot;) {
          eval {
              $_-&gt;import;
          };
      }
      else {
          eval $_;
          die $@ if $@;
      }
  }
  
  my $after = $gtop-&gt;proc_mem($$)-&gt;size;
  printf &quot;@ARGV added %s\n&quot;, GTop::size_string($after - $before);</pre>
        </td>
	    
      </tr>
    </table>
    <P>
Now let's try to load <CODE>IO</CODE>, which loads <CODE>IO::Handle</CODE>,
<CODE>IO::Seekable</CODE>, <CODE>IO::File</CODE>, <CODE>IO::Pipe</CODE>, <CODE>IO::Socket</CODE> and
<CODE>IO::Dir</CODE>:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  % ./perlbloat.pl 'use IO;'
  use IO; added  1.5M</pre>
        </td>
	    
      </tr>
    </table>
    <P>
<EM>"Only"</EM> 1.5 MB overhead. Now let's load CGI (v2.74) and compile all its methods:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  % ./perlbloat.pl 'use CGI; CGI-&gt;compile(&quot;:all&quot;)'
  use CGI; CGI-&gt;compile(&quot;:all&quot;) added  1.8M</pre>
        </td>
	    
      </tr>
    </table>
    <P>
Almost 2MB extra memory. Let's compare <CODE>CGI.pm</CODE> with its younger sister, whose internals are implemented in C.

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  %. /perlbloat.pl 'use Apache::Request'
  use Apache::Request added   48k</pre>
        </td>
	    
      </tr>
    </table>
    <P>
48KB. A significant difference isn't it?

<P>
The following numbers show memory sizes in KB (virtual and resident) for
v5.6.0 of Perl on four different operating systems, The three calls each
are without any modules, with just -MCGI, and with -MIO (never with both):

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>              OpenBSD       FreeBSD    Redhat Linux    Solaris
              vsz   rss     vsz  rss     vsz  rss    vsz    rss
  Raw Perl    736   772     832 1208    2412  980    2928  2272
  w/ CGI     1220  1464    1308 1828    2972 1768    3616  3232
  w/ IO      2292  2580    2456 3016    4080 2868    5384  4976</pre>
        </td>
	    
      </tr>
    </table>
    <P>
Anybody who's thinking of choosing one of these might do well to digest
these numbers first.

<P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H2><A NAME="Apache_args_vs_Apache_Request">Apache::args vs. Apache::Request::param vs. CGI::param</A></H2></CENTER>
<P>
Let's write three <CODE>Apache::Registry</CODE> scripts that use
<CODE>Apache::args</CODE>, <CODE>Apache::Request::param</CODE> and <CODE>CGI::param</CODE> to process the form's input and print it out. Notice that <CODE>Apache::args</CODE>
is considered identical to <CODE>Apache::Request::param</CODE> only when you have a single valued keys, in case of multivalued keys (e.g.
when using checkbox groups) you will have to write some more code, since if
you do a simple:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  my %params = $r-&gt;args;</pre>
        </td>
	    
      </tr>
    </table>
    <P>
only the last value will be stored and the rest will collapse, something
that you will solve with <CODE>Apache::Request::params</CODE> as:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  my @values = $q-&gt;params('key');</pre>
        </td>
	    
      </tr>
    </table>
    <P>
In addition <CODE>Apache::Request</CODE> and <CODE>CGI.pm</CODE> has many more functions that ease input processing, like handling file
uploads. But
<CODE>Apache::Request</CODE> is much faster since its guts are implemented in C, glued with Perl using
the XS code.

<P>
Therefore assuming that the only functionality that you need is the parsing
of the key-value pairs, and assuming that every key has a single value, we
will compare the following almost indentical scripts, by trying to pass
various query strings.

<P>
The code that we have used:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  processing_with_apache_args.pl
  ------------------------------
  use strict;
  my $r = shift;
  $r-&gt;send_http_header('text/plain');
  my %args = $r-&gt;args;
  print join &quot;\n&quot;, map {&quot;$_ =&gt; &quot;.$args{$_} } keys %args;</pre>
        </td>
	    
      </tr>
    </table>
    <P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  processing_with_apache_request.pl
  ---------------------------------
  use strict;
  use Apache::Request ();
  my $r = shift;
  my $q = Apache::Request-&gt;new($r);
  $r-&gt;send_http_header('text/plain');
  my %args = map {$_ =&gt; $q-&gt;param($_) } $q-&gt;param;
  print join &quot;\n&quot;, map {&quot;$_ =&gt; &quot;.$args{$_} } keys %args;</pre>
        </td>
	    
      </tr>
    </table>
    <P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  processing_with_cgi_pm.pl
  ---------------------------------
  use strict;
  use CGI;
  my $r = shift;
  $r-&gt;send_http_header('text/plain');
  my $q = new CGI;
  my %args = map {$_ =&gt; $q-&gt;param($_) } $q-&gt;param;
  print join &quot;\n&quot;, map {&quot;$_ =&gt; &quot;.$args{$_} } keys %args;</pre>
        </td>
	    
      </tr>
    </table>
    <P>
All three scripts were preloaded at the server startup:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  &lt;Perl&gt;
  use Apache::RegistryLoader ();
  Apache::RegistryLoader-&gt;new-&gt;handler(
                            &quot;/perl/processing_with_cgi_pm.pl&quot;,
            &quot;[ROOT_DIR]/httpd/perl/processing_with_cgi_pm.pl&quot;
                                    );
  Apache::RegistryLoader-&gt;new-&gt;handler(
                            &quot;/perl/processing_with_apache_request.pl&quot;,
            &quot;[ROOT_DIR]/httpd/perl/processing_with_apache_request.pl&quot;
                                    );
  Apache::RegistryLoader-&gt;new-&gt;handler(
                            &quot;/perl/processing_with_apache_args.pl&quot;,
            &quot;[ROOT_DIR]/httpd/perl/processing_with_apache_args.pl&quot;
                                    );
  &lt;/Perl&gt;</pre>
        </td>
	    
      </tr>
    </table>
    <P>
And the results:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  -------------------------------------------------------------
  name           query_length  | avtime completed failed    rps
  -------------------------------------------------------------
  apache_args              25  |     69      5000      0    698
  apache_request           25  |     76      5000      0    632
  apache_args             337  |     97      5000      0    500
  cgi_pm                   25  |    115      5000      0    422
  apache_request          337  |    159      5000      0    308
  cgi_pm                  337  |    301      5000      0    163
  --------------------------------------------------------------
  Non-varying sub-test parameters:
  --------------------------------------------------------------
  concurrency : 50
  connections : 5000</pre>
        </td>
	    
      </tr>
    </table>
    <P>
We have used two different query strings, generated by:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  my $query = [
             join(&quot;&amp;&quot;, map {&quot;$_=&quot;.'e' x 10}  ('a'..'b')),
             join(&quot;&amp;&quot;, map {&quot;$_=&quot;.'e' x 10}  ('a'..'z')),
            ];</pre>
        </td>
	    
      </tr>
    </table>
    <P>
The first one renders into:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  a=eeeeeeeeee&amp;b=eeeeeeeeee</pre>
        </td>
	    
      </tr>
    </table>
    <P>
which is 25 characters in length. The other is similar but of 337
characters in length. Now you can tell what are the numbers in the
<CODE>query_length</CODE> column of the report.

<P>
You can see that <CODE>Apache::args</CODE> is much faster than the other two modules, whereas <CODE>Apache::Request::param</CODE> is much faster than
<CODE>CGI::param</CODE>.

<P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H2><A NAME="Using_1_Under_mod_perl_and_Be">Using $|=1 Under mod_perl and Better print() Techniques.</A></H2></CENTER>
<P>
As you know, <CODE>local $|=1;</CODE> disables the buffering of the currently selected file handle (default is <CODE>STDOUT</CODE>). If you enable it,
<CODE>ap_rflush()</CODE> is called after each <CODE>print()</CODE>, unbuffering Apache's IO.

<P>
If you are using multiple <CODE>print()</CODE> calls (_bad_ style in generating output) or if you just have too many of
them, then you will experience a degradation in performance. The severity
depends on the number of <CODE>print()</CODE> calls that you make.

<P>
Many old CGI scripts were written like this:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  print &quot;&lt;BODY BGCOLOR=\&quot;black\&quot; TEXT=\&quot;white\&quot;&gt;&quot;;
  print &quot;&lt;H1&gt;&quot;;
  print &quot;Hello&quot;;
  print &quot;&lt;/H1&gt;&quot;;
  print &quot;&lt;A HREF=\&quot;foo.html\&quot;&gt; foo &lt;/A&gt;&quot;;
  print &quot;&lt;/BODY&gt;&quot;;</pre>
        </td>
	    
      </tr>
    </table>
    <P>
This example has multiple <CODE>print()</CODE> calls, which will cause performance degradation with <CODE>$|=1</CODE>. It also uses too many backslashes. This makes the code less readable, and
it is also more difficult to format the HTML so that it is easily readable
as the script's output. The code below solves the problems:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  print qq{
    &lt;BODY BGCOLOR=&quot;black&quot; TEXT=&quot;white&quot;&gt;
      &lt;H1&gt;
        Hello
      &lt;/H1&gt;
      &lt;A HREF=&quot;foo.html&quot;&gt; foo &lt;/A&gt;
    &lt;/BODY&gt;
  };</pre>
        </td>
	    
      </tr>
    </table>
    <P>
I guess you see the difference. Be careful though, when printing a
<CODE>&lt;HTML&gt;</CODE> tag. The correct way is:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  print qq{&lt;HTML&gt;
    &lt;HEAD&gt;&lt;/HEAD&gt;
    &lt;BODY&gt;
  }</pre>
        </td>
	    
      </tr>
    </table>
    <P>
If you try the following:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  print qq{
    &lt;HTML&gt;
    &lt;HEAD&gt;&lt;/HEAD&gt;
    &lt;BODY&gt;
  }</pre>
        </td>
	    
      </tr>
    </table>
    <P>
Some older browsers expect the first characters after the headers and empty
line to be <CODE>&lt;HTML&gt;</CODE> with <EM>no</EM> spaces before the opening left angle-bracket. If there are any other
characters, they might not accept the output as HTML and print it as a
plain text. Even if it works with your browser, it might not work for
others.

<P>
One other approach is to use `here' documents, e.g.:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>    print &lt;&lt;EOT;
    &lt;HTML&gt;
    &lt;HEAD&gt;&lt;/HEAD&gt;
    &lt;BODY&gt;
    EOT</pre>
        </td>
	    
      </tr>
    </table>
    <P>
Now let's go back to the <CODE>$|=1</CODE> topic. I still disable buffering, for two reasons:

<UL>
<P><LI><STRONG><A NAME="item_I">I use relatively few print() calls.  I achieve this by
arranging for my print() statements to print multiline HTML, and
not one line per print() statement.</A></STRONG>
<P><LI><STRONG><A NAME="item_I">I want my users to see the output immediately.  So if I am
about to produce the results of a DB query which might take some time
to complete, I want users to get some text while they are waiting.
This improves the usability of my site.  Ask yourself which you like
better: getting the output a bit slower, but steadily from the moment
you've pressed the Submit button, or having to watch the &quot;falling
stars&quot; for a while and then get the whole output at once, even
if it's a few milliseconds faster - assuming the browser didn't time
out during the wait.</A></STRONG>
</UL>
<P>
An even better solution is to keep buffering enabled, and use a Perl API <CODE>rflush()</CODE> call to flush the buffers when needed. This way you can place the first
part of the page that you are going to send to the user in the buffer, and
flush it a moment before you are going to do some lenghty operation, like a
DB query. So you kill two birds with one stone: you show some of the data
to the user immediately, so she will feel that something is actually
happening, and you have no performance hit from disabled buffering.

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  use CGI ();
  my $r = shift;
  my $q = new CGI;
  print $q-&gt;header('text/html');
  print $q-&gt;start_html;
  print $q-&gt;p(&quot;Searching...Please wait&quot;);
  $r-&gt;rflush;
    # imitate a lenghty operation
  for (1..5) {
    sleep 1;
  }
  print $q-&gt;p(&quot;Done!&quot;);</pre>
        </td>
	    
      </tr>
    </table>
    <P>
<STRONG>Conclusion</STRONG>: Do not blindly follow suggestions, but think what is best for you in each
case.

<P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H2><A NAME="Global_vs_Fully_Qualified_Varia">Global vs. Fully Qualified Variables</A></H2></CENTER>
<P>
It's always a good idea to avoid using global variables where it's
possible. Some variables must be either global, such as <CODE>@ISA</CODE> or else fully qualified such as <CODE>@MyModule::ISA</CODE>, so that Perl can see them from different packages.

<P>
A combination of <CODE>strict</CODE> and <CODE>vars</CODE> pragmas keeps modules clean and reduces a bit of noise. However, the <CODE>vars</CODE> pragma also creates aliases, as does <CODE>Exporter</CODE>, which eat up more memory. When possible, try to use fully qualified names
instead of <CODE>use vars</CODE>.

<P>
For example write:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  package MyPackage1;
  use strict;
  use vars; # added only for fair comparison
  @MyPackage1::ISA = qw(CGI);
  $MyPackage1::VERSION = &quot;1.00&quot;;
  1;</pre>
        </td>
	    
      </tr>
    </table>
    <P>
instead of:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  package MyPackage2;
  use strict;
  use vars qw(@ISA $VERSION);
  @ISA = qw(CGI);
  $VERSION = &quot;1.00&quot;;
  1;</pre>
        </td>
	    
      </tr>
    </table>
    <P>
Note that we have added the <CODE>vars</CODE> pragma in the package that doesn't use it so the memory comparison will be
fair. 

<P>
Here are the numbers under Perl version 5.6.0

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  % perl -MGTop -MMyPackage1 -le 'print GTop-&gt;new-&gt;proc_mem($$)-&gt;size'
    2023424
  % perl -MGTop -MMyPackage2 -le 'print GTop-&gt;new-&gt;proc_mem($$)-&gt;size'
    2031616</pre>
        </td>
	    
      </tr>
    </table>
    <P>
We have a difference of 8192 bytes. So every few global variables declared
with <CODE>vars</CODE> pragma add about 8KB overhead.

<P>
Note that Perl 5.6.0 introduced a new <CODE>our()</CODE> pragma which works
like <CODE>my()</CODE> scope-wise, but declares global variables.

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  package MyPackage3;
  use strict;
  use vars; # not needed, added only for fair comparison
  our @ISA = qw(CGI);
  our $VERSION = &quot;1.00&quot;;
  1;</pre>
        </td>
	    
      </tr>
    </table>
    <P>
which uses the same amount of memory as a fully qualified global variable:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  % perl -MGTop -MMyPackage3 -le 'print GTop-&gt;new-&gt;proc_mem($$)-&gt;size'
  2023424</pre>
        </td>
	    
      </tr>
    </table>
    <P>
Imported symbols act just like global variables, they can add up quick:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  % perlbloat.pl 'use POSIX ()'
  use POSIX () added  316k</pre>
        </td>
	    
      </tr>
    </table>
    <P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  % perlbloat.pl 'use POSIX'
  use POSIX added  696k</pre>
        </td>
	    
      </tr>
    </table>
    <P>
That's 380k worth of aliases. Now let's say 6 different
<CODE>Apache::Registry</CODE> scripts <CODE>'use POSIX;'</CODE> for <CODE>strftime()</CODE> or some other function: 6 * 380k = 2.3Mb

<P>
One could save 2.3Mb per single process with <CODE>'use POSIX ();'</CODE> and using fully qualifying <CODE>POSIX::</CODE> function calls.

<P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H2><A NAME="Object_Methods_Calls_vs_Functio">Object Methods Calls vs. Function Calls</A></H2></CENTER>
<P>
Which subroutine calling form is more efficient: Object methods or
functions?

<P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H3><A NAME="The_Overhead_with_Light_Subrouti">The Overhead with Light Subroutines</A></H3></CENTER>
<P>
Let's do some benchmarking. We will start doing it using empty methods,
which will allow us to measure the real difference in the overhead each
kind of call introduces. We will use this code:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  bench_call1.pl
  --------------
  package Foo;
  
  use strict;
  use Benchmark;
  
  sub bar { };
  
  timethese(50_000, {
                 method   =&gt; sub { Foo-&gt;bar()      },
                 function =&gt; sub { Foo::bar('Foo');},
                });</pre>
        </td>
	    
      </tr>
    </table>
    <P>
The two calls are equivalent, since both pass the class name as their first
parameter; <EM>function</EM> does this explicitly, while <EM>method</EM> does this transparently.

<P>
The benchmarking result:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  Benchmark: timing 50000 iterations of function, method...
    function:  0 wallclock secs ( 0.80 usr +  0.05 sys =  0.85 CPU)
      method:  1 wallclock secs ( 1.51 usr +  0.08 sys =  1.59 CPU)</pre>
        </td>
	    
      </tr>
    </table>
    <P>
We are are interested in the 'total CPU times' and not the 'wallclock
seconds'. It's possible that the load on the system was different for the
two tests while benchmarking, so the wallclock times give us no useful
information.

<P>
We see that the <EM>method</EM> calling type is almost twice as slow as the
<EM>function</EM> call, 0.85 CPU compared to 1.59 CPU real execution time. Why does this
happen? Because the difference between functions and methods is the time
taken to resolve the pointer from the object, to find the module it belongs
to and then the actual method. The function form has one parameter less to
pass, less stack operations, less time to get to the guts of the
subroutine.

<P>
perl5.6+ does better method caching, <CODE>Foo-&gt;method()</CODE> is a little bit faster (some constant folding magic), but not
<CODE>Foo-&gt;$method()</CODE>. And the improvement does not address the
<CODE>@ISA</CODE> lookup that still happens in either case.

<P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H3><A NAME="The_Overhead_with_Heavy_Subrouti">The Overhead with Heavy Subroutines</A></H3></CENTER>
<P>
But that doesn't mean that you shouldn't use methods. Generally your
functions do something, and the more they do the less significant is the
time to perform the call, because the calling time is effectively fixed and
is probably a very small overhead in comparison to the execution time of
the method or function itself. Therefore the longer execution time of the
function the smaller the relative overhead of the method call. The next
benchmark proves this point:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  bench_call2.pl
  --------------
  package Foo;
  
  use strict;
  use Benchmark;
  
  sub bar { 
    my $class = shift;
  
    my ($x,$y) = (100,100);
    $y = log ($x ** 10)  for (0..20);
  };
  
  timethese(50_000, {
                 method   =&gt; sub { Foo-&gt;bar()      },
                 function =&gt; sub { Foo::bar('Foo');},
                });</pre>
        </td>
	    
      </tr>
    </table>
    <P>
We get a very close benchmarks!

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  function: 33 wallclock secs (15.81 usr +  1.12 sys = 16.93 CPU)
    method: 32 wallclock secs (18.02 usr +  1.34 sys = 19.36 CPU)</pre>
        </td>
	    
      </tr>
    </table>
    <P>
Let's make the subroutine <EM>bar</EM> even slower:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  sub bar { 
    my $class = shift;
  
    my ($x,$y) = (100,100);
    $y = log ($x ** 10)  for (0..40);
  };</pre>
        </td>
	    
      </tr>
    </table>
    <P>
And the result is amazing, the <EM>method</EM> call convention was faster than <EM>function</EM>:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  function: 81 wallclock secs (25.63 usr +  1.84 sys = 27.47 CPU)
    method: 61 wallclock secs (19.69 usr +  1.49 sys = 21.18 CPU)</pre>
        </td>
	    
      </tr>
    </table>
    <P>
In case your functions do very little, like the functions that generate
HTML tags in <CODE>CGI.pm</CODE>, the overhead might become a significant one. If your goal is speed you
might consider using the
<EM>function</EM> form, but if you write a big and complicated application, it's much better
to use the <EM>method</EM> form, as it will make your code easier to develop, maintain and debug,
saving programmer time which, over the life of a project may turn out to be
the most significant cost factor.

<P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H3><A NAME="Are_All_Methods_Slower_than_Func">Are All Methods Slower than Functions?</A></H3></CENTER>
<P>
Some modules' API is misleading, for example <CODE>CGI.pm</CODE> allows you to execute its subroutines as functions or as methods. As you
will see in a moment its function form of the calls is slower than the
method form because it does some voodoo work when the function form call is
used.

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  use CGI;
  my $q = new CGI;
  $q-&gt;param('x',5);
  my $x = $q-&gt;param('x');</pre>
        </td>
	    
      </tr>
    </table>
    <P>
vs

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  use CGI qw(:standard);
  param('x',5);
  my $x = param('x');</pre>
        </td>
	    
      </tr>
    </table>
    <P>
As usual, let's benchmark some very light calls and compare. Ideally we
would expect the <EM>methods</EM> to be slower than <EM>functions</EM> based on the previous benchmarks:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  bench_call3.pl
  ---------------
  use Benchmark;
  
  use CGI qw(:standard);
  $CGI::NO_DEBUG = 1;
  my $q = new CGI;
  my $x;
  timethese
    (20000, {
      method   =&gt; sub {$q-&gt;param('x',5); $x = $q-&gt;param('x'); },
      function =&gt; sub {    param('x',5); $x =     param('x'); },
     });</pre>
        </td>
	    
      </tr>
    </table>
    <P>
The benchmark is written is such a way that all the initializations are
done at the beginning, so that we get as accurate performance figures as
possible. Let's do it:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  % ./bench_call3.pl
  
  function: 51 wallclock secs (28.16 usr +  2.58 sys = 30.74 CPU)
    method: 39 wallclock secs (21.88 usr +  1.74 sys = 23.62 CPU)</pre>
        </td>
	    
      </tr>
    </table>
    <P>
As we can see methods are faster than functions, which seems to be wrong.
The explanation lays in the way <CODE>CGI.pm</CODE> is implemented.
<CODE>CGI.pm</CODE> uses some <EM>fancy</EM> tricks to make the same routine act both as a <EM>method</EM> and a plain <EM>function</EM>. The overhead of checking whether the arguments list looks like a <EM>method</EM> invocation or not, will mask the slight difference in time for the way the
function was called.

<P>
If you are intrigued and want to investigate further by yourself the
subroutine you want to explore is called <EM>self_or_default</EM>. The first line of this function short-circuits if you are using the
object methods, but the whole function is called if you are using the
functional forms. Therefore, the functional form should be slightly slower
than the object form.

<P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H2><A NAME="Imported_Symbols_and_Memory_Usag">Imported Symbols and Memory Usage</A></H2></CENTER>
<P>
There is a real memory hit when you import all of the functions into your
process' memory. This can significantly enlarge memory requirements,
particularly when there are many child processes.

<P>
In addition to polluting the namespace, when a process imports symbols from
any module or any script it grows by the size of the space allocated for
those symbols. The more you import (e.g. <CODE>qw(:standard)</CODE> vs
<CODE>qw(:all))</CODE> the more memory will be used. Let's say the overhead
is of size X. Now take the number of scripts in which you deploy the
function method interface, let's call that Y. Finally let's say that you
have a number of processes equal to Z.

<P>
You will need X*Y*Z size of additional memory, taking X=10k, Y=10, Z=30, we
get 10k*10*30 = 3Mb!!! Now you understand the difference.

<P>
Let's benchmark <CODE>CGI.pm</CODE> using <CODE>GTop.pm</CODE>. First we will try it with no exporting at all.

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  use GTop ();
  use CGI ();
  print GTop-&gt;new-&gt;proc_mem($$)-&gt;size;</pre>
        </td>
	    
      </tr>
    </table>
    <P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  1,949,696</pre>
        </td>
	    
      </tr>
    </table>
    <P>
Now exporting a few dozens symbols:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  use GTop ();
  use CGI qw(:standard);
  print GTop-&gt;new-&gt;proc_mem($$)-&gt;size;</pre>
        </td>
	    
      </tr>
    </table>
    <P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  1,966,080</pre>
        </td>
	    
      </tr>
    </table>
    <P>
And finally exporting all the symbols (about 130)

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  use GTop ();
  use CGI qw(:all);
  print GTop-&gt;new-&gt;proc_mem($$)-&gt;size;</pre>
        </td>
	    
      </tr>
    </table>
    <P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  1,970,176</pre>
        </td>
	    
      </tr>
    </table>
    <P>
Results:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  import symbols  size(bytes)  delta(bytes) relative to ()
  --------------------------------------
  ()              1949696             0
  qw(:standard)   1966080         16384
  qw(:all)        1970176         20480</pre>
        </td>
	    
      </tr>
    </table>
    <P>
So in my example above X=20k =&gt; 20K*10*30 = 6Mb. You will need 6Mb more
when importing all the <CODE>CGI.pm</CODE>'s symbols than when you import none at all.

<P>
Generally you use more than one script, run more than one process and
probably import more symbols from the additional modules that you deploy.
So the real numbers are much bigger.

<P>
The function method is faster in the general case, because of the time
overhead to resolve the pointer from the object.

<P>
If you are looking for performance improvements, you will have to face the
fact that having to type <CODE>My::Module::my_method</CODE> might save you a good chunk of memory if the above call must not be called
with a reference to an object, but even then it can be passed by value.

<P>
I strongly endorse <A HREF="././modules.html#Apache_Request_libapreq_Gen">Apache::Request (libapreq) - Generic Apache Request Library</A>. Its core is written in C, giving it a significant memory and performance
benefit. It has all the functionality of <CODE>CGI.pm</CODE> except the HTML generation functions.

<P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H2><A NAME="Interpolation_Concatenation_or_">Interpolation, Concatenation or List</A></H2></CENTER>
<P>
Somewhat overlapping with the previous section we want to revisit the
various approaches of mungling with strings, and compare the speed of using
lists of strings compared to interpolatoin. We will add a string
concatenation angle as well.

<P>
When the strings are small, it almost doesn't matter whether interpolation
or a list is used. Here is a benchmark:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  use Benchmark;
  use Symbol;
  my $fh = gensym;
  open $fh, &quot;&gt;/dev/null&quot; or die;
    
  my($one, $two, $three, $four) = ('a'..'d');
  
  timethese(1_000_000,
      {
       interp =&gt; sub {
         print $fh &quot;$one$two$three$four&quot;;
       },
       list =&gt; sub {
         print $fh $one, $two, $three, $four;
       },
       conc =&gt; sub {
         print $fh $one.$two.$three.$four;
       },
      });</pre>
        </td>
	    
      </tr>
    </table>
    <P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre> Benchmark: timing 1000000 iterations of conc, interp, list...
      conc:  3 wallclock secs ( 3.38 usr +  0.00 sys =  3.38 CPU)
    interp:  3 wallclock secs ( 3.45 usr + -0.01 sys =  3.44 CPU)
      list:  2 wallclock secs ( 2.58 usr +  0.00 sys =  2.58 CPU)</pre>
        </td>
	    
      </tr>
    </table>
    <P>
The concatenation technique is very similar to interpolation. The list
technique is a little bit faster than interpolation. But when the strings
are large, lists are significantly faster. We have seen this in the
previous section and here is another benchmark to increase our confidence
in our conclusion. This time we use 1000 character long strings:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  use Benchmark;
  use Symbol;
  my $fh = gensym;
  open $fh, &quot;&gt;/dev/null&quot; or die;
  
  my($one, $two, $three, $four) = map { $_ x 1000 } ('a'..'d');
  
  timethese(500_000,
      {
       interp =&gt; sub {
         print $fh &quot;$one$two$three$four&quot;;
       },
       list =&gt; sub {
         print $fh $one, $two, $three, $four;
       },
       conc =&gt; sub {
         print $fh $one.$two.$three.$four;
       },
      });</pre>
        </td>
	    
      </tr>
    </table>
    <P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  Benchmark: timing 500000 iterations of interp, list...
      conc:  5 wallclock secs ( 4.47 usr +  0.27 sys =  4.74 CPU)
    interp:  4 wallclock secs ( 4.25 usr +  0.26 sys =  4.51 CPU)
      list:  4 wallclock secs ( 2.87 usr +  0.16 sys =  3.03 CPU)</pre>
        </td>
	    
      </tr>
    </table>
    <P>
In this case using a list is about 30% faster than interpolation.
Concatenation is a little bit slower than interpolation.

<P>
Let's look at this code:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>    $title = 'My Web Page';
    print &quot;&lt;h1&gt;$title&lt;/h1&gt;&quot;;         # Interpolation (slow)
    print '&lt;h1&gt;' . $title . '&lt;/h1&gt;'; # Concatenation (slow)
    print '&lt;h1&gt;', $title, '&lt;/h1&gt;';   # List (fast for long strings)</pre>
        </td>
	    
      </tr>
    </table>
    <P>
When you use <EM>"&lt;h1&gt;$title&lt;/h1&gt;"</EM> Perl does interpolation (since <CODE>&quot;&quot;</CODE> is an operator in Perl), which must parse the contents of the string and
replace any variables or expressions it finds with their respective values.
This uses more memory and is slower than using a list. Of course if there
are no variables to interpolate it makes no difference whether to use <CODE>&quot;string&quot;</CODE> or
<CODE>'string'</CODE>.

<P>
Concatenation is also potentially slow since Perl might create a temporary
string which it then prints.

<P>
Lists are fast because Perl can simply deal with each element in turn. This
is true if you don't run <CODE>join()</CODE> on the list at the end to
create a single string from the elements of list. This operation might be
slower than direct append to the string whenever a new string springs into
existance.

<P>
[ReaderMETA]: Please send more mod_perl relevant Perl performance hints

<P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H2><A NAME="Using_Perl_stat_Call_s_Cached_">Using Perl stat() Call's Cached Results</A></H2></CENTER>
<P>
When you do a <CODE>stat()</CODE> (or its variations <CODE>-M</CODE> -- last modification time, <CODE>-A</CODE> -- last access time, <CODE>-C</CODE> -- last inode-change time, etc), the returned information is cached
internally. If you need to make an additional check for the same file, use
the <CODE>_</CODE> magic variable and save the overhead of an unnecessary <CODE>stat()</CODE>
call. For example when testing for existence and read permissions you might
use:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  my $filename = &quot;./test&quot;;
    # three stat() calls
  print &quot;OK\n&quot; if -e $filename and -r $filename;
  my $mod_time = (-M $filename) * 24 * 60 * 60;
  print &quot;$filename was modified $mod_time seconds before startup\n&quot;;</pre>
        </td>
	    
      </tr>
    </table>
    <P>
or the more efficient:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  my $filename = &quot;./test&quot;;
    # one stat() call
  print &quot;OK\n&quot; if -e $filename and -r _;
  my $mod_time = (-M _) * 24 * 60 * 60;
  print &quot;$filename was modified $mod_time seconds before startup\n&quot;;</pre>
        </td>
	    
      </tr>
    </table>
    <P>
Two <CODE>stat()</CODE> calls were saved!

<P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H1><A NAME="Apache_Registry_and_Derivatives">Apache::Registry and Derivatives Specific Notes</A></H1></CENTER>
<P>
These are the sections that deal solely with <CODE>Apache::Registry</CODE> and derived modules, like <CODE>Apache::PerlRun</CODE> and <CODE>Apache::RegistryBB</CODE>. No Perl handlers code is discussed here, so if you don't use these
modules, feel free to skip this section.

<P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H2><A NAME="Be_Careful_with_Symbolic_Links">Be Careful with Symbolic Links</A></H2></CENTER>
<P>
As you know <CODE>Apache::Registry</CODE> caches the scripts in the packages whose names are constructed by scripts'
URI. If you have the same script that can be reached by different URIs,
which is possible if you have used symbolic links, you will get the same
script stored twice in the memory.

<P>
For example:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  % ln -s /home/httpd/perl/news/news.pl /home/httpd/perl/news.pl</pre>
        </td>
	    
      </tr>
    </table>
    <P>
Now the script can be reached through the both URIs <EM>/news/news.pl</EM>
and <EM>/news.pl</EM>. It doesn't really matter until you advertise the two URIs, and users
reach the same script from both of them.

<P>
So let's assume that you have issued the requests to the both URIs:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  <A HREF="http://localhost/perl/news/news.pl">http://localhost/perl/news/news.pl</A>
  <A HREF="http://localhost/perl/news.pl">http://localhost/perl/news.pl</A></pre>
        </td>
	    
      </tr>
    </table>
    <P>
To spot the duplication you should use the
<A HREF="././debug.html#Apache_Status_Embedded_Inter"><CODE>Apache::Status</CODE></A> module. Amongst other things, it shows all the compiled <CODE>Apache::Registry</CODE>
scripts (using their respective packages):

<P>
If you are using the default configuration directives you should either use
this URI:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  <A HREF="http://localhost/perl-status?rgysubs">http://localhost/perl-status?rgysubs</A></pre>
        </td>
	    
      </tr>
    </table>
    <P>
or just go to the main menu at:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  <A HREF="http://localhost/perl-status">http://localhost/perl-status</A></pre>
        </td>
	    
      </tr>
    </table>
    <P>
And click on <CODE>Compiled Registry Scripts</CODE> menu item.

<P>
META: we need a screen snapshot here!!!

<P>
If you the script was accessed through the URI that was remapped to the
real file and through the URI that was remapped to the symbolic link, you
will see the following output:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  Apache::ROOT::perl::news::news_2epl
  Apache::ROOT::perl::news_2epl</pre>
        </td>
	    
      </tr>
    </table>
    <P>
You should run the server in the single mode, to see it immediately. If you
test it in the normal mode--it's possible that some child processes would
show only one entry or none at all, since they might not serve the same
requests as the others. For more hints see the section ``<A HREF="././control.html#Running_a_Server_in_Single_Proce">Run the server in single mode</A>''.

<P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H1><A NAME="Improving_Performance_by_Prevent">Improving Performance by Prevention</A></H1></CENTER>
<P>
There are two ways to improve performance: one is by tuning to squeeze the
most out of your hardware and software; and the other is preventing certain
bad things from happening, like impolite robots that crawl your site
without pausing between requests, memory leakages, getting the memory
unshared, making sure that some processes won't take up all the CPU etc.

<P>
In the following sections we are going to discuss about the tools and
programming techniques that would help you to keep your service in order,
even if you are not around.

<P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H2><A NAME="Memory_leakage">Memory leakage</A></H2></CENTER>
<P>
Scripts under mod_perl can very easily leak memory! Global variables stay
around indefinitely, lexically scoped variables (declared with
<CODE>my()</CODE>) are destroyed when they go out of scope, provided there are no references
to them from outside that scope.

<P>
Perl doesn't return the memory it acquired from the kernel. It does reuse
it though!

<P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H3><A NAME="Reading_In_A_Whole_File">Reading In A Whole File</A></H3></CENTER>
<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  open IN, $file or die $!;
  local $/ = undef; # will read the whole file in
  $content = &lt;IN&gt;;
  close IN;</pre>
        </td>
	    
      </tr>
    </table>
    <P>
If your file is 5Mb, the child which served that script will grow by
exactly that size. Now if you have 20 children, and all of them will serve
this CGI, they will consume 20*5M = 100M of RAM in total! If that's the
case, try to use other approaches to processing the file, if possible. Try
to process a line at a time and print it back to the file. If you need to
modify the file itself, use a temporary file. When finished, overwrite the
source file. Make sure you use a locking mechanism!

<P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H3><A NAME="Copying_Variables_Between_Functi">Copying Variables Between Functions</A></H3></CENTER>
<P>
Now let's talk about passing variables by value. Let's use the example
above, assuming we have no choice but to read the whole file before any
data processing takes place. Now you have some imaginary
<CODE>process()</CODE> subroutine that processes the data and returns it. What happens if you pass
the <CODE>$content</CODE> by value? You have just copied another 5M and the child has grown in size
by <STRONG>another</STRONG> 5M. Watch your swap space! Now multiply it again by factor of 20 you have
200M of wasted RAM, which will apparently be reused, but it's a waste!
Whenever you think the variable can grow bigger than a few Kb, pass it by
reference!

<P>
Once I wrote a script that passed the contents of a little flat file
database to a function that processed it by value -- it worked and it was
fast, but after a time the database became bigger, so passing it by value
was expensive. I had to make the decision whether to buy more memory or to
rewrite the code. It's obvious that adding more memory will be merely a
temporary solution. So it's better to plan ahead and pass variables by
reference, if a variable you are going to pass might eventually become
bigger than you envisage at the time you code the program. There are a few
approaches you can use to pass and use variables passed by reference. For
example:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  my $content = qq{foobarfoobar};
  process(\$content);
  sub process{
    my $r_var = shift; 
    $$r_var =~ s/foo/bar/gs;
      # nothing returned - the variable $content outside has already 
      # been modified
  }</pre>
        </td>
	    
      </tr>
    </table>
    <P>
If you work with arrays or hashes it's:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  @{$var_lr}  dereferences an array
  %{$var_hr}  dereferences a hash</pre>
        </td>
	    
      </tr>
    </table>
    <P>
We can still access individual elements of arrays and hashes that we have a
reference to without dereferencing them:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  $var_lr-&gt;[$index]  get $index'th element of an array via a ref
  $var_hr-&gt;{$key}    get $key'th element of a hash via a ref</pre>
        </td>
	    
      </tr>
    </table>
    <P>
For more information see <CODE>perldoc perlref</CODE>.

<P>
Another approach would be to use the <CODE>@_</CODE> array directly. This has the effect of passing by reference:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  process($content);
  sub process{
    $_[0] =~ s/foo/bar/gs;
      # nothing returned - the variable $content outside has been
      # already modified
  }</pre>
        </td>
	    
      </tr>
    </table>
    <P>
From <CODE>perldoc perlsub</CODE>:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>      The array @_ is a local array, but its elements are aliases for
      the actual scalar parameters.  In particular, if an element
      $_[0] is updated, the corresponding argument is updated (or an
      error occurs if it is not possible to update)...</pre>
        </td>
	    
      </tr>
    </table>
    <P>
Be careful when you write this kind of subroutine, since it can confuse a
potential user. It's not obvious that call like
<CODE>process($content);</CODE> modifies the passed variable. Programmers (the users of your library in
this case) are used to subroutines that either modify variables passed by
reference or expressly return a result (e.g. <CODE>$content=process($content);</CODE>).

<P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H3><A NAME="Work_With_Databases">Work With Databases</A></H3></CENTER>
<P>
If you do some DB processing, you will often encounter the need to read
lots of records into your program, and then print them to the browser after
they are formatted. I won't even mention the horrible case where
programmers read in the whole DB and then use Perl to process it!!! Use a
relational DB and let the SQL do the job, so you get only the records you
need!

<P>
We will use <CODE>DBI</CODE> for this (assume that we are already connected to the DB--refer to <CODE>perldoc DBI</CODE> for a complete reference to the <CODE>DBI</CODE>
module):

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  $sth-&gt;execute;
  while(@row_ary  = $sth-&gt;fetchrow_array) {
        # do DB accumulation into some variable
  }
  # print the output using the the data returned from the DB</pre>
        </td>
	    
      </tr>
    </table>
    <P>
In the example above the httpd_process will grow by the size of the
variables that have been allocated for the records that matched the query.
Again remember to multiply it by the number of the children your server
runs!

<P>
A better approach is not to accumulate the records, but rather to print
them as they are fetched from the DB. Moreover, we will use the
<CODE>bind_col()</CODE> and <CODE>$sth-&gt;fetchrow_arrayref()</CODE> (aliased to
<CODE>$sth-&gt;fetch()</CODE>) methods, to fetch the data in the fastest possible way. The example below
prints an HTML table with matched data, the only memory that is being used
is a <CODE>@cols</CODE> array to hold temporary row values. The table will be rendered by the
client browser only when the whole table will be out though.

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  my @select_fields = qw(a b c);
      # create a list of cols values
  my @cols = ();
  @cols[0..$#select_fields] = ();
  $sth = $dbh-&gt;prepare($do_sql);
  $sth-&gt;execute;
    # Bind perl variables to columns.
  $sth-&gt;bind_columns(undef,\(@cols));
  print &quot;&lt;TABLE&gt;&quot;;
  while($sth-&gt;fetch) {
     print &quot;&lt;TR&gt;&quot;,
           map(&quot;&lt;TD&gt;$_&lt;/TD&gt;&quot;, @cols),
           &quot;&lt;/TR&gt;&quot;;
  }
  print &quot;&lt;/TABLE&gt;&quot;;</pre>
        </td>
	    
      </tr>
    </table>
    <P>
Note: the above method doesn't allow you to know how many records have been
matched. The workaround is to run an identical query before the code above
where you use <CODE>SELECT count(*) ...</CODE> instead of <CODE>'SELECT *
...</CODE>, to get the number of matched records. It should be much faster, since you
can remove any <STRONG>SORTBY</STRONG> and similar attributes.

<P>
For those who think that <STRONG>$sth-&gt;rows</STRONG> will do the job, here is the quote from the <CODE>DBI</CODE> manpage:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  rows();</pre>
        </td>
	    
      </tr>
    </table>
    <P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  $rv = $sth-&gt;rows;</pre>
        </td>
	    
      </tr>
    </table>
    <P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  Returns the number of rows affected by the last database altering
  command, or -1 if not known or not available.  Generally you can
  only rely on a row count after a do or non-select execute (for some
  specific operations like update and delete) or after fetching all
  the rows of a select statement.</pre>
        </td>
	    
      </tr>
    </table>
    <P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  For select statements it is generally not possible to know how many
  rows will be returned except by fetching them all.  Some drivers
  will return the number of rows the application has fetched so far
  but others may return -1 until all rows have been fetched. So use of
  the rows method with select statements is not recommended.</pre>
        </td>
	    
      </tr>
    </table>
    <P>
As a bonus, I wanted to write a single sub that flexibly processes any
query. It would accept conditions, a call-back closure sub, select fields
and restrictions.

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  # Usage:
  # $o-&gt;dump(\%conditions,\&amp;callback_closure,\@select_fields,@restrictions);
  #
  sub dump{
    my $self = shift;
    my %param = %{+shift}; # dereference hash
    my $rsub = shift;
    my @select_fields = @{+shift}; # dereference list
    my @restrict = shift || '';
  
      # create a list of cols values
    my @cols = ();
    @cols[0..$#select_fields] = ();
  
    my $do_sql = '';
    my @where = ();
  
      # make a @where list 
    map { push @where, &quot;$_=\'$param{$_}\'&quot; if $param{$_};} keys %param;
  
      # prepare the sql statement
    $do_sql = &quot;SELECT &quot;;
    $do_sql .= join(&quot; &quot;, @restrict) if @restrict;    # append restriction list
    $do_sql .= &quot; &quot; .join(&quot;,&quot;, @select_fields) ;      # append select list 
    $do_sql .= &quot; FROM $DBConfig{TABLE} &quot;;            # from table
  
      # we will not add the WHERE clause if @where is empty
    $do_sql .= &quot; WHERE &quot; . join &quot; AND &quot;, @where if @where;
  
    print &quot;SQL: $do_sql \n&quot; if $debug;
  
    $dbh-&gt;{RaiseError} = 1;     # do this, or check every call for errors
    $sth = $dbh-&gt;prepare($do_sql);
    $sth-&gt;execute;
      # Bind perl variables to columns.
    $sth-&gt;bind_columns(undef,\(@cols));
    while($sth-&gt;fetch) {
      &amp;$rsub(@cols);
    }
      # print the tail or &quot;no records found&quot; message
      # according to the previous calls
    &amp;$rsub();
  
  } # end of sub dump</pre>
        </td>
	    
      </tr>
    </table>
    <P>
Now a callback closure sub can do lots of things. We need a closure to know
what stage are we in: header, body or tail. For example, we want a callback
closure for formatting the rows to print: 

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  my $rsub = eval {
      # make a copy of @fields list, since it might go
      # out of scope when this closure is called
    my @fields = @fields; 
    my @query_fields = qw(user dir tool act);   # no date field!!!
    my $header = 0;
    my $tail   = 0;
    my $counter = 0;
    my %cols = ();                     # columns name=&gt; value hash
  
    # Closure with the following behavior:
    # 1. Header's code will be executed on the first call only and
    #    if @_ was set
    # 2. Row's printing code will be executed on every call with @_ set
    # 3. Tail's code will be executed only if Header's code was
    #    printed and @_ isn't set
    # 4. &quot;No record found&quot; code will be executed if Header's code
    #    wasn't executed
  
    sub {
          # Header
        if (@_ and !$header){
          print &quot;&lt;TABLE&gt;\n&quot;;
          print $q-&gt;Tr(map{ $q-&gt;td($_) } @fields );
          $header = 1; 
        }
        
          # Body
        if (@_) {
          print $q-&gt;Tr(map{$q-&gt;td($_)} @_ );
          $counter++;
          return; 
        }
        
          # Tail, will be printed only at the end
        if ($header and !($tail or @_)){
          print &quot;&lt;/TABLE&gt;\n $counter records found&quot;;
          $tail = 1;
          return;
        }
        
          # No record found
        unless ($header){
          print $q-&gt;p($q-&gt;center($q-&gt;b(&quot;No record was found!\n&quot;)));
        }
  
      }  #  end of sub {}
  };  #  end of my $rsub = eval {</pre>
        </td>
	    
      </tr>
    </table>
    <P>
You might also want to check the section <A HREF="././performance.html#Limiting_the_Size_of_the_Process">Limiting the Size of the Processes</A>
and <A HREF="././performance.html#Limiting_Other_Resources_Used_by">Limiting Other Resources Used by Apache Child Processes</A>.

<P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H2><A NAME="Keeping_the_Shared_Memory_Limit">Keeping the Shared Memory Limit</A></H2></CENTER>
<P>
As we have discussed already, during the child process' life a part of the
memory pages becomes unshared as some data structures become
<EM>"dirty"</EM> leading to the increased real memory consuming. As you remember to prevent
from the process from growing, it should be killed and the newly started
process will have all its memory shared with the parent process. While it
serves requests the unsharing process repeats and it has to be replaced
again.

<P>
As you remember the <CODE>MaxRequestsPerChild</CODE> directive allows you to specify the number of requests the server should
process before it gets killed. So you have to tune this directive, by
finding the optimal value using which, the process won't get too much
unshared memory. But this is very inconvenient solution since chances are
that your service is undergoing constant changes and you will have to
re-tune this number again and again to adapt to the ever changing code
base.

<P>
It would be so nice if we could just set some guardian to watch the shared
size and kill the process based on the actual shared memory usage, when it
goes below the specified limit, so it's possible that the processes will
never be killed if there limit is never passed.

<P>
That's where the <CODE>Apache::GTopLimit</CODE> module comes to help. If you are lucky to have your OS among those that can
build the
<A HREF="././download.html#libgtop">libgtop</A> library, you will be able to build the
<CODE>GTop</CODE> module that provides the Perl API for <CODE>libgtop</CODE>, which in turn used by <CODE>Apache::GTopLimit</CODE> (that's the <EM>GTop</EM> part in the name).

<P>
To set the shared memory lower limit of 4MB using the
<CODE>Apache::GTopLimit</CODE> add the following code into the <EM>startup.pl</EM>
file:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  use Apache::GTopLimit;
  $Apache::GTopLimit::MIN_PROCESS_SHARED_SIZE = 4096;</pre>
        </td>
	    
      </tr>
    </table>
    <P>
and in <EM>httpd.conf</EM>:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  PerlFixupHandler Apache::GTopLimit</pre>
        </td>
	    
      </tr>
    </table>
    <P>
and don't forget to restart the server for the changes to take the effect.

<P>
If you don't want to set this limit by default but only for those requests
that are likely to get the memory unshared. In this case the memory size
testing would be be done only if you decide that you want it. You register
the post-processing check by using the <CODE>set_min_shared_size()</CODE>
function. For example:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>    use Apache::GTopLimit;
    if ($need_to_limit){
      Apache::GTopLimit-&gt;set_min_shared_size(4096);
    }</pre>
        </td>
	    
      </tr>
    </table>
    <P>
Since accessing the process info might add a little overhead, you may want
to only check the process size every N times. And that's where the <CODE>$Apache::GTopLimit::CHECK_EVERY_N_REQUESTS</CODE> variable comes to help. For example to test the size every other time--put
in your
<EM>startup.pl</EM>:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  $Apache::GTopLimit::CHECK_EVERY_N_REQUESTS = 2;</pre>
        </td>
	    
      </tr>
    </table>
    <P>
If you want to run this module in the debug mode, add the following
directive in your <EM>startup.pl</EM>:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  $Apache::GTopLimit::DEBUG = 1;</pre>
        </td>
	    
      </tr>
    </table>
    <P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H2><A NAME="Limiting_the_Size_of_the_Process">Limiting the Size of the Processes</A></H2></CENTER>
<P>
So now you know how to prevent processes from consuming more real memory
when the memory gets unshared. An even more important restriction that we
want to impose is the absolute size of the process. If the process grows
after each request, especially if your code has memory leaks or you are
unfortunate to run an OS with C libraries that leak memory, you can easily
run out of memory if nothing will restrict those processes from growing.
The only restriction we can impose is killing the processes when they
become too big.

<P>
You can set the <CODE>MaxRequestPerChild</CODE> directive to kill the processes after only a few requests have been served.
But as we have explained in the previous section this solution is not as
good as the ability to control the process size and killing it only when
the limit is crossed.

<P>
If you have the <CODE>Apache::GTopLimit</CODE> we have described in the previous section you can control the upper limit
by setting the
<CODE>$Apache::GTopLimit::MAX_PROCESS_SIZE</CODE> directive. For example if you want the processes to be killed when they are
growing bigger than 10MB you should set the following limit in the <EM>startup.pl</EM> file:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>    $Apache::GTopLimit::MAX_PROCESS_SIZE = 10240;</pre>
        </td>
	    
      </tr>
    </table>
    <P>
Just like with the shared memory limiting, you can set the limit for the
current process using the <CODE>set_max_size()</CODE> method in your code:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>    use Apache::GTopLimit;
    Apache::GTopLimit-&gt;set_max_size(10000);</pre>
        </td>
	    
      </tr>
    </table>
    <P>
Another alternative is to use the <CODE>Apache::SizeLimit</CODE> module, which is available for more platforms than <CODE>Apache::GTopLimit</CODE> at the moment of this writing. You should check the module's manpage to
find out what they are.

<P>
To usage is very similar to <CODE>Apache::GTopLimit</CODE>, you control the upper size limit by setting the
<CODE>$Apache::SizeLimit::MAX_PROCESS_SIZE</CODE> variable in your <EM>startup.pl</EM>
file:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  use Apache::SizeLimit;
  $Apache::SizeLimit::MAX_PROCESS_SIZE = 10240; </pre>
        </td>
	    
      </tr>
    </table>
    <P>
And in your <EM>httpd.conf</EM> you should add:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  PerlFixupHandler Apache::SizeLimit</pre>
        </td>
	    
      </tr>
    </table>
    <P>
Just like with <CODE>Apache::GTopLimit</CODE>, you can test the memory every few times, by setting the <CODE>$Apache::SizeLimit::CHECK_EVERY_N_REQUESTS</CODE>
variable. For example every fourth time:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  $Apache::SizeLimit::CHECK_EVERY_N_REQUESTS = 4;</pre>
        </td>
	    
      </tr>
    </table>
    <P>
And you can set the limit from within your code, rather from the global
configuration:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  use Apache::SizeLimit;
  Apache::SizeLimit-&gt;setmax(10240);</pre>
        </td>
	    
      </tr>
    </table>
    <P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H2><A NAME="Limiting_Other_Resources_Used_by">Limiting Other Resources Used by Apache Child Processes</A></H2></CENTER>
<P>
In addition to the absolute and shared memory sizes limiting, you might
need to prevent the processes from excessive consumption of the system
resources. Like limiting the CPU usage, the number of files that can be
opened, or memory segment usage and more.

<P>
The <CODE>Apache::Resource</CODE> module allows this all by deploying the
<CODE>BSD::Resource</CODE> module, which in turn uses the C function
<CODE>setrlimit()</CODE> to set limits on system resources.

<P>
A resource limit is specified as a soft limit and a hard limit. When a soft
limit is exceeded a process may receive a signal (for example, if the CPU
time or file size is exceeded), but it will be allowed to continue
execution until it reaches the hard limit (or modifies its resource limit).
The rlimit structure is used to specify the hard and soft limits on a
resource. (See the manpage for <EM>setrlimit</EM> for your OS specific information.)

<P>
If the value of the variable is of the form <CODE>S:H</CODE>, <CODE>S</CODE> is treated as the soft limit, and <CODE>H</CODE> is the hard limit. If it is just a single number, it is used for both soft
and hard limits. So if you set
<CODE>10:20</CODE>, the soft limit is 10 and the hard limit is 20. If you set just <CODE>10</CODE>--both the soft and the hard limits are set to 20.

<P>
The mostly spread usage of this module is to limit the CPU usage. The
environment variable <CODE>PERL_RLIMIT_CPU</CODE> defines the maximum amount of CPU time the process can use. If it runs for
longer than this, it gets killed, no matter what it does, either processing
a new request or just waiting. This is very useful when you have a code
with a bug and the process starts to spin in an endless loop or alike using
a lot of CPU and never completing the request. 

<P>
META: verify this.

<P>
The value is measured in seconds. The following example sets the soft limit
of the CPU usage to 120 seconds (the default is 360).

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  PerlModule Apache::Resource
  PerlSetEnv PERL_RLIMIT_CPU 120</pre>
        </td>
	    
      </tr>
    </table>
    <P>
Of course you should tell mod_perl to use this module, which is done by
adding the following directive to <EM>httpd.conf</EM>:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  PerlChildInitHandler Apache::Resource</pre>
        </td>
	    
      </tr>
    </table>
    <P>
There are other resources that you might want to limit. For example you can
limit the memory data and stack segment sizes (<CODE>PERL_RLIMIT_DATA</CODE> and <CODE>PERL_RLIMIT_STACK</CODE>), the maximum process file size (<CODE>PERL_RLIMIT_FSIZE</CODE>), the core file size (<CODE>PERL_RLIMIT_CORE</CODE>), the address space (virtual memory) limit (<CODE>PERL_RLIMIT_AS</CODE>), etc. Refer to the <CODE>setrlimit(2)</CODE> man page on your OS for
other possible resources. Remember to prepend <CODE>PERL_</CODE> before the resource types you will see in the man page.

<P>
If you configure <CODE>Apache::Status</CODE>, it will let you review the resources set in this way. Remember that <CODE>Apache::Status</CODE> must be loaded before <CODE>Apache::Resource</CODE> in order to enable the resources display menu.

<P>
If you want to set the debug mode set the <CODE>$Apache::Resource::Debug</CODE>
before loading the module, for example by using the Perl sections in
<EM>httpd.conf</EM>.

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  &lt;Perl&gt;
    $Apache::Resource::Debug = 1;
    require Apache::Resource;
  &lt;/Perl&gt;
  PerlChildInitHandler Apache::Resource</pre>
        </td>
	    
      </tr>
    </table>
    <P>
Now open in the <EM>error_log</EM> file using tell and watch the debug messages showing up, when the requests
are served.

<P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H3><A NAME="OS_Specific_notes">OS Specific notes</A></H3></CENTER>
<P>
Note that under Linux <CODE>malloc()</CODE> uses <CODE>mmap()</CODE>
instead of <CODE>brk().</CODE> This is done to conserve virtual memory -
that is, when you malloc a large block of memory, it isn't actually given
to your program until you initialize it. The old-style <CODE>brk()</CODE>
system call obeyed resource limits on data segment size as set in
<CODE>setrlimit()</CODE> - <CODE>mmap()</CODE> doesn't.

<P>
<CODE>Apache::Resource</CODE>'s defaults put caps on data size and stack size. Linux's current memory
allocation scheme doesn't honor these limits, so if you just do

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  PerlSetEnv PERL_RLIMIT_DEFAULTS On
  PerlModule Apache::Resource
  PerlChildInitHandler Apache::Resource</pre>
        </td>
	    
      </tr>
    </table>
    <P>
Your Apache processes are still free to use as much memory as they like.

<P>
However, <CODE>BSD::Resource</CODE> also has a limit called <CODE>RLIMIT_AS</CODE>
(Address Space) which limits the total number of bytes of virtual memory
assigned to a process. Happily, Linux's memory manager <EM>does</EM>
honor this limit.

<P>
Therefore, you <EM>can</EM> limit memory usage under Linux with
<CODE>Apache::Resource</CODE> -- simply add a line to <EM>httpd.conf</EM>:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  PerlSetEnv PERL_RLIMIT_AS  67108864</pre>
        </td>
	    
      </tr>
    </table>
    <P>
This example sets a hard and soft limit of 64MB of total address space.

<P>
Refer to the <CODE>Apache::Resource</CODE> and <CODE>setrlimit(2)</CODE> manpages for more information.

<P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H2><A NAME="Limiting_the_Number_of_Processes">Limiting the Number of Processes Serving the Same Resource</A></H2></CENTER>
<P>
If you want to limit number of Apache children that could simultaneously be
serving the (nearly) same resource, you should take a look at the <A HREF="././download.html#mod_throttle_access"><CODE>mod_throttle_access</CODE></A>
module.

<P>
It solves the problem of too many concurrent request accessing the same
URI, if for example the handler that serves this URI uses some resource
that has a limitation on the maximum number of possible users or the
handlers code is very CPU intensive and you cannot afford more than a
certain number of concurrent requests to this specific URI.

<P>
Imagine that your service provides the three following URIs:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  /perl/news/
  /perl/webmail/
  /perl/morphing/</pre>
        </td>
	    
      </tr>
    </table>
    <P>
The first two URIs are response critical as people want to read news and
their email. The third URI is very CPU and RAM intensive image morphing
service, provided as a bonus to your users. Since you don't want users to
abuse this service, you have to set some limits on the number of concurrent
requests for this resource, since if you don't--the other two critical
resources can be hurt.

<P>
When you compile in and enable the Apache mod_throttle_access module, the <CODE>MaxConcurrentReqs</CODE> directive becomes available. For example, the following setting:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  &lt;Location &quot;/perl/morphing&quot;&gt;
    &lt;Limit PUT GET POST&gt;
      MaxConcurrentReqs 10
    &lt;/Limit&gt;
  &lt;/Location&gt; </pre>
        </td>
	    
      </tr>
    </table>
    <P>
will allow only 10 concurrent PUT, GET or POST requests under the URI
<EM>/perl/morphing</EM> to be processed at one time. The other two URIs remain unlimited.

<P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H2><A NAME="Limiting_the_Request_Rate_Speed_">Limiting the Request Rate Speed (Robot Blocking)</A></H2></CENTER>
<P>
A limitation of using pattern matching to identify robots is that it only
catches the robots that you know about, and then only those that identify
themselves by name. A few devious robots masquerade as users by using user
agent strings that identify themselves as conventional browsers. To catch
such robots, you'll have to be more sophisticated.

<P>
<CODE>Apache::SpeedLimit</CODE> comes to your aid, see:

<P>
<A
HREF="http://www.modperl.com/chapters/ch6.html#Blocking_Greedy_Clients">http://www.modperl.com/chapters/ch6.html#Blocking_Greedy_Clients</A>


<P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H1><A NAME="Perl_Modules_for_Performance_Imp">Perl Modules for Performance Improvement</A></H1></CENTER>
<P>
These sections are about Perl modules that improve performance without
requiring changes to your code. Mostly you just need to tweak the
configuration file to plug these modules in.

<P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H2><A NAME="Sending_Plain_HTML_as_Compressed">Sending Plain HTML as Compressed Output</A></H2></CENTER>
<P>
See <A HREF="././modules.html#Apache_GzipChain_compress_HTM">Apache::GzipChain - compress HTML (or anything) in the OutputChain</A>



<P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H2><A NAME="Caching_Components_with_HTML_Ma">Caching Components with HTML::Mason</A></H2></CENTER>
<P>
META: complete the full description

<P>
<CODE>HTML::Mason</CODE> is a system that makes use of components to build HTML pages.

<P>
If most of your output is generated dynamically, but each finished page can
be separated into different components, <CODE>HTML::Mason</CODE> can cache those components. This can really improve the performance of your
service and reduce the load on the system.

<P>
Say for example that you have a page consisting of five components, each
generated by a different SQL query, but for four of the five components
it's the same four queries for each user so you don't have to rerun them
again and again. Only one component is generated by a unique query and will
not use the cache.

<P>
META: HTML::Mason docs (v 8.0) said Mason was 2-3 times slower than pure
mod_perl, implying that the power &amp; convenience made up for this.

<P>
META: Should also mention Embperl (especially since its C + XS)

<P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H1><A NAME="Efficient_Work_with_Databases_un">Efficient Work with Databases under mod_perl</A></H1></CENTER>
<P>
Most of the mod_perl enabled servers work with database engines, so in this
section we will learn about two things: how mod_perl makes working with
databases faster and a few tips for a more efficient DBI coding in Perl.
(DBI provides an identical Perl interface to many database
implementations.)

<P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H2><A NAME="Persistent_DB_Connections">Persistent DB Connections</A></H2></CENTER>
<P>
Another popular use of mod_perl is to take advantage of its ability to
maintain persistent open database connections.

<P>
You want to have a persistent database connection because the the most
expensive part of a network transaction for most databases is the business
of building and tearning down connections.

<P>
Of course the persistence doesn't help with the latency problems during the
actual use of the database connections. Oracle is notoriously
latency-sensitive which in most cases generates a network transaction per
row returned which slows things down if the query execution matches many
rows. You may want to read the Tim Bunce's Advanced DBI talk at <A
HREF="http://www.carumba.com/talk/perl/DBI_Talk3_1999/">http://www.carumba.com/talk/perl/DBI_Talk3_1999/</A>
which covers a lot of techniques to reduce latency.

<P>
So here is the basic approach of making the connection persistent:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  # Apache::Registry script
  -------------------------
  use strict;
  use vars qw($dbh);
  
  $dbh ||= SomeDbPackage-&gt;connect(...);</pre>
        </td>
	    
      </tr>
    </table>
    <P>
Since <CODE>$dbh</CODE> is a global variable for the child, once the child has opened the
connection it will use it over and over again, unless you perform <CODE>disconnect()</CODE>.

<P>
Be careful to use different names for handlers if you open connections to
different databases!

<P>
<CODE>Apache::DBI</CODE> allows you to make a persistent database connection. With this module
enabled, every <CODE>connect()</CODE> request to the plain
<CODE>DBI</CODE> module will be forwarded to the <CODE>Apache::DBI</CODE> module. This looks to see whether a database handle from a previous <CODE>connect()</CODE>
request has already been opened, and if this handle is still valid using
the ping method. If these two conditions are fulfilled it just returns the
database handle. If there is no appropriate database handle or if the ping
method fails, a new connection is established and the handle is stored for
later re-use.  <STRONG>There is no need to
delete the <CODE>disconnect()</CODE> statements from your code</STRONG>. They will not do anything, the <CODE>Apache::DBI</CODE> module overloads the <CODE>disconnect()</CODE>
method with a NOP. When a child exits there is no explicit disconnect, the
child dies and so does the database connection. You may leave the <CODE>use DBI;</CODE> statement inside the scripts as well.

<P>
The usage is simple -- add to <EM>httpd.conf</EM>:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  PerlModule Apache::DBI</pre>
        </td>
	    
      </tr>
    </table>
    <P>
It is important to load this module before any other <CODE>DBI</CODE>,
<CODE>DBD::*</CODE> and <CODE>ApacheDBI*</CODE> modules!

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  db.pl
  ------------
  use DBI ();
  use strict;
  
  my $dbh = DBI-&gt;connect( 'DBI:mysql:database', 'user', 'password',
                          { autocommit =&gt; 0 }
                        ) || die $DBI::errstr;
  
  ...rest of the program</pre>
        </td>
	    
      </tr>
    </table>
    <P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H3><A NAME="Preopening_Connections_at_the_Ch">Preopening Connections at the Child Process' Fork Time</A></H3></CENTER>
<P>
If you use <CODE>DBI</CODE> for DB connections, and you use <CODE>Apache::DBI</CODE> to make them persistent, it also allows you to preopen connections to the
DB for each child with the <CODE>connect_on_init()</CODE> method, thus saving a connection overhead on the very first request of
every child.

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  use Apache::DBI ();
  Apache::DBI-&gt;connect_on_init(&quot;DBI:mysql:test&quot;,
                               &quot;login&quot;,
                               &quot;passwd&quot;,
                               {
                                RaiseError =&gt; 1,
                                PrintError =&gt; 0,
                                AutoCommit =&gt; 1,
                               }
                              );</pre>
        </td>
	    
      </tr>
    </table>
    <P>
This is a simple way to have Apache children establish connections on
server startup. This call should be in a startup file <CODE>require()d</CODE>
by <CODE>PerlRequire</CODE> or inside a &lt;Perl&gt; section. It will establish a connection when a child is started in
that child process. See the
<CODE>Apache::DBI</CODE> manpage for the requirements for this method.

<P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H3><A NAME="Caching_prepare_Statements">Caching prepare() Statements</A></H3></CENTER>
<P>
You can also benefit from persistent connections by replacing
<CODE>prepare()</CODE> with <CODE>prepare_cached().</CODE> That way you
will always be sure that you have a good statement handle and you will get
some caching benefit. The downside is that you are going to pay for DBI to
parse your SQL and do a cache lookup every time you call
<CODE>prepare_cached().</CODE>

<P>
Be warned that some databases (e.g PostgreSQL and Sybase) don't support
caches of prepared plans. With Sybase you could open multiple connections
to achieve the same result, although this is at the risk of getting
deadlocks depending on what you are trying to do!

<P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H2><A NAME="mod_perl_Database_Performance_Im">mod_perl Database Performance Improving</A></H2></CENTER>
<P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H3><A NAME="Analysis_of_the_Problem">Analysis of the Problem</A></H3></CENTER>
<P>
A common web application architecture is one or more application servers
which handle requests from client browsers by consulting one or more
database servers and performing a transform on the data. When an
application must consult the database on every request, the interaction
with the database server becomes the central performance issue. Spending a
bit of time optimizing your database access can result in significant
application performance improvements. In this analysis, a system using
Apache, mod_perl, <CODE>DBI</CODE>, and Oracle will be considered. The application server uses Apache and
mod_perl to service client requests, and <CODE>DBI</CODE> to communicate with a remote Oracle database.

<P>
In the course of servicing a typical client request, the application server
must retrieve some data from the database and execute a stored procedure.
There are several steps that need to be performed to complete the request:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre> 1: Connect to the database server
 2: Prepare a SQL SELECT statement
 3: Execute the SELECT statement
 4: Retrieve the results of the SELECT statement
 5: Release the SELECT statement handle
 6: Prepare a PL/SQL stored procedure call
 7: Execute the stored procedure
 8: Release the stored procedure statement handle
 9: Commit or rollback
 10: Disconnect from the database server</pre>
        </td>
	    
      </tr>
    </table>
    <P>
In this document, an application will be described which achieves maximum
performance by eliminating some of the steps above and optimizing others.

<P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H3><A NAME="Optimizing_Database_Connections">Optimizing Database Connections</A></H3></CENTER>
<P>
A naive implementation would perform steps 1 through 10 from above on every
request. A portion of the source code might look like this:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  # ...
  my $dbh = DBI-&gt;connect('dbi:Oracle:host', 'user', 'pass')
        || die $DBI::errstr;
  
  my $baz = $r-&gt;param('baz');
  
  eval {
        my $sth = $dbh-&gt;prepare(qq{
                SELECT foo 
                  FROM bar 
                 WHERE baz = $baz
        });
        $sth-&gt;execute;
  
        while (my @row = $sth-&gt;fetchrow_array) {
                # do HTML stuff
        }
        
        $sth-&gt;finish;
  
        my $sph = $dbh-&gt;prepare(qq{
                BEGIN
                        my_procedure(
                                arg_in =&gt; $baz
                        );
                END;
        });
        $sph-&gt;execute;
        $sph-&gt;finish;
        
        $dbh-&gt;commit;
  };
  if ($@) {
        $dbh-&gt;rollback;
  }
  
  $dbh-&gt;disconnect;
  # ...</pre>
        </td>
	    
      </tr>
    </table>
    <P>
In practice, such an implementation would have hideous performance
problems. The majority of the execution time of this program would likely
be spent connecting to the database. An examination shows that step 1 is
comprised of many smaller steps:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre> 1: Connect to the database server
 1a: Build client-side data structures for an Oracle connection
 1b: Look up the server's alias in a file
 1c: Look up the server's hostname
 1d: Build a socket to the server
 1e: Build server-side data structures for this connection</pre>
        </td>
	    
      </tr>
    </table>
    <P>
The naive implementation waits for all of these steps to happen, and then
throws away the database connection when it is done! This is obviously
wasteful, and easily rectified. The best solution is to hoist the database
connection step out of the per-request lifecycle so that more than one
request can use the same database connection. This can be done by
connecting to the database server once, and then not disconnecting until
the Apache child process exits. The
<CODE>Apache::DBI</CODE> module does this transparently and automatically with little effort on the
part of the programmer.

<P>
<CODE>Apache::DBI</CODE> intercepts calls to <CODE>DBI</CODE>'s connect and disconnect methods and replaces them with its own.  <CODE>Apache::DBI</CODE> caches database connections when they are first opened, and it ignores
disconnect commands. When an application tries to connect to the same
database, <CODE>Apache::DBI</CODE> returns a cached connection, thus saving the significant time penalty of
repeatedly connecting to the database. You will find a full treatment of <CODE>Apache::DBI</CODE> at <A HREF="././performance.html#Persistent_DB_Connections">Persistent DB Connections</A>



<P>
When <CODE>Apache::DBI</CODE> is in use, none of the code in the example needs to change. The code is
upgraded from naive to respectable with the use of a simple module! The
first and biggest database performance problem is quickly dispensed with.

<P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H3><A NAME="Utilizing_the_Database_Server_s_">Utilizing the Database Server's Cache</A></H3></CENTER>
<P>
Most database servers, including Oracle, utilize a cache to improve the
performance of recently seen queries. The cache is keyed on the SQL
statement. If a statement is identical to a previously seen statement, the
execution plan for the previous statement is reused. This can be a
considerable improvement over building a new statement execution plan.

<P>
Our respectable implementation from the last section is not making use of
this caching ability. It is preparing the statement: 

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  SELECT foo FROM bar WHERE baz = $baz</pre>
        </td>
	    
      </tr>
    </table>
    <P>
The problem is that <CODE>$baz</CODE> is being read from an HTML form, and is therefore likely to change on every
request. When the database server sees this statement, it is going to look
like:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  SELECT foo FROM bar WHERE baz = 1</pre>
        </td>
	    
      </tr>
    </table>
    <P>
and on the next request, the SQL will be:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  SELECT foo FROM bar WHERE baz = 42</pre>
        </td>
	    
      </tr>
    </table>
    <P>
Since the statements are different, the database server will not be able to
reuse its execution plan, and will proceed to make another one. This
defeats the purpose of the SQL statement cache.

<P>
The application server needs to make sure that SQL statements which are the
same look the same. The way to achieve this is to use placeholders and
bound parameters. The placeholder is a blank in the SQL statement, which
tells the database server that the value will be filled in later. The bound
parameter is the value which is inserted into the blank before the
statement is executed.

<P>
With placeholders, the SQL statement looks like: 

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  SELECT foo FROM bar WHERE baz = :baz</pre>
        </td>
	    
      </tr>
    </table>
    <P>
Regardless of whether <CODE>baz</CODE> is 1 or 42, the SQL always looks the same, and the database server can
reuse its cached execution plan for this statement. This technique has
eliminated the execution plan generation penalty from the per-request
runtime. The potential performance improvement from this optimization could
range from modest to very significant.

<P>
Here is the updated code fragment which employs this optimization:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  # ...
  my $dbh = DBI-&gt;connect('dbi:Oracle:host', 'user', 'pass')
        || die $DBI::errstr;
  
  my $baz = $r-&gt;param('baz');
  
  eval {
        my $sth = $dbh-&gt;prepare(qq{
                SELECT foo 
                  FROM bar 
                 WHERE baz = :baz
        });
        $sth-&gt;bind_param(':baz', $baz);
        $sth-&gt;execute;
  
        while (my @row = $sth-&gt;fetchrow_array) {
                # do HTML stuff
        }
        
        $sth-&gt;finish;
  
        my $sph = $dbh-&gt;prepare(qq{
                BEGIN
                        my_procedure(
                                arg_in =&gt; :baz
                        );
                END;
        });
        $sph-&gt;bind_param(':baz', $baz);
        $sph-&gt;execute;
        $sph-&gt;finish;
        
        $dbh-&gt;commit;
  };
  if ($@) {
        $dbh-&gt;rollback;
  }
  # ...</pre>
        </td>
	    
      </tr>
    </table>
    <P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H3><A NAME="Eliminating_SQL_Statement_Parsin">Eliminating SQL Statement Parsing</A></H3></CENTER>
<P>
The example program has certainly come a long way and the performance is
now probably much better than that of the first revision. However, there is
still more speed that can be wrung out of this server architecture. The
last bottleneck is in SQL statement parsing. Every time <CODE>DBI</CODE>'s <CODE>prepare()</CODE> method is called, <CODE>DBI</CODE> parses the SQL command looking for placeholder strings, and does some
housekeeping work. Worse, a context has to be built on the client and
server sides of the connection which the database will use to refer to the
statement. These things take time, and by eliminating these steps the time
can be saved.

<P>
To get rid of the statement handle construction and statement parsing
penalties, we could use <CODE>DBI</CODE>'s <CODE>prepare_cached()</CODE> method. This method compares the SQL
statement to others that have already been executed. If there is a match,
the cached statement handle is returned. But the application server is
still spending time calling an object method (very expensive in Perl), and
doing a hash lookup. Both of these steps are unnecessary, since the SQL is
very likely to be static and known at compile time. The smart programmer
can take advantage of these two attributes to gain better database
performance. In this example, the database statements will be prepared
immediately after the connection to the database is made, and they will be
cached in package scalars to eliminate the method call.

<P>
What is needed is a routine that will connect to the database and prepare
the statements. Since the statements are dependent upon the connection, the
integrity of the connection needs to be checked before using the
statements, and a reconnection should be attempted if needed. Since the
routine presented here does everything that
<CODE>Apache::DBI</CODE> does, it does not use <CODE>Apache::DBI</CODE> and therefore has the added benefit of eliminating a cache lookup on the
connection.

<P>
Here is an example of such a package:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  package My::DB;
  
  use strict;
  use DBI ();
  
  sub connect {
        if (defined $My::DB::conn) {
                eval {
                        $My::DB::conn-&gt;ping;
                };
                if (!$@) {
                        return $My::DB::conn;
                }
        }
  
        $My::DB::conn = DBI-&gt;connect(
                'dbi:Oracle:server', 'user', 'pass', {
                        PrintError =&gt; 1,
                        RaiseError =&gt; 1,
                        AutoCommit =&gt; 0
                }
        ) || die $DBI::errstr; #Assume application handles this
  
        $My::DB::select = $My::DB::conn-&gt;prepare(q{
                SELECT foo
                  FROM bar
                 WHERE baz = :baz
        });
        
        $My::DB::procedure = $My::DB::conn-&gt;prepare(q{
                BEGIN
                        my_procedure(
                                arg_in =&gt; :baz
                        );
                END;
        });
  
        return $My::DB::conn;
  }
  
  1;</pre>
        </td>
	    
      </tr>
    </table>
    <P>
Now the example program needs to be modified to use this package.

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  # ...
  my $dbh = My::DB-&gt;connect;
  
  my $baz = $r-&gt;param('baz');
  
  eval {
        my $sth = $My::DB::select;
        $sth-&gt;bind_param(':baz', $baz);
        $sth-&gt;execute;
  
        while (my @row = $sth-&gt;fetchrow_array) {
                # do HTML stuff
        }
  
        my $sph = $My::DB::procedure;
        $sph-&gt;bind_param(':baz', $baz);
        $sph-&gt;execute;
         
        $dbh-&gt;commit;
  };
  if ($@) {
        $dbh-&gt;rollback;
  }
  # ...</pre>
        </td>
	    
      </tr>
    </table>
    <P>
Notice that several improvements have been made. Since the statement
handles have a longer life than the request, there is no need for each
request to prepare the statement, and no need to call the statement
handle's finish method. Since <CODE>Apache::DBI</CODE> and the <CODE>prepare_cached()</CODE> method are not used, no cache lookups
are needed.

<P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H3><A NAME="Conclusion">Conclusion</A></H3></CENTER>
<P>
The number of steps needed to service the request in the example system has
been reduced significantly. In addition, the hidden cost of building and
tearing down statement handles and of creating query execution plans is
removed. Compare the new sequence with the original:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre> 1: Check connection to database
 2: Bind parameter to SQL SELECT statement
 3: Execute SELECT statement
 4: Fetch rows
 5: Bind parameters to PL/SQL stored procedure
 6: Execute PL/SQL stored procedure
 7: Commit or rollback</pre>
        </td>
	    
      </tr>
    </table>
    <P>
It is probably possible to optimize this example even further, but I have
not tried. It is very likely that the time could be better spent improving
your database indexing scheme or web server buffering and load balancing.

<P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H1><A NAME="Using_3rd_Party_Applications">Using 3rd Party Applications</A></H1></CENTER>
<P>
It's been said that no one can do everything well, but one can do something
specific extremely well. This seems to be true for many software
applications, when you don't try to do everything but instead concentrate
on something specific you can do it really well.

<P>
Based on the above introduction, while the mod_perl server can do many many
things, there are other applications (or Apache server modules) that can do
some specific operations faster or do a really great job for the mod_perl
server by unloading it when doing some operations by themselves.

<P>
Let's take a look at a few of these.

<P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H2><A NAME="Proxying_the_mod_perl_Server">Proxying the mod_perl Server</A></H2></CENTER>
<P>
Proxy gives you a great performance increase in most cases. It's discussed
in the section <A HREF="././strategy.html#Adding_a_Proxy_Server_in_http_Ac">Adding a Proxy Server in http Accelerator Mode</A>.

<P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H1><A NAME="Upload_and_Download_of_Big_Files">Upload and Download of Big Files</A></H1></CENTER>
<P>
You don't want to tie up your precious mod_perl backend server children
doing something as long and simple as transfering a file, especially a big
one. The overhead saved by mod_perl is typically under one second, which is
an enormous saving for the scripts whose run time is under one second. The
user won't really see any important performance benefits from mod_perl,
since the upload may take up to several minutes.

<P>
If some particular script's main functionality is the uploading or
downloading of big files, you probably want it to be executed on a plain
apache server under mod_cgi (i.e. performing this operation on the
front-end server, if you use <A HREF="././scenario.html#One_Plain_and_One_mod_perl_enabl">a dual-server setup</A>.

<P>
This of course assumes that the script requires none of the functionality
of the mod_perl server, such as custom authentication handlers.

<P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H1><A NAME="Apache_mod_perl_Build_Options">Apache/mod_perl Build Options</A></H1></CENTER>
<P>
It's important how you build mod_perl enabled Apache. It influences the
size of the httpd executable, some irrelevant modules might slow the
performance.

<P>
[ReaderMETA: Any other building time things that influence performance?]

<P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H2><A NAME="mod_perl_Process_Size_as_a_Funct">mod_perl Process Size as a Function of Compiled in C Modules and mod_perl Features</A></H2></CENTER>
<P>
You might wonder whether it's better to compile in only the required
modules and mod_perl hooks, or it doesn't really matter. To answer on this
question lets first make a few compilation and compare the results.

<P>
So we are going to build mod_perl starting with:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  % perl Makefile.PL APACHE_SRC=../apache_x.x.x/src \
         DO_HTTPD=1 USE_APACI=1</pre>
        </td>
	    
      </tr>
    </table>
    <P>
and followed by one of these option groups:

<OL>
<P><LI><STRONG><A NAME="item_Default">Default</A></STRONG>
<P>
<EM>no arguments</EM>



<P><LI><STRONG><A NAME="item_Minumum">Minumum</A></STRONG>
<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  APACI_ARGS='--disable-module=env, \
              --disable-module=negotiation, \
              --disable-module=status, \
              --disable-module=info, \
              --disable-module=include, \
              --disable-module=autoindex, \
              --disable-module=dir, \
              --disable-module=cgi, \
              --disable-module=asis, \
              --disable-module=imap, \
              --disable-module=userdir, \
              --disable-module=access, \
              --disable-module=auth'</pre>
        </td>
	    
      </tr>
    </table>
    <P><LI><STRONG><A NAME="item_Everything">Everything</A></STRONG>
<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  EVERYTHING=1</pre>
        </td>
	    
      </tr>
    </table>
    <P><LI><STRONG><A NAME="item_Everything_Debug">Everything + Debug</A></STRONG>
<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  EVERYTHING=1 PERL_DEBUG=1</pre>
        </td>
	    
      </tr>
    </table>
    </OL>
<P>
After re-compiling with arguments of each of these groups, we can summarize
the results:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  Build group    httpd size (bytes)  Difference
  ---------------------------------------------
  Minumum              892928         +     0
  Default              994316         +101388
  Everything          1044432         +151504
  Everything+Debug    1162100         +269172</pre>
        </td>
	    
      </tr>
    </table>
    <P>
Indeed when you strip most of the default things, the server size is
slimmer. But the savings are insignificant since you don't muliply the
added size by the number of child processes if your OS supports sharing
memory. The parent processes is a little bigger, but it shares these memory
pages with its child processes. Of course not everything will be shared, if
some module you add does some process memory modification particular to the
process, but the most will.

<P>
And of course this was just an example to show the difference is size. It
doesn't mean that you can everything away, since there will be Apache
modules and mod_perl options that you won't be able to work without.

<P>
But as a good system administrator's rule says: <EM>"Run the absolute
minimum of the applications. If you don't know or need something,
disable it"</EM>. Following this rule to decide on the required Apache components and
disabling the unneeded default components, makes you a good Apache
administrator.

<P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H1><A NAME="Perl_Build_Options">Perl Build Options</A></H1></CENTER>
<P>
The Perl interpreter lays in the brain of the mod_perl server and if we can
optimize perl into doing things faster under mod_perl we make the whole
server faster. Generally, optimizing the Perl interpreter means enabling or
disabling some command line options. Let's see a few important ones.

<P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H2><A NAME="_DTWO_POT_OPTIMIZE_and_DPACK_MA">-DTWO_POT_OPTIMIZE and -DPACK_MALLOC Perl Build Options</A></H2></CENTER>
<P>
Newer Perl versions also have build time options to reduce runtime memory
consumption. These options might shrink the size of your httpd by about
150k -- quite a big number if you remember to multiply it by the number of
chidren you use.

<P>
The <CODE>-DTWO_POT_OPTIMIZE</CODE> macro improves allocations of data with size close to a power of two; but
this works for big allocations (starting with 16K by default). Such
allocations are typical for big hashes and special-purpose scripts,
especially image processing.

<P>
Perl memory allocation is by bucket with sizes close to powers of two.
Because of these the <CODE>malloc()</CODE> overhead may be big, especially
for data of size exactly a power of two. If <CODE>PACK_MALLOC</CODE> is defined, perl uses a slightly different algorithm for small allocations
(up to 64 bytes long), which makes it possible to have overhead down to 1
byte for allocations which are powers of two (and appear quite often).

<P>
Expected memory savings (with 8-byte alignment in <CODE>alignbytes</CODE>) is about 20% for typical Perl usage. Expected slowdown due to additional
<CODE>malloc()</CODE> overhead is in fractions of a percent and hard to
measure, because of the effect of saved memory on speed.

<P>
You will find these and other memory improvement details in
<CODE>perl5004delta.pod</CODE>.

<P>
Important: both options are On by default in perl versions 5.005 and
higher.

<P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H2><A NAME="_Dusemymalloc_Perl_Build_Option">-Dusemymalloc Perl Build Option</A></H2></CENTER>
<P>
You have a choice to use the native or Perl's own <CODE>malloc()</CODE>
implementation. The choice depends on your Operating System. Unless you
know which of the two is better on yours, you better try both and compare
the benchmarks.

<P>
To build without Perl's <CODE>malloc(),</CODE> you can use the Configure
command:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  % sh Configure -Uusemymalloc&quot;</pre>
        </td>
	    
      </tr>
    </table>
    <P>
Note that:

<P>

    <table>
      <tr>

	<td bgcolor="#eeeeee" width="1">
	  &nbsp;
        </td>

	<td>
	  <pre>  -U == undefine usemymalloc (use system malloc)
  -D == define   usemymalloc (use Perl's malloc)</pre>
        </td>
	    
      </tr>
    </table>
    <P>
It seems that Linux still defaults to system malloc so you might want to
configure Perl with -Dusemymalloc. Perl's malloc is not much of a win under
linux, but makes a <STRONG>huge</STRONG> difference under Solaris.

<P>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<CENTER><H1><A NAME="Architecture_Specific_Compile_Op">Architecture Specific Compile Options</A></H1></CENTER>
<P>
When you build Apache and Perl you can optimize the compiled applications
to take the benefits of your machine's architecture.

<P>
Everything depends on the kind of compiler that you use, the kind of CPU
and 

<P>
For example if you use <CODE>gcc(1)</CODE> you might want to use:

<UL>
<P><LI>
<P>
<EM>-march=pentium</EM> if you have a pentium CPU

<P><LI>
<P>
<EM>-march=pentiumpro</EM> for pentiumpro and above (but the binary won't run on i386)

<P><LI>
<P>
<EM>-fomit-frame-pointer</EM> makes extra register available but disables debugging

<P><LI>
<P>
you can try these options were reported to improve the performance:
<EM>-ffast-math</EM>, <EM>-malign-double</EM>, <EM>-funroll-all-loops</EM>,
<EM>-fno-rtti</EM>, <EM>-fno-exceptions</EM>.

<P>
see the <CODE>gcc(1)</CODE> manpage for the details about these

<P><LI>
<P>
and of course you may want to change the usually default <CODE>-02</CODE> flag with a higher number like <EM>-O3</EM>. <EM>-OX</EM> (where X is a number between 1 and 6) defines a collection of various
optimization flags, the higher the number the more flags are bundled. The
gcc man page will tell you what flags are used for each number.

</UL>
<P>
Test your applications thoroughly when you change the default optimization
flags, especially when you go beyond <CODE>-02</CODE>. It's possible that the optimization will make the code work incorrectly
and/or cause segmentation faults.

<P>
See your preferred compiler's man page for detailed information about
optimization.

<P>
Also see: <A
HREF="http://members.nbci.com/Alex_Maranda/gnuintel/GNUintel.htm">http://members.nbci.com/Alex_Maranda/gnuintel/GNUintel.htm</A>


[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>


    <p>
    <div class="navbar">
      <a href="./porting.html">Prev</a>                                 |
      <A HREF="./index.html"         >Contents</A> |
      <A HREF="./index.html#search"  >Search</A>   |
      <A HREF="./index.html#download">Download</A> |
      <a href="./frequent.html">Next</a>
    </div>
    <p>

    <table width="60%" align="center">

      <tr>
	<td>
	  <div class="notice">
	  <B>Your corrections of the technical and grammatical
	     errors are very welcome. You are encouraged to help me
	     improve this guide.  If you have something to contribute
	     please <A HREF="help.html#Contacting_me"> send it
	     directly to me</A>.</B>
	  </div>
	</td>
      </tr>

      <tr>
	<td>
	  <div class="ad">
	    The <a href="http://www.modperl.com/">
	      <B>Writing Apache Modules with Perl and C</B></a>
	    book can be purchased online from <a
	      href="http://www.ora.com/catalog/wrapmod/">O'Reilly </a>
	    and <a
	    href="http://www.amazon.com/exec/obidos/ASIN/156592567X/writinapachemodu">
	      Amazon.com</a>.
	  </div>
	</td>
      </tr>

</table>

<center>
[ <B><FONT SIZE=-1><A HREF="#toc">TOC</A></FONT></B> ]
<HR>
<table cellspacing=2 cellpadding=2>

<tr align=center valign=top>
<td align=center valign=center>

<b><font size=-1>Written by <a
href="help.html#Contacting_me">Stas Bekman</a>.<br> Last Modified at 04/28/2001
</font></b>
<br>

</td>

<td>

<a href="http://perl.apache.org"><img src="images/mod_perl2.jpg"  border=0 alt="mod_perl icon" border=0 height=59 width=150></a>
<br>

</td>

<td>

<font size=-2>Use of the Camel for Perl is <br>
a trademark of <a href="http://www.ora.com">O'Reilly &amp; Associates</a>,<br>
and is used by permission. </font> 
<br>

</td>

</tr>
</table>
</center>

</body>
</html>
